{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 数据预处理\n",
    "root_dir = 'D:/数据库/小样本数据库/data/omniglot2/raw'\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#an example of img_items:\n",
    "#( '0709_17.png',                                                                             #file\n",
    "# 'Alphabet_of_the_Magi/character01',                                                         #r[-2] + \"/\" + r[-1]\n",
    "#'D:\\\\数据库\\\\小样本数据库\\\\data\\\\omniglot2\\\\raw\\\\images_evaluation\\\\Tibetan\\\\character32')   #root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Found 32460 items \n",
      "('0709_01.png', 'omniglot2/raw\\\\images_background\\\\Alphabet_of_the_Magi\\\\character01', 'D:/数据库/小样本数据库/data/omniglot2/raw\\\\images_background\\\\Alphabet_of_the_Magi\\\\character01')\n"
     ]
    }
   ],
   "source": [
    "#返回一个img_items列表，包含所有图片样本，每个样本都是一个三元组（图片名词，语言/字母类别，图片样本所在的目录）\n",
    "def find_classes(root_dir):\n",
    "    img_items = []\n",
    "    #root='D:\\\\数据库\\\\小样本数据库\\\\data\\\\omniglot2\\\\raw\\\\images_evaluation\\\\Tibetan\\\\character32'\n",
    "    #dirs=[]\n",
    "    #files=['1585_01.png', '1585_02.png', '1585_03.png',,,,,'1585_20.png']\n",
    "    for (root, dirs, files) in os.walk(root_dir):\n",
    "        for file in files:  #遍历某种语言某类字母的20张图片\n",
    "            if (file.endswith(\"png\")):\n",
    "                r = root.split('/')\n",
    "                img_items.append((file, r[-2] + \"/\" + r[-1], root))\n",
    "    print(\"== Found %d items \" % len(img_items))   #32460个样本\n",
    "    return img_items\n",
    "\n",
    "img_items = find_classes(root_dir)\n",
    "print(img_items[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Found 1623 classes\n"
     ]
    }
   ],
   "source": [
    "## 构建一个词典{class:idx}  把所有类（具体到所有语言的所有字母类别）构成一个映射，索引按顺序排列\n",
    "def index_classes(items):\n",
    "    class_idx = {}\n",
    "    count = 0\n",
    "    for item in items:\n",
    "        if item[1] not in class_idx:\n",
    "            class_idx[item[1]] = count\n",
    "            count += 1\n",
    "    print('== Found {} classes'.format(len(class_idx)))   #1623类\n",
    "    return class_idx\n",
    "\n",
    "class_idx = index_classes(img_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = dict()  #把所有样本生成一个字典按类别保存，(类别索引：[图片1，图片2，，，图片20])\n",
    "for imgname, classes, dirs in img_items:\n",
    "    img = '{}/{}'.format(dirs, imgname)  #某张图片的地址\n",
    "    label = class_idx[classes]  #某张图片的类别对应的索引\n",
    "    transform = transforms.Compose([lambda img: Image.open(img).convert('L'),  #转成灰度图\n",
    "                                    lambda img: img.resize((28, 28)),  #统一大小\n",
    "                                    lambda img: np.reshape(img, (28, 28, 1)),\n",
    "                                    lambda img: np.transpose(img, [2, 0, 1]),   #通道在前\n",
    "                                    lambda img: img / 255.  #归一化\n",
    "                                    ])\n",
    "    img = transform(img)  #图像处理\n",
    "    if label in temp.keys():\n",
    "        temp[label].append(img)\n",
    "    else:\n",
    "        temp[label] = [img]\n",
    "        \n",
    "#print(len(temp))  #1623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#存放所有样本图片[[img1,,,,20张图片],[],[],[],,,,,1623个[]]\n",
    "img_list = []   \n",
    "for label, imgs in temp.items():\n",
    "    img_list.append(np.array(imgs))\n",
    "img_list = np.array(img_list).astype(np.float)\n",
    "#print('data shape:{}'.format(img_list.shape))  # (1623, 20, 1, 28, 28)\n",
    "#print(img_list[0][0].shape)  #一张图片的像素数组  (1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分割训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = img_list[:1200]  #前1200类作为训练集\n",
    "x_val = img_list[1200:1400]  #后200类作为验证集\n",
    "x_test=img_list[1400:]  #后223类作为测试集\n",
    "num_classes = img_list.shape[0]  #训练集+测试集一共有1623类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把训练集转换成一个个样本存放的形式，并生成对应样本的标签\n",
    "imgs=[]  #训练集所有图片\n",
    "labels=[] #imgs对应的标签\n",
    "for i in range(len(x_train)):\n",
    "    for j in range(20):\n",
    "        img=x_train[i][j]\n",
    "        imgs.append(img)\n",
    "        labels.append(i)\n",
    "        \n",
    "#验证集\n",
    "val_imgs=[]  \n",
    "val_labels=[] \n",
    "for i in range(len(x_val)):\n",
    "    for j in range(20):\n",
    "        img=x_val[i][j]\n",
    "        val_imgs.append(img)\n",
    "        val_labels.append(i)\n",
    "        \n",
    "#测试集\n",
    "test_imgs=[]  \n",
    "test_labels=[] \n",
    "for i in range(len(x_test)):\n",
    "    for j in range(20):\n",
    "        img=x_test[i][j]\n",
    "        test_imgs.append(img)\n",
    "        test_labels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "class OmniglotDataset(data.Dataset):\n",
    "    def __init__(self,imgs,labels):\n",
    "        self.imgs=imgs\n",
    "        self.labels=labels\n",
    "    def __getitem__(self, idx):\n",
    "        return self.imgs[idx], self.labels[idx]\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrototypicalBatchSampler(object):\n",
    "    def __init__(self, labels, classes_per_it, num_samples, iterations):\n",
    "        super(PrototypicalBatchSampler, self).__init__()\n",
    "        self.labels = labels\n",
    "        self.classes_per_it = classes_per_it\n",
    "        self.sample_per_class = num_samples  #s+q\n",
    "        self.iterations = iterations\n",
    "\n",
    "        self.classes, self.counts = np.unique(self.labels, return_counts=True)\n",
    "        #print(self.classes, self.counts )   #[0~1199]   [20,,,,,,20]\n",
    "        self.classes = torch.LongTensor(self.classes)\n",
    "\n",
    "        self.idxs = range(len(self.labels)) #[0~2399]\n",
    "        self.indexes = np.empty((len(self.classes), max(self.counts)), dtype=int) * np.nan\n",
    "        self.indexes = torch.Tensor(self.indexes)\n",
    "        \n",
    "        self.numel_per_class = torch.zeros_like(self.classes)\n",
    "        for idx, label in enumerate(self.labels):\n",
    "            label_idx = np.argwhere(self.classes == label).item()\n",
    "            self.indexes[label_idx, np.where(np.isnan(self.indexes[label_idx]))[0][0]] = idx\n",
    "            self.numel_per_class[label_idx] += 1\n",
    "        #print(self.indexes[2][15])  #  55     self.indexes ([1200, 20])   表示第n类的第k张图片在数据集中排第几个样本\n",
    "        #print(self.numel_per_class[0])  #   20    self.numel_per_class([1200])  \n",
    "    \n",
    "    #产生一个batch样本的索引\n",
    "    def __iter__(self):\n",
    "        spc = self.sample_per_class\n",
    "        cpi = self.classes_per_it\n",
    "\n",
    "        for it in range(self.iterations):  #一个batch包含self.iterations个任务,iterations相当于eposides\n",
    "            batch_size = spc * cpi  #一个任务需要的数据量（支持集+查询集）\n",
    "            batch = torch.LongTensor(batch_size)\n",
    "            c_idxs = torch.randperm(len(self.classes))[:cpi]  #从数据集1200个类别中随机选取cpi个类别\n",
    "            #print(c_idxs)  #([ 335,   56, 1139,  991,  137])\n",
    "            for i, c in enumerate(self.classes[c_idxs]):   #从被选出的每个类别中随机选取spc个样本\n",
    "                s = slice(i * spc, (i + 1) * spc) #每个类被选出的所有样本在新生成batch中的存放位置\n",
    "                #print('c=%d',c)  #c分别为335,   56, 1139,  991,  137\n",
    "                #print('i=%d',i) #0~4\n",
    "                #label_idx = torch.arange(len(self.classes)).long()[self.classes == c].item()\n",
    "                label_idx=c\n",
    "                sample_idxs = torch.randperm(20)[:spc]  #从某一类20个样本中随机选择spc个样本\n",
    "                batch[s] = self.indexes[label_idx][sample_idxs]\n",
    "            batch = batch[torch.randperm(len(batch))]\n",
    "            yield batch\n",
    "    def __len__(self):\n",
    "        return self.iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata=OmniglotDataset(imgs,labels)\n",
    "trainsampler=PrototypicalBatchSampler(labels,5,15,28)\n",
    "dataloader = torch.utils.data.DataLoader(traindata, batch_sampler=trainsampler)\n",
    "\n",
    "#验证集\n",
    "valdata=OmniglotDataset(val_imgs,val_labels)\n",
    "valsampler=PrototypicalBatchSampler(val_labels,5,15,28)\n",
    "val_dataloader = torch.utils.data.DataLoader(valdata, batch_sampler=valsampler)\n",
    "\n",
    "#测试集\n",
    "testdata=OmniglotDataset(test_imgs,test_labels)\n",
    "testsampler=PrototypicalBatchSampler(test_labels,5,15,28)\n",
    "test_dataloader = torch.utils.data.DataLoader(testdata, batch_sampler=testsampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(next(iter(dataloader))) #[75个图片矩阵，75个标签]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建原型网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProtoNet(\n",
      "  (encoder): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def conv_block(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2)\n",
    "    )\n",
    "\n",
    "\n",
    "class ProtoNet(nn.Module):\n",
    "    def __init__(self, x_dim=1, hid_dim=64, z_dim=64):\n",
    "        super(ProtoNet, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            conv_block(x_dim, hid_dim),\n",
    "            conv_block(hid_dim, hid_dim),\n",
    "            conv_block(hid_dim, hid_dim),\n",
    "            conv_block(hid_dim, z_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=x.type(torch.cuda.FloatTensor)\n",
    "        x = self.encoder(x)\n",
    "        return x.view(x.size(0), -1)\n",
    "    \n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "model = ProtoNet().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim=torch.optim.Adam(params=model.parameters(),lr=0.001)\n",
    "lr_scheduler=torch.optim.lr_scheduler.StepLR(optimizer=optim,gamma=0.5,step_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "#欧式距离\n",
    "def euclidean_dist(x, y):\n",
    "    # x: N x D\n",
    "    # y: M x D\n",
    "    n = x.size(0)  #查询集的样本数=原型的数*n_query\n",
    "    m = y.size(0)  #原型的数\n",
    "    d = x.size(1)  #每个样本的嵌入网络输出维度=每个原型的嵌入维度\n",
    "    if d != y.size(1):\n",
    "        raise Exception\n",
    "\n",
    "    x = x.unsqueeze(1).expand(n, m, d)\n",
    "    y = y.unsqueeze(0).expand(n, m, d)\n",
    "\n",
    "    return torch.pow(x - y, 2).sum(2)  #返回（n,m）\n",
    "\n",
    "def prototypical_loss(input, target, n_support):\n",
    "    target_cpu = target.to('cpu')   #75个样本的类别\n",
    "    input_cpu = input.to('cpu')  #75个样本全部网络嵌入后的输出结果\n",
    "\n",
    "    #返回出类别c选出的支持集样本索引\n",
    "    def supp_idxs(c):\n",
    "        # FIXME when torch will support where as np\n",
    "        return target_cpu.eq(c).nonzero()[:n_support].squeeze(1)  #从类别c的所有样本中取n_support个作为支持集\n",
    "\n",
    "    # FIXME when torch.unique will be available on cuda too\n",
    "    classes = torch.unique(target_cpu)  #一共有哪些类别\n",
    "    n_classes = len(classes)  #一共有多少给类别\n",
    "    # FIXME when torch will support where as np\n",
    "    # assuming n_query, n_target constants\n",
    "    n_query = target_cpu.eq(classes[0].item()).sum().item() - n_support  #每个类别各有多少个样本组成查询集\n",
    "\n",
    "    support_idxs = list(map(supp_idxs, classes))   #全部支持集样本的索引[[类别1]，,,[类别n_classes]]\n",
    "\n",
    "    prototypes = torch.stack([input_cpu[idx_list].mean(0) for idx_list in support_idxs])   #计算出支持集每个类别的原型\n",
    "    # FIXME when torch will support where as np\n",
    "    #全部查询集样本的索引\n",
    "    query_idxs = torch.stack(list(map(lambda c: target_cpu.eq(c).nonzero()[n_support:], classes))).view(-1)\n",
    "\n",
    "    query_samples = input.to('cpu')[query_idxs]     #取出所有支持集样本的嵌入向量\n",
    "    dists = euclidean_dist(query_samples, prototypes)  #返回（查询集样本数，原型类别数）的距离矩阵\n",
    "\n",
    "    log_p_y = F.log_softmax(-dists, dim=1).view(n_classes, n_query, -1)\n",
    "\n",
    "    target_inds = torch.arange(0, n_classes)\n",
    "    target_inds = target_inds.view(n_classes, 1, 1)\n",
    "    target_inds = target_inds.expand(n_classes, n_query, 1).long()\n",
    "\n",
    "    loss_val = -log_p_y.gather(2, target_inds).squeeze().view(-1).mean()\n",
    "    _, y_hat = log_p_y.max(2)  #把log_p_y最小的原型对应的类别定为查询集样本的类别\n",
    "    acc_val = y_hat.eq(target_inds.squeeze()).float().mean()\n",
    "\n",
    "    return loss_val,  acc_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                           | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch: 0 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:02<00:00, 11.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 0.4625422563403845, Avg Train Acc: 0.8357142827340535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▉                                                                             | 2/28 [00:00<00:01, 18.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Val Loss: 1.0961973326546806, Avg Val Acc: 0.7800000054495675 (Best)\n",
      "=== Epoch: 1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:01<00:00, 18.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 0.398562701685088, Avg Train Acc: 0.8639285670859473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████▉                                                                          | 3/28 [00:00<00:01, 22.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Val Loss: 0.7758758286280292, Avg Val Acc: 0.8110714278050831 (Best)\n",
      "=== Epoch: 2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:01<00:00, 19.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 0.34443896461189505, Avg Train Acc: 0.8811904724155154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████▉                                                                          | 3/28 [00:00<00:01, 21.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Val Loss: 0.6436975156622273, Avg Val Acc: 0.8330952383223034 (Best)\n",
      "=== Epoch: 3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:01<00:00, 19.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 0.25318576232530177, Avg Train Acc: 0.9151999974250793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|████████▉                                                                          | 3/28 [00:00<00:01, 22.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Val Loss: 0.5097465296834707, Avg Val Acc: 0.8537999975681305 (Best)\n",
      "=== Epoch: 4 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 28/28 [00:01<00:00, 19.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 0.1871448717173189, Avg Train Acc: 0.9335999995470047\n",
      "Avg Val Loss: 0.3491128814406693, Avg Val Acc: 0.8827999967336655 (Best)\n",
      "最后的结果： best_acc=0, train_loss=0, train_acc=0, val_loss=0, val_acc=0\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "\n",
    "best_acc = 0\n",
    "best_model_path='C:/Users/user/Desktop/proto_net/best_protonet/best_model.pth'\n",
    "last_model_path='C:/Users/user/Desktop/proto_net/best_protonet/last_model.pth'\n",
    "\n",
    "#遍历epoch训练\n",
    "for epoch in range(5):\n",
    "    print('=== Epoch: {} ==='.format(epoch))\n",
    "    #取一个batch的训练数据\n",
    "    tr_iter = iter(dataloader)\n",
    "    model.train()\n",
    "    for batch in tqdm(tr_iter):  #遍历每个batch   #len(next(iter(dataloader))) #[75个图片矩阵，75个标签]\n",
    "        optim.zero_grad()  #梯度清零\n",
    "        x, y = batch\n",
    "        #print(len(x))  #75\n",
    "        #print(x.shape)  #([75, 1, 28, 28])\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        model_output = model(x)  #前传\n",
    "        loss, acc = prototypical_loss(model_output, target=y,n_support=5)  #计算loss\n",
    "        loss.backward()  #反传\n",
    "        optim.step()  #参数更新\n",
    "        train_loss.append(loss.item())   #加入这个batch的计算loss\n",
    "        train_acc.append(acc.item())  #加入这个batch的计算acc\n",
    "    avg_loss = np.mean(train_loss[-100:])  #计算本次epoch的所有batch迭代的平均损失\n",
    "    avg_acc = np.mean(train_acc[-100:])   #计算本次epoch的所有batch迭代的平均准确率\n",
    "    print('Avg Train Loss: {}, Avg Train Acc: {}'.format(avg_loss, avg_acc))\n",
    "    lr_scheduler.step()   #更新学习率\n",
    "    \n",
    "    #一边训练一边验证\n",
    "    val_iter = iter(val_dataloader)\n",
    "    model.eval()\n",
    "    for batch in val_iter:\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        model_output = model(x)\n",
    "        loss, acc = prototypical_loss(model_output, target=y,n_support=5)\n",
    "        val_loss.append(loss.item())\n",
    "        val_acc.append(acc.item())\n",
    "\n",
    "    avg_loss = np.mean(val_loss[-100:])\n",
    "    avg_acc = np.mean(val_acc[-100:])\n",
    "\n",
    "    #如果当前模型的验证效果比先前好，则把当前模型记为最佳模型\n",
    "    postfix = ' (Best)' if avg_acc >= best_acc else ' (Best: {})'.format(best_acc)\n",
    "\n",
    "    print('Avg Val Loss: {}, Avg Val Acc: {}{}'.format(  #输出本次验证的平均损失和准确率\n",
    "            avg_loss, avg_acc, postfix))\n",
    "\n",
    "    #保存某个epoch内所有batch得到的最佳模型、准确率\n",
    "    if avg_acc >= best_acc:\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        best_acc = avg_acc\n",
    "        best_state = model.state_dict()\n",
    "\n",
    "#保存最终所有epoch得到的最佳模型\n",
    "torch.save(model.state_dict(), last_model_path)\n",
    "\n",
    "print('最后的结果： best_acc=%d, train_loss=%d, train_acc=%d, val_loss=%d, val_acc=%d' % (best_acc, train_loss[-1], train_acc[-1], val_loss[-1], val_acc[-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.9102857112884521\n"
     ]
    }
   ],
   "source": [
    "avg_acc = list()\n",
    "for epoch in range(10):\n",
    "    test_iter = iter(test_dataloader)\n",
    "    for batch in test_iter:\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        model_output = model(x)\n",
    "        _, acc = prototypical_loss(model_output, target=y,n_support=5)\n",
    "        avg_acc.append(acc.item())\n",
    "avg_acc = np.mean(avg_acc)\n",
    "print('Test Acc: {}'.format(avg_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with best model..\n",
      "Test Acc: 0.9153571414096014\n"
     ]
    }
   ],
   "source": [
    "model=None\n",
    "#加载训练最好的模型参数\n",
    "model = ProtoNet().to(device)\n",
    "model.load_state_dict(best_state)\n",
    "print('Testing with best model..')\n",
    "#测试模型\n",
    "avg_acc = list()\n",
    "for epoch in range(10):\n",
    "    test_iter = iter(test_dataloader)\n",
    "    for batch in test_iter:\n",
    "        x, y = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        model_output = model(x)\n",
    "        _, acc = prototypical_loss(model_output, target=y,n_support=5)\n",
    "        avg_acc.append(acc.item())\n",
    "avg_acc = np.mean(avg_acc)\n",
    "print('Test Acc: {}'.format(avg_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyenv] *",
   "language": "python",
   "name": "conda-env-pyenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
