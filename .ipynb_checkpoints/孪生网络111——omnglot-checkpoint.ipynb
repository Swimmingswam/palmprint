{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# 数据预处理\n",
    "root_dir = 'D:\\\\数据库\\\\小样本数据库\\\\data\\\\omniglot2\\\\raw'\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成数据集的x，y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.把每个样本存为三元组格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0709_01.png', 'Alphabet_of_the_Magi/character01', 'D:\\\\数据库\\\\小样本数据库\\\\data\\\\omniglot2\\\\raw\\\\images_background\\\\Alphabet_of_the_Magi\\\\character01')\n"
     ]
    }
   ],
   "source": [
    "#返回一个img_items列表，包含所有图片样本，每个样本都是一个三元组（图片名词，语言/字母类别，图片样本所在的目录）\n",
    "def find_classes(root_dir):\n",
    "    img_items = []\n",
    "    for (root, dirs, files) in os.walk(root_dir):\n",
    "        for file in files:  #遍历某种语言某类字母的20张图片\n",
    "            if (file.endswith(\"png\")):\n",
    "                r = root.split('\\\\')\n",
    "                img_items.append((file, r[-2] + \"/\" + r[-1], root))\n",
    "    #print(\"== Found %d items \" % len(img_items))   #32460个样本\n",
    "    return img_items\n",
    "\n",
    "img_items = find_classes(root_dir)\n",
    "print(img_items[0])\n",
    "# print(img_items[0])  \n",
    "# ('0709_01.png', \n",
    "#  'Alphabet_of_the_Magi/character01', \n",
    "#  'D:/数据库/小样本数据库/data/omniglot2/raw\\\\images_background\\\\Alphabet_of_the_Magi\\\\character01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.构造类别映射字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 构建一个词典{class:idx}  把所有类（具体到所有语言的所有字母类别）构成一个映射，索引按顺序排列\n",
    "def index_classes(items):\n",
    "    class_idx = {}\n",
    "    count = 0\n",
    "    for item in items:\n",
    "        if item[1] not in class_idx:\n",
    "            class_idx[item[1]] = count\n",
    "            count += 1\n",
    "    #print('== Found {} classes'.format(len(class_idx)))   #1623类\n",
    "    return class_idx\n",
    "\n",
    "class_idx = index_classes(img_items)\n",
    "#print(class_idx)  #{'Alphabet_of_the_Magi/character01': 0, 'Alphabet_of_the_Magi/character02': 1;,,,,1622}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.构造字典，按类别存放样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = dict()  #把所有样本生成一个字典按类别保存，(类别索引：[图片1，图片2，，，图片20])\n",
    "for imgname, classes, dirs in img_items:\n",
    "    img = '{}/{}'.format(dirs, imgname)  #某张图片的地址\n",
    "    label = class_idx[classes]  #某张图片的类别对应的索引\n",
    "    transform = transforms.Compose([lambda img: Image.open(img).convert('L'),  #转成灰度图\n",
    "                                    lambda img: img.resize((28, 28)),  #统一大小\n",
    "                                    lambda img: np.reshape(img, (28, 28, 1)),\n",
    "                                    lambda img: np.transpose(img, [2, 0, 1]),   #通道在前\n",
    "                                    lambda img: img / 255.  #归一化\n",
    "                                    ])\n",
    "    img = transform(img)  #图像处理\n",
    "    if label in temp.keys():\n",
    "        temp[label].append(img)\n",
    "    else:\n",
    "        temp[label] = [img]\n",
    "        \n",
    "#print(len(temp))  #1623"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.把字典转换成数组，按类划分小数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#存放所有样本图片[[img1,,,,20张图片],[],[],[],,,,,1623个[]]\n",
    "img_list = []   \n",
    "for label, imgs in temp.items():\n",
    "    img_list.append(np.array(imgs))\n",
    "img_list = np.array(img_list).astype(np.float)\n",
    "#print('data shape:{}'.format(img_list.shape))  # (1623, 20, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.分割训练集/验证集/测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = img_list.shape[0]  #训练集+测试集一共有1623类\n",
    "x_train = img_list[:1100]  #前1100类作为训练集\n",
    "x_val = img_list[1100:1300]  #后200类作为验证集\n",
    "x_test=img_list[1300:]  #后323类作为测试集\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.把数据集分割成x和y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_x_y(subset):\n",
    "    imgs=[]  #数据集所有图片\n",
    "    labels=[] #imgs对应的标签\n",
    "    for i in range(len(subset)):\n",
    "        for j in range(20):\n",
    "            img=subset[i][j]\n",
    "            imgs.append(img)\n",
    "            labels.append(i)\n",
    "    return imgs,labels\n",
    "\n",
    "train_imgs,train_labels=split_x_y(x_train)\n",
    "val_imgs,val_labels=split_x_y(x_val)\n",
    "test_imgs,test_labels=split_x_y(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义dataset类和dataloader类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "\n",
    "class SiamsDataset(data.Dataset):\n",
    "    def __init__(self,imgs,labels):\n",
    "        self.imgs=imgs\n",
    "        self.labels=labels\n",
    "        self.classes, self.counts = np.unique(self.labels, return_counts=True)\n",
    "        self.classes = torch.LongTensor(self.classes)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img0_tuple=torch.randperm(len(self.classes))[0]   #第一个样本随机选择一类\n",
    "        should_get_same_class = random.randint(0,1)  #随机决定是否要获取同类样本\n",
    "        if should_get_same_class:  \n",
    "            img1_tuple = img0_tuple\n",
    "        else:\n",
    "            while True:    \n",
    "                #直到找到非同一类别\n",
    "                img1_tuple = torch.randperm(len(self.classes))[0]   \n",
    "                if img0_tuple !=img1_tuple:\n",
    "                    break\n",
    "            \n",
    "        img0_idx = torch.randperm(int(self.counts[img0_tuple]))[0] #取出图片一\n",
    "        img1_idx = torch.randperm(int(self.counts[img1_tuple]))[0] #取出图片二\n",
    "        \n",
    "        idx0=img0_tuple*20+img0_idx\n",
    "        idx1=img1_tuple*20+img1_idx\n",
    "\n",
    "        return self.imgs[idx0], self.imgs[idx1],should_get_same_class\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 28, 28])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dataloader(imgs,labels,train_batch_size):\n",
    "    dataset=SiamsDataset(imgs,labels)\n",
    "    return torch.utils.data.DataLoader(dataset, shuffle=True,batch_size=train_batch_size)\n",
    "\n",
    "train_batch_size=32\n",
    "train_loader=dataloader(train_imgs,train_labels,train_batch_size)\n",
    "val_loader=dataloader(val_imgs,val_labels,train_batch_size)\n",
    "test_loader=dataloader(test_imgs,test_labels,train_batch_size)\n",
    "next(iter(train_loader))[0].shape  #([32, 1, 28, 28])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造孪生网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SiamsNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiamsNet, self).__init__()\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),   #padding\n",
    "            nn.Conv2d(1, 4, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(4),\n",
    "            \n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(4, 8, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(8),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(8*28*28, 500),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(500, 500),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(500, 5))\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        output = self.cnn1(x)\n",
    "        output = output.view(output.size()[0], -1)  #拉直\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2\n",
    "    \n",
    "#自定义损失函数\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SiamsNet().cuda() #定义模型且移至GPU\n",
    "criterion = ContrastiveLoss() #定义损失函数\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0005) #定义优化器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 0 , Current loss: 1.1699\n",
      "\n",
      "Epoch number: 1 , Current loss: 1.0408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counter = []\n",
    "loss_history = [] \n",
    "iteration_number = 0\n",
    "\n",
    "\n",
    "#开始训练\n",
    "for epoch in range(0, 2):\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        img0, img1 , label = data\n",
    "        #img0维度为torch.Size([32, 1, 100, 100])，32是batch，label为torch.Size([32, 1])\n",
    "        img0, img1, label=img0.type(torch.FloatTensor),img1.type(torch.FloatTensor),label.type(torch.FloatTensor),\n",
    "        img0, img1 , label = img0.cuda(), img1.cuda(), label.cuda() #数据移至GPU\n",
    "        optimizer.zero_grad()\n",
    "        output1,output2 = model(img0, img1)\n",
    "        loss_contrastive = criterion(output1, output2, label)\n",
    "        loss_contrastive.backward()\n",
    "        optimizer.step()\n",
    "        if i % 10 == 0 :\n",
    "            iteration_number +=10\n",
    "            counter.append(iteration_number)\n",
    "            loss_history.append(loss_contrastive.item())\n",
    "    print(\"Epoch number: {} , Current loss: {:.4f}\\n\".format(epoch,loss_contrastive.item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/688 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch: 0 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [00:36<00:00, 18.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 1.1107262504100799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                 | 2/688 [00:00<00:36, 18.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Val Loss: 1.1642585253715516, (Best: 0)\n",
      "=== Epoch: 1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [00:36<00:00, 19.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 1.0972810328006743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                 | 2/688 [00:00<00:37, 18.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Val Loss: 1.116766031384468, (Best: 0)\n",
      "=== Epoch: 2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [00:35<00:00, 19.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 1.0843740338087082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                 | 2/688 [00:00<00:38, 18.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Val Loss: 1.137569010257721, (Best: 0)\n",
      "=== Epoch: 3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [00:35<00:00, 19.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 1.1067077189683914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                                 | 2/688 [00:00<00:39, 17.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Val Loss: 1.1296838533878326, (Best: 0)\n",
      "=== Epoch: 4 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 688/688 [00:36<00:00, 18.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 1.0917650824785232\n",
      "Avg Val Loss: 1.103089679479599, (Best: 0)\n",
      "最后的结果： best_loss=0, train_loss=1, val_loss=1\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import random\n",
    "    \n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "train_loss = [] #记录每个eposide，每个任务更新的结果\n",
    "\n",
    "val_loss = []\n",
    "\n",
    "best_loss = 0\n",
    "best_model_path='C:/Users/user/Desktop/最近/best_protonet/best_model.pth'\n",
    "last_model_path='C:/Users/user/Desktop/最近/best_protonet/last_model.pth'\n",
    "\n",
    "#遍历epoch训练\n",
    "for epoch in range(5):\n",
    "    print('=== Epoch: {} ==='.format(epoch))\n",
    "    #取一个batch的训练数据\n",
    "    tr_iter = iter(train_loader)\n",
    "    model.train()\n",
    "    for eposide in tqdm(tr_iter):  #遍历每个eposide，一共遍历iterations次，#len(next(iter(dataloader))) #[75个图片矩阵，75个标签]\n",
    "        \n",
    "        x1, x2, y = eposide   #x.shape=([75, 1, 28, 28])\n",
    "        #print(x1.shape)\n",
    "        x1, x2, y=x1.type(torch.FloatTensor),x2.type(torch.FloatTensor),y.type(torch.FloatTensor),\n",
    "        x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "        optimizer.zero_grad()  #梯度清零\n",
    "        \n",
    "        output1,output2= model(x1,x2)  #前传\n",
    "        loss= criterion(output1,output2, y)  #计算loss\n",
    " \n",
    "        loss.backward()  #反传\n",
    "        optimizer.step()  #参数更新\n",
    "        \n",
    "        train_loss.append(loss.item())   #加入这个batch的计算loss\n",
    "        \n",
    "    avg_loss = np.mean(train_loss[-100:])  #计算本次epoch的所有batch迭代的平均损失\n",
    "    print('Avg Train Loss: {}'.format(avg_loss))\n",
    "    \n",
    "    #每训练一个batch=iterations个任务后，验证一次模型\n",
    "    val_iter = iter(val_loader)\n",
    "    model.eval()\n",
    "    for eposide in val_iter:\n",
    "        x1, x2, y = eposide   #x.shape=([75, 1, 28, 28])\n",
    "        x1, x2, y=x1.type(torch.FloatTensor),x2.type(torch.FloatTensor),y.type(torch.FloatTensor),\n",
    "        x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "        \n",
    "        output1,output2= model(x1,x2)\n",
    "        loss= criterion(output1,output2, y)  #计算loss\n",
    "        \n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "    avg_loss = np.mean(val_loss[-100:])\n",
    "\n",
    "    #如果当前模型的验证效果比先前好，则把当前模型记为最佳模型\n",
    "    postfix = ' (Best)' if avg_loss <= best_loss else ' (Best: {})'.format(best_loss)\n",
    "    print('Avg Val Loss: {},{}'.format(  #输出本次验证的平均损失和准确率\n",
    "            avg_loss, postfix))\n",
    "\n",
    "    #保存某个epoch内所有batch在验证集上得到的最佳模型、准确率\n",
    "    if avg_loss <= best_loss:\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        best_loss = avg_loss\n",
    "        best_state = model.state_dict()\n",
    "\n",
    "#print(len(train_loss))  #iterations\n",
    "#print(len(val_loss)) #iterations\n",
    "\n",
    "#保存最终所有epoch得到的最佳模型\n",
    "torch.save(model.state_dict(), last_model_path)\n",
    "print('最后的结果： best_loss=%d, train_loss=%d, val_loss=%d' % (best_loss, train_loss[-1] ,val_loss[-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 1.1037377886842974\n"
     ]
    }
   ],
   "source": [
    "test_loss = list()\n",
    "for epoch in range(10):\n",
    "    test_iter = iter(test_loader)\n",
    "    for eposide in test_iter:\n",
    "        x1, x2, y = eposide   #x.shape=([75, 1, 28, 28])\n",
    "        x1, x2, y=x1.type(torch.FloatTensor),x2.type(torch.FloatTensor),y.type(torch.FloatTensor),\n",
    "        x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "        \n",
    "        output1,output2= model(x1,x2)\n",
    "        loss= criterion(output1,output2, y)  #计算loss\n",
    "        \n",
    "        test_loss.append(loss.item())\n",
    "        \n",
    "avg_loss = np.mean(test_loss)\n",
    "print('Test loss: {}'.format(avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with best model..\n",
      "Test loss: 1.1022309557931258\n"
     ]
    }
   ],
   "source": [
    "model=None\n",
    "#加载训练最好的模型参数\n",
    "model = SiamsNet().to(device)\n",
    "model.load_state_dict(torch.load(os.path.join('C:\\\\Users\\\\user\\\\Desktop\\\\最近\\\\best_siamsnet','last_model.pth')))\n",
    "#model.load_state_dict(best_state)\n",
    "print('Testing with best model..')\n",
    "\n",
    "#测试模型\n",
    "test_loss = list()\n",
    "for epoch in range(10):\n",
    "    test_iter = iter(test_loader)\n",
    "    for eposide in test_iter:\n",
    "        x1, x2, y = eposide   #x.shape=([75, 1, 28, 28])\n",
    "        x1, x2, y=x1.type(torch.FloatTensor),x2.type(torch.FloatTensor),y.type(torch.FloatTensor),\n",
    "        x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "        \n",
    "        output1,output2= model(x1,x2)\n",
    "        loss= criterion(output1,output2, y)  #计算loss\n",
    "        \n",
    "        test_loss.append(loss.item())\n",
    "        \n",
    "avg_loss = np.mean(test_loss)\n",
    "print('Test loss: {}'.format(avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyenv] *",
   "language": "python",
   "name": "conda-env-pyenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
