{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-dcd247ce3bb1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mResNetBasicBlock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0min_channels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mResNetBasicBlock\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBatchNorm2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_channels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class ResNetBasicBlock(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,strides):\n",
    "        super(ResNetBasicBlock,self).__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels,out_channels,kernel_size=3,stride=stride,padding=1,bias=False)\n",
    "        self.bn1=nn.BatchNorm2d(out_channels)\n",
    "        self.conv2=nn.Conv2d(in_channels,out_channels,kernel_size=3,stride=stride,padding=1,bias=False)\n",
    "        self.bn2=nn.BatchNorm2d(out_channels)\n",
    "        self.stride=stride\n",
    "    def forward(self,x):\n",
    "        residual=x\n",
    "        out=self.conv1(x)\n",
    "        out=F.relu(self.bn1(out),inplace=True)\n",
    "        out=self.conv2(out)\n",
    "        out=self.bn2(out)\n",
    "        out+=residual\n",
    "        return F.relu(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform=transforms.Compose([\n",
    "    transforms.Resize((229,229)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "train_set=ImageFolder('../../catdog/train/',transforms=data_transform)\n",
    "val_set=ImageFolder('../../catdog/valid/',transforms=data_transform)\n",
    "classes=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(train_set,batch_size=32,shuffle=False,num_workers=0)\n",
    "val_loader=DataLoader(val_set,batch_size=32,shuffle=False,num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_resnet=resnet34(pretrained=True)\n",
    "if is_cuda:\n",
    "    my_resnet=my_resnet.cuda()\n",
    "    \n",
    "mu_resnet=nn.Squential(*list(my_resnet.children())[:-1])\n",
    "\n",
    "for p in my_resnet.parameters():\n",
    "    p.requires_grad=False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提取卷积特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_labels=[]\n",
    "trn_features=[]\n",
    "for d,la in train_loader:\n",
    "    o=my_resnet(Variable(d.cuda()))\n",
    "    o=o.view(size(0),-1)\n",
    "    trn_labels.extend(la)\n",
    "    trn_features.extend(o.cpu().data)\n",
    "    \n",
    "val_labels=[]\n",
    "val_features=[]\n",
    "for d,la in val_loader:\n",
    "    o=my_resnet(Variable(d.cuda()))\n",
    "    o=o.view(size(0),-1)\n",
    "    val_labels.extend(la)\n",
    "    val_features.extend(o.cpu().data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 为预卷积特征和加载器创建自定义的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesDataset(Dataset):\n",
    "    def __init__(self,fealist,lalist):\n",
    "        self.fealist=fealist\n",
    "        self.lalist=lalist\n",
    "    def __getitem__(self,index):\n",
    "        return (self.fealist[index],self.lablist[index])\n",
    "    def __len__(self):\n",
    "        return len(self.lablist)\n",
    "    \n",
    "trn_fea_set=FeaturesDataset(trn_features,trn_labels)\n",
    "val_fea_set=FeaturesDataset(val_features,val_labels)\n",
    "\n",
    "trn_fea_loader=DataLoader(trn_fea_set,batch_szie=64,shuffle=True)\n",
    "val_fea_loader=DataLoader(val_fea_set,batch_szie=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建简单线性模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyConnecteModel(nn.Module):\n",
    "    def __init__(self,in_size,out_size):\n",
    "        super(FullyConnecteModel,self).__init__()\n",
    "        self.fc=nn.Linear(in_size,out_size)\n",
    "        \n",
    "    def forward(self.inp):\n",
    "        out=self.fc(inp)\n",
    "        return out\n",
    "    \n",
    "fc_in_size=8192\n",
    "fc=FullyConnecteModel(fc_in_size,classes)\n",
    "if is_cuda:\n",
    "    fc=fc.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练并验证模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epoch,model,data_loader,phase='training',volatile=False,dataset_size=23000):\n",
    "    if phase == 'training':\n",
    "        model.train()\n",
    "    if phase == 'validation':\n",
    "        model.eval()\n",
    "        volatile=True\n",
    "    running_loss=0.0\n",
    "    running_correct=0\n",
    "    for batch_idx,(data,target) in enumerate(data_loader):\n",
    "        if is_cuda:\n",
    "            data,target=data.cuda(),target.cuda()\n",
    "        data,target=Variable(data,volatile),Variable(target)\n",
    "        \n",
    "        if phase =='training':\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        output=model(data)\n",
    "        loss=loss_fn(output,target)\n",
    "        running_loss+=loss_fn(output,target).data\n",
    "        preds=output.data.max(dim=1,keepdim=True)[1]\n",
    "        running_correct+=preds.eq(target.data.view_as(preds)).cpu().sum()\n",
    "        if phase == 'training':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    loss=running_loss/dataset_size\n",
    "    accuracy=100.*running_correct/dataset_size\n",
    "    print(f'{phase} loss is {loss} and {phase} accuracy is {running_correct}/{dataset_size}{accuracy}')\n",
    "    return loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses,train_accuracy=[],[]\n",
    "val_losses,val_accuracy=[],[]\n",
    "\n",
    "for epoch in range(1,10):\n",
    "    epoch_loss,epoch_accuracy=fit(epoch,fc,trn_fea_loader,phase='training')\n",
    "    val_epoch_loss,val_epoch_accuracy=fit(epoch,fc,val_fea_loader,phase='validation')\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracy.append(epoch_accuracy)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConv2d(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,**kwargs):\n",
    "        super(BasicConv2d,self).__init__()\n",
    "        self.conv=nn.Conv2d(in_channels,out_channels,bias=False,**kwargs)\n",
    "        self.bn=nn.BatchNorm2d(out_channels)\n",
    "    def forward(self,x):\n",
    "        x=self.conv(x)\n",
    "        x=self.bn(x)\n",
    "        return F.relu(x,inplace=True)\n",
    "    \n",
    "class InceptionBasicBlock(nn.Module):\n",
    "    super(InceptionBasicBlock,self).__init__()\n",
    "    self.branch1x1=BasicConv2d(in_channels,64,kernel_size=1)\n",
    "    \n",
    "    self.branch5x5_1=BasicConv2d(in_channels,48,kernel_size=1)\n",
    "    self.branch5x5_2=BasicConv2d(48,64,kernel_size=5,padding=2)\n",
    "    \n",
    "    self.branch3x3db1_1=BasicConv2d(in_channels,64,kernel_size=1)\n",
    "    self.branch3x3db1_2=BasicConv2d(64,96,kernel_size=3,padding=1)   \n",
    "    \n",
    "    self.branch_pool=BasicConv2d(in_channels,pool_features,kernel_size=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        branch1x1=self.branch1x1(x)\n",
    "        \n",
    "        branch5x5=self.branch5x5_1(x)\n",
    "        branch5x5=self.branch5x5_2(branch5x5)   \n",
    "        \n",
    "        branch3x3db1=self.branch3x3db1_1(x)\n",
    "        branch3x3db1=self.branch3x3db1_2(branch3x3db1)\n",
    "        \n",
    "        branch_pool=F.avg_pool2d(x,kernel_size=3,stride=1,padding=1)\n",
    "        branch_pool=self.branch_pool(branch_pool)\n",
    "        \n",
    "        outputs=[branch1x1,branch5x5,branch3x3db1,branch_pool]\n",
    "        return torch.cat(outputs,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Sequential):\n",
    "    def __init__(self,num_layers,num_input_features,bn_size,growth_rate,drop_rate):\n",
    "        super(DenseBlock,self).__init__()\n",
    "        for i in range(num_layers):\n",
    "            layer=DenseLayer(num_input_features+i*growth_rate,growth_rate,bn_size,drop_rate)\n",
    "            self.add_module('denselayer%d' % (i+1),layer)\n",
    "            \n",
    "class DenseLayer(nn.Sequential):\n",
    "    def __init__(self,num_input_features,growth_rate,bn_size,drop_rate):\n",
    "        super(DenseLayer,self).__init__()\n",
    "        self.add_module('norm.1',nn.BatchNorm2d(num_input_features)),\n",
    "        self.add_module('relu.1',nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv.1',nn.Conv2d(num_input_features,bn_size*growth_rate,kernel_size=3,stride=1,padding=1,bias=False)),\n",
    "        \n",
    "        \n",
    "        self.add_module('norm.2',nn.BatchNorm2d(bn_size*growth_rate)),\n",
    "        self.add_module('relu.2',nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv.2',nn.Conv2d(bn_size*growth_rate,bn_size*growth_rate,kernel_size=3,stride=1,padding=1,bias=False)),\n",
    "        \n",
    "        self.drop_rate=drop_rate\n",
    "        \n",
    "    def forward(self,x):\n",
    "        new_features=super(DenseLayer,self).forward(x)\n",
    "        if self.drop_rate>0:\n",
    "            new_features=F.dropout(new_features,p=self.drop_rate,training=self.training)\n",
    "        return torch.cat([x,new_features],1)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型集成：resnet+inception+densenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  创建三个模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_resnet=resnet34(pretrained=True)\n",
    "if is_cuda:\n",
    "    my_resnet=my_resnet.cuda()\n",
    "    \n",
    "my_resnet=nn.Sequential(*list(my_resnet.children())[:-1])\n",
    "\n",
    "for p in my_resnet.parameters():\n",
    "    p.requires_grad=False\n",
    "    \n",
    "    \n",
    "    \n",
    "my_inception=inception_v3(pretrained=True)\n",
    "if is_cuda:\n",
    "    my_inception=my_inception.cuda()\n",
    "    \n",
    "for p in my_inception.parameters():\n",
    "    p.requires_grad=False\n",
    "    \n",
    "    \n",
    "my_densenet=densenet121(pretrained=True)\n",
    "if is_cuda:\n",
    "    my_densenet=my_densenet.cuda()\n",
    "\n",
    "for p in my_densenet.parameters():\n",
    "    p.requires_grad=False   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分别提取特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_labels=[]\n",
    "trn_resnet_features=[]\n",
    "for d,la in train_loader:\n",
    "    o=my_resnet(Variable(d.cuda()))\n",
    "    o=o.view(size(0),-1)\n",
    "    trn_labels.extend(la)\n",
    "    trn_resnet_features.extend(o.cpu().data)\n",
    "    \n",
    "val_labels=[]\n",
    "val_resnet_features=[]\n",
    "for d,la in val_loader:\n",
    "    o=my_resnet(Variable(d.cuda()))\n",
    "    o=o.view(size(0),-1)\n",
    "    val_labels.extend(la)\n",
    "    val_resnet_features.extend(o.cpu().data)\n",
    "    \n",
    "    \n",
    "    \n",
    "trn_inception_features=LayerActivations(my_inception.Mixed_7c)\n",
    "for da,la in train_loader:\n",
    "    _=my_inception(Variable(da.cuda()))\n",
    "    \n",
    "trn_inception_features.remove()\n",
    "\n",
    "val_inception_features=LayerActivations(my_inception.Mixed_7c)\n",
    "for da,la in val_loader:\n",
    "    _=my_inception(Variable(da.cuda()))\n",
    "    \n",
    "val_inception_features.remove()\n",
    "\n",
    "\n",
    "\n",
    "trn_densenet_features=[]\n",
    "for d,la in train_loader:\n",
    "    o=my_densenet(Variable(d.cuda()))\n",
    "    o=o.view(size(0),-1)\n",
    "    trn_densenet_features.extend(o.cpu().data)\n",
    "    \n",
    "val_densenet_features=[]\n",
    "for d,la in val_loader:\n",
    "    o=my_densenet(Variable(d.cuda()))\n",
    "    o=o.view(size(0),-1)\n",
    "    val_densenet_features.extend(o.cpu().data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建自定义数据集和数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesDataset(Dataset):\n",
    "    def __init__(self,fealist1,fealist2,fealist2,lablist):\n",
    "        self.fealist1=fealist1\n",
    "        self.fealist2=fealist2\n",
    "        self.fealist3=fealist3\n",
    "        self.lablist=lablist\n",
    "    def __getitem__(self,index):\n",
    "        return (self.fealist1[index],self.fealist2[index],self.fealist3[index],self.lablist[index])\n",
    "    def __len__(self):\n",
    "        return len(self.lablist)\n",
    "    \n",
    "trn_feat_set=FeaturesDataset(trn_resnet_features,trn_inception_features,trn_densenet_features,trn_labels)\n",
    "val_feat_set=FeaturesDataset(val_resnet_features,val_inception_features,val_densenet_features,val_labels)\n",
    "\n",
    "trn_feat_loader=DataLoader(trn_feat_set,batch_size=64,shuffle=True)\n",
    "val_feat_loader=DataLoader(val_feat_set,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建集成模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self,out_size,training=True):\n",
    "        super(EnsembleModel,self).__init__()\n",
    "        self.fc1=nn.Linear(8192,512)\n",
    "        self.fc2=nn.Linear(131072,512)       \n",
    "        self.fc3=nn.Linear(82944,512)    \n",
    "        \n",
    "        self.fc4=nn.Linear(512,out_size)      \n",
    "    def foeward(self,inp1,inp2,inp3):\n",
    "        out1=self.fc1(inp1)\n",
    "        out2=self.fc2(inp2)\n",
    "        out3=self.fc3(inp3)\n",
    "        out=pit1+out2+out3\n",
    "        out=self.fc4(F.dropout(out,training=self.training))\n",
    "        return out\n",
    "    \n",
    "em=EnsembleModel(2)\n",
    "if is_cuda:\n",
    "    em=em.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练和验证模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epoch,model,data_loader,phase='training',volatile=False,dataset_size=23000):\n",
    "    if phase == 'training':\n",
    "        model.train()\n",
    "    if phase == 'validation':\n",
    "        model.eval()\n",
    "        volatile=True\n",
    "    running_loss=0.0\n",
    "    running_correct=0\n",
    "    for batch_idx,(data1,data2,data3,target) in enumerate(data_loader):\n",
    "        if is_cuda:\n",
    "            data1,data2,data3,target=data1.cuda(),data2.cuda(),data3.cuda(),target.cuda()\n",
    "        data1,data2,data3,target=Variable(data1,volatile),Variable(data2,volatile),Variable(data3,volatile),Variable(target)\n",
    "        \n",
    "        if phase =='training':\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        output=model(data1,data2,data3)\n",
    "        loss=loss_fn(output,target)\n",
    "        running_loss+=loss_fn(output,target).data\n",
    "        preds=output.data.max(dim=1,keepdim=True)[1]\n",
    "        running_correct+=preds.eq(target.data.view_as(preds)).cpu().sum()\n",
    "        if phase == 'training':\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    loss=running_loss/dataset_size\n",
    "    accuracy=100.*running_correct/dataset_size\n",
    "    print(f'{phase} loss is {loss} and {phase} accuracy is {running_correct}/{dataset_size}{accuracy}')\n",
    "    return loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses,train_accuracy=[],[]\n",
    "val_losses,val_accuracy=[],[]\n",
    "\n",
    "for epoch in range(1,10):\n",
    "    epoch_loss,epoch_accuracy=fit(epoch,em,trn_fea_loader,phase='training')\n",
    "    val_epoch_loss,val_epoch_accuracy=fit(epoch,em,val_fea_loader,phase='validation')\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracy.append(epoch_accuracy)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyenv] *",
   "language": "python",
   "name": "conda-env-pyenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
