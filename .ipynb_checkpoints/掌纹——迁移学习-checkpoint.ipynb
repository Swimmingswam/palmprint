{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# 定义是否使用GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "EPOCH = 10   #遍历数据集次数\n",
    "pre_epoch = 0  # 定义已经遍历数据集的次数\n",
    "BATCH_SIZE = 10   #批处理尺寸(batch_size)\n",
    "LR = 0.0001        #学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据集并预处理\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,imageFolderDataset,transform=None,should_invert=True):\n",
    "        self.imgs = imageFolderDataset.imgs    \n",
    "        self.transform = transform\n",
    "        self.should_invert = should_invert\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        fn, label = self.imgs[index]\n",
    "        #print(fn)   图片地址\n",
    "        #print(label)   图片类别，cat=0，dog=1\n",
    "        img = Image.open(fn).convert('RGB')\n",
    "             \n",
    "        if self.should_invert:\n",
    "            img = PIL.ImageOps.invert(img)   #invert：图片取反\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img) \n",
    "            \n",
    "        return img, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "transform = transforms.Compose([transforms.CenterCrop(128),\n",
    "                                transforms.ToTensor()\n",
    "                                ])\n",
    "\n",
    "train_dir = 'D:\\数据库\\palmdata\\iitd'\n",
    "\n",
    "train_dataset=torchvision.datasets.ImageFolder(root=train_dir)\n",
    "\n",
    "training_set=MyDataset(imageFolderDataset=train_dataset,transform=transform,should_invert=False)\n",
    "\n",
    "training_loader = DataLoader(training_set,shuffle=True,batch_size=BATCH_SIZE,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(training_loader))[0].shape)  #torch.Size([128, 3, 128, 128])\n",
    "print(next(iter(training_loader))[1].shape)  #torch.Size([128])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[331  90  27 358 268  94]\n"
     ]
    }
   ],
   "source": [
    "def show_img(img0,title=None):\n",
    "    img=img0.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if title:\n",
    "        plt.text(75, 8, text, style='italic',fontweight='bold',bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "    plt.imshow(np.transpose(img,(1,2,0)))\n",
    "    plt.show()\n",
    "    \n",
    "visual_dataloader=DataLoader(training_set,shuffle=True,batch_size=6)\n",
    "x,y=next(iter(visual_dataloader)) \n",
    "show_img(torchvision.utils.make_grid(x, nrow=6))\n",
    "print(y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 调用与训练的vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGGNet(\n",
      "  (features): VGG(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (1): ReLU(inplace)\n",
      "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (3): ReLU(inplace)\n",
      "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (6): ReLU(inplace)\n",
      "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (8): ReLU(inplace)\n",
      "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (11): ReLU(inplace)\n",
      "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (13): ReLU(inplace)\n",
      "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (15): ReLU(inplace)\n",
      "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (18): ReLU(inplace)\n",
      "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (20): ReLU(inplace)\n",
      "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (22): ReLU(inplace)\n",
      "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (25): ReLU(inplace)\n",
      "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (27): ReLU(inplace)\n",
      "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (29): ReLU(inplace)\n",
      "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "    (classifier): Sequential()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=1024, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.3)\n",
      "    (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.3)\n",
      "    (6): Linear(in_features=1024, out_features=460, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class VGGNet(nn.Module):\n",
    "    def __init__(self, num_classes=460):   # num_classes，此处为 二分类值为2\n",
    "        super(VGGNet, self).__init__()\n",
    "        net = models.vgg16(pretrained=True)   # 从预训练模型加载VGG16网络参数\n",
    "        net.classifier = nn.Sequential()  # 将分类层置空，下面将改变我们的分类层\n",
    "        self.features = net  # 保留VGG16的特征层\n",
    "        self.classifier = nn.Sequential(    # 定义自己的分类层\n",
    "                nn.Linear(512 * 7 * 7, 1024),  #512 * 7 * 7不能改变 ，由VGG16网络决定的，第二个参数为神经元个数可以微调\n",
    "                nn.ReLU(True),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(1024, 1024),\n",
    "                nn.ReLU(True),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(1024, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x) # 预训练提供的提取特征的部分\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x) # 自定义的分类部分\n",
    "        return x\n",
    "net = VGGNet().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Iterable\n",
    "def set_freeze_by_names(model, layer_names, freeze=True):\n",
    "    if not isinstance(layer_names, Iterable):\n",
    "        layer_names = [layer_names]\n",
    "    for name, child in model.named_children():\n",
    "        if name not in layer_names:\n",
    "            continue\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = not freeze\n",
    "\n",
    "def freeze_by_names(model, layer_names):   #冻结某层\n",
    "    set_freeze_by_names(model, layer_names, True)\n",
    "\n",
    "def unfreeze_by_names(model, layer_names):  #解冻某层\n",
    "    set_freeze_by_names(model, layer_names, False)\n",
    "    \n",
    "freeze_by_names(net,['features','avgpool','classifier'])\n",
    "unfreeze_by_names(net,'classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = []\n",
    "y_true = []\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training!\n",
      "\n",
      "Epoch: 1\n",
      "[epoch:1, iter:1] Loss: 6.122 | Acc: 10.000% \n",
      "[epoch:1, iter:2] Loss: 6.136 | Acc: 5.000% \n",
      "[epoch:1, iter:3] Loss: 6.144 | Acc: 3.333% \n",
      "[epoch:1, iter:4] Loss: 6.128 | Acc: 2.500% \n",
      "[epoch:1, iter:5] Loss: 6.128 | Acc: 2.000% \n",
      "[epoch:1, iter:6] Loss: 6.135 | Acc: 1.667% \n",
      "[epoch:1, iter:7] Loss: 6.130 | Acc: 2.857% \n",
      "[epoch:1, iter:8] Loss: 6.126 | Acc: 2.500% \n",
      "[epoch:1, iter:9] Loss: 6.129 | Acc: 2.222% \n",
      "[epoch:1, iter:10] Loss: 6.124 | Acc: 2.000% \n",
      "[epoch:1, iter:11] Loss: 6.131 | Acc: 1.818% \n",
      "[epoch:1, iter:12] Loss: 6.130 | Acc: 2.500% \n",
      "[epoch:1, iter:13] Loss: 6.129 | Acc: 2.308% \n",
      "[epoch:1, iter:14] Loss: 6.133 | Acc: 2.143% \n",
      "[epoch:1, iter:15] Loss: 6.138 | Acc: 2.000% \n",
      "[epoch:1, iter:16] Loss: 6.138 | Acc: 1.875% \n",
      "[epoch:1, iter:17] Loss: 6.142 | Acc: 1.765% \n",
      "[epoch:1, iter:18] Loss: 6.149 | Acc: 1.667% \n",
      "[epoch:1, iter:19] Loss: 6.149 | Acc: 1.579% \n",
      "[epoch:1, iter:20] Loss: 6.150 | Acc: 1.500% \n",
      "[epoch:1, iter:21] Loss: 6.150 | Acc: 1.429% \n",
      "[epoch:1, iter:22] Loss: 6.157 | Acc: 1.364% \n",
      "[epoch:1, iter:23] Loss: 6.151 | Acc: 1.304% \n",
      "[epoch:1, iter:24] Loss: 6.151 | Acc: 1.250% \n",
      "[epoch:1, iter:25] Loss: 6.154 | Acc: 1.200% \n",
      "[epoch:1, iter:26] Loss: 6.157 | Acc: 1.154% \n",
      "[epoch:1, iter:27] Loss: 6.160 | Acc: 1.111% \n",
      "[epoch:1, iter:28] Loss: 6.165 | Acc: 1.071% \n",
      "[epoch:1, iter:29] Loss: 6.165 | Acc: 1.034% \n",
      "[epoch:1, iter:30] Loss: 6.167 | Acc: 1.000% \n",
      "[epoch:1, iter:31] Loss: 6.165 | Acc: 0.968% \n",
      "[epoch:1, iter:32] Loss: 6.164 | Acc: 0.938% \n",
      "[epoch:1, iter:33] Loss: 6.163 | Acc: 0.909% \n",
      "[epoch:1, iter:34] Loss: 6.165 | Acc: 0.882% \n",
      "[epoch:1, iter:35] Loss: 6.171 | Acc: 0.857% \n",
      "[epoch:1, iter:36] Loss: 6.172 | Acc: 0.833% \n",
      "[epoch:1, iter:37] Loss: 6.171 | Acc: 0.811% \n",
      "[epoch:1, iter:38] Loss: 6.170 | Acc: 0.789% \n",
      "[epoch:1, iter:39] Loss: 6.173 | Acc: 0.769% \n",
      "[epoch:1, iter:40] Loss: 6.179 | Acc: 0.750% \n",
      "[epoch:1, iter:41] Loss: 6.178 | Acc: 0.732% \n",
      "[epoch:1, iter:42] Loss: 6.180 | Acc: 0.714% \n",
      "[epoch:1, iter:43] Loss: 6.179 | Acc: 0.698% \n",
      "[epoch:1, iter:44] Loss: 6.179 | Acc: 0.682% \n",
      "[epoch:1, iter:45] Loss: 6.176 | Acc: 0.667% \n",
      "[epoch:1, iter:46] Loss: 6.175 | Acc: 0.652% \n",
      "[epoch:1, iter:47] Loss: 6.178 | Acc: 0.638% \n",
      "[epoch:1, iter:48] Loss: 6.177 | Acc: 0.833% \n",
      "[epoch:1, iter:49] Loss: 6.177 | Acc: 1.020% \n",
      "[epoch:1, iter:50] Loss: 6.176 | Acc: 1.000% \n",
      "[epoch:1, iter:51] Loss: 6.175 | Acc: 0.980% \n",
      "[epoch:1, iter:52] Loss: 6.176 | Acc: 0.962% \n",
      "[epoch:1, iter:53] Loss: 6.176 | Acc: 0.943% \n",
      "[epoch:1, iter:54] Loss: 6.175 | Acc: 0.926% \n",
      "[epoch:1, iter:55] Loss: 6.177 | Acc: 0.909% \n",
      "[epoch:1, iter:56] Loss: 6.174 | Acc: 0.893% \n",
      "[epoch:1, iter:57] Loss: 6.174 | Acc: 0.877% \n",
      "[epoch:1, iter:58] Loss: 6.173 | Acc: 0.862% \n",
      "[epoch:1, iter:59] Loss: 6.173 | Acc: 0.847% \n",
      "[epoch:1, iter:60] Loss: 6.174 | Acc: 0.833% \n",
      "[epoch:1, iter:61] Loss: 6.174 | Acc: 0.820% \n",
      "[epoch:1, iter:62] Loss: 6.175 | Acc: 0.806% \n",
      "[epoch:1, iter:63] Loss: 6.174 | Acc: 0.794% \n",
      "[epoch:1, iter:64] Loss: 6.171 | Acc: 0.781% \n",
      "[epoch:1, iter:65] Loss: 6.171 | Acc: 0.769% \n",
      "[epoch:1, iter:66] Loss: 6.171 | Acc: 0.758% \n",
      "[epoch:1, iter:67] Loss: 6.170 | Acc: 0.746% \n",
      "[epoch:1, iter:68] Loss: 6.171 | Acc: 0.735% \n",
      "[epoch:1, iter:69] Loss: 6.169 | Acc: 0.725% \n",
      "[epoch:1, iter:70] Loss: 6.170 | Acc: 0.714% \n",
      "[epoch:1, iter:71] Loss: 6.170 | Acc: 0.704% \n",
      "[epoch:1, iter:72] Loss: 6.169 | Acc: 0.694% \n",
      "[epoch:1, iter:73] Loss: 6.170 | Acc: 0.685% \n",
      "[epoch:1, iter:74] Loss: 6.171 | Acc: 0.676% \n",
      "[epoch:1, iter:75] Loss: 6.170 | Acc: 0.667% \n",
      "[epoch:1, iter:76] Loss: 6.169 | Acc: 0.658% \n",
      "[epoch:1, iter:77] Loss: 6.168 | Acc: 0.779% \n",
      "[epoch:1, iter:78] Loss: 6.167 | Acc: 0.769% \n",
      "[epoch:1, iter:79] Loss: 6.168 | Acc: 0.759% \n",
      "[epoch:1, iter:80] Loss: 6.166 | Acc: 0.750% \n",
      "[epoch:1, iter:81] Loss: 6.165 | Acc: 0.741% \n",
      "[epoch:1, iter:82] Loss: 6.165 | Acc: 0.732% \n",
      "[epoch:1, iter:83] Loss: 6.163 | Acc: 0.843% \n",
      "[epoch:1, iter:84] Loss: 6.163 | Acc: 0.833% \n",
      "[epoch:1, iter:85] Loss: 6.164 | Acc: 0.824% \n",
      "[epoch:1, iter:86] Loss: 6.163 | Acc: 0.814% \n",
      "[epoch:1, iter:87] Loss: 6.163 | Acc: 0.805% \n",
      "[epoch:1, iter:88] Loss: 6.162 | Acc: 0.795% \n",
      "[epoch:1, iter:89] Loss: 6.162 | Acc: 0.787% \n",
      "[epoch:1, iter:90] Loss: 6.162 | Acc: 0.778% \n",
      "[epoch:1, iter:91] Loss: 6.162 | Acc: 0.769% \n",
      "[epoch:1, iter:92] Loss: 6.164 | Acc: 0.761% \n",
      "[epoch:1, iter:93] Loss: 6.166 | Acc: 0.753% \n",
      "[epoch:1, iter:94] Loss: 6.165 | Acc: 0.745% \n",
      "[epoch:1, iter:95] Loss: 6.163 | Acc: 0.737% \n",
      "[epoch:1, iter:96] Loss: 6.163 | Acc: 0.729% \n",
      "[epoch:1, iter:97] Loss: 6.164 | Acc: 0.722% \n",
      "[epoch:1, iter:98] Loss: 6.164 | Acc: 0.714% \n",
      "[epoch:1, iter:99] Loss: 6.164 | Acc: 0.707% \n",
      "[epoch:1, iter:100] Loss: 6.164 | Acc: 0.700% \n",
      "[epoch:1, iter:101] Loss: 6.165 | Acc: 0.693% \n",
      "[epoch:1, iter:102] Loss: 6.164 | Acc: 0.686% \n",
      "[epoch:1, iter:103] Loss: 6.164 | Acc: 0.680% \n",
      "[epoch:1, iter:104] Loss: 6.164 | Acc: 0.673% \n",
      "[epoch:1, iter:105] Loss: 6.164 | Acc: 0.667% \n",
      "[epoch:1, iter:106] Loss: 6.165 | Acc: 0.660% \n",
      "[epoch:1, iter:107] Loss: 6.165 | Acc: 0.654% \n",
      "[epoch:1, iter:108] Loss: 6.164 | Acc: 0.648% \n",
      "[epoch:1, iter:109] Loss: 6.164 | Acc: 0.642% \n",
      "[epoch:1, iter:110] Loss: 6.164 | Acc: 0.636% \n",
      "[epoch:1, iter:111] Loss: 6.164 | Acc: 0.631% \n",
      "[epoch:1, iter:112] Loss: 6.163 | Acc: 0.625% \n",
      "[epoch:1, iter:113] Loss: 6.162 | Acc: 0.619% \n",
      "[epoch:1, iter:114] Loss: 6.161 | Acc: 0.614% \n",
      "[epoch:1, iter:115] Loss: 6.160 | Acc: 0.696% \n",
      "[epoch:1, iter:116] Loss: 6.160 | Acc: 0.690% \n",
      "[epoch:1, iter:117] Loss: 6.159 | Acc: 0.684% \n",
      "[epoch:1, iter:118] Loss: 6.159 | Acc: 0.678% \n",
      "[epoch:1, iter:119] Loss: 6.158 | Acc: 0.672% \n",
      "[epoch:1, iter:120] Loss: 6.159 | Acc: 0.667% \n",
      "[epoch:1, iter:121] Loss: 6.158 | Acc: 0.661% \n",
      "[epoch:1, iter:122] Loss: 6.157 | Acc: 0.656% \n",
      "[epoch:1, iter:123] Loss: 6.158 | Acc: 0.650% \n",
      "[epoch:1, iter:124] Loss: 6.159 | Acc: 0.645% \n",
      "[epoch:1, iter:125] Loss: 6.158 | Acc: 0.640% \n",
      "[epoch:1, iter:126] Loss: 6.158 | Acc: 0.635% \n",
      "[epoch:1, iter:127] Loss: 6.158 | Acc: 0.630% \n",
      "[epoch:1, iter:128] Loss: 6.158 | Acc: 0.625% \n",
      "[epoch:1, iter:129] Loss: 6.158 | Acc: 0.620% \n",
      "[epoch:1, iter:130] Loss: 6.158 | Acc: 0.615% \n",
      "[epoch:1, iter:131] Loss: 6.157 | Acc: 0.611% \n",
      "[epoch:1, iter:132] Loss: 6.158 | Acc: 0.606% \n",
      "[epoch:1, iter:133] Loss: 6.158 | Acc: 0.602% \n",
      "[epoch:1, iter:134] Loss: 6.158 | Acc: 0.597% \n",
      "[epoch:1, iter:135] Loss: 6.157 | Acc: 0.593% \n",
      "[epoch:1, iter:136] Loss: 6.157 | Acc: 0.588% \n",
      "[epoch:1, iter:137] Loss: 6.157 | Acc: 0.584% \n",
      "[epoch:1, iter:138] Loss: 6.156 | Acc: 0.580% \n",
      "[epoch:1, iter:139] Loss: 6.155 | Acc: 0.576% \n",
      "[epoch:1, iter:140] Loss: 6.155 | Acc: 0.643% \n",
      "[epoch:1, iter:141] Loss: 6.155 | Acc: 0.638% \n",
      "[epoch:1, iter:142] Loss: 6.155 | Acc: 0.634% \n",
      "[epoch:1, iter:143] Loss: 6.155 | Acc: 0.629% \n",
      "[epoch:1, iter:144] Loss: 6.155 | Acc: 0.625% \n",
      "[epoch:1, iter:145] Loss: 6.155 | Acc: 0.621% \n",
      "[epoch:1, iter:146] Loss: 6.155 | Acc: 0.616% \n",
      "[epoch:1, iter:147] Loss: 6.154 | Acc: 0.612% \n",
      "[epoch:1, iter:148] Loss: 6.154 | Acc: 0.608% \n",
      "[epoch:1, iter:149] Loss: 6.153 | Acc: 0.604% \n",
      "[epoch:1, iter:150] Loss: 6.153 | Acc: 0.600% \n",
      "[epoch:1, iter:151] Loss: 6.152 | Acc: 0.596% \n",
      "[epoch:1, iter:152] Loss: 6.152 | Acc: 0.592% \n",
      "[epoch:1, iter:153] Loss: 6.152 | Acc: 0.588% \n",
      "[epoch:1, iter:154] Loss: 6.152 | Acc: 0.584% \n",
      "[epoch:1, iter:155] Loss: 6.152 | Acc: 0.581% \n",
      "[epoch:1, iter:156] Loss: 6.152 | Acc: 0.577% \n",
      "[epoch:1, iter:157] Loss: 6.151 | Acc: 0.637% \n",
      "[epoch:1, iter:158] Loss: 6.151 | Acc: 0.633% \n",
      "[epoch:1, iter:159] Loss: 6.151 | Acc: 0.629% \n",
      "[epoch:1, iter:160] Loss: 6.151 | Acc: 0.625% \n",
      "[epoch:1, iter:161] Loss: 6.150 | Acc: 0.621% \n",
      "[epoch:1, iter:162] Loss: 6.150 | Acc: 0.617% \n",
      "[epoch:1, iter:163] Loss: 6.150 | Acc: 0.613% \n",
      "[epoch:1, iter:164] Loss: 6.149 | Acc: 0.671% \n",
      "[epoch:1, iter:165] Loss: 6.148 | Acc: 0.667% \n",
      "[epoch:1, iter:166] Loss: 6.148 | Acc: 0.663% \n",
      "[epoch:1, iter:167] Loss: 6.147 | Acc: 0.659% \n",
      "[epoch:1, iter:168] Loss: 6.147 | Acc: 0.655% \n",
      "[epoch:1, iter:169] Loss: 6.146 | Acc: 0.651% \n",
      "[epoch:1, iter:170] Loss: 6.146 | Acc: 0.706% \n",
      "[epoch:1, iter:171] Loss: 6.146 | Acc: 0.702% \n",
      "[epoch:1, iter:172] Loss: 6.146 | Acc: 0.698% \n",
      "[epoch:1, iter:173] Loss: 6.145 | Acc: 0.694% \n",
      "[epoch:1, iter:174] Loss: 6.145 | Acc: 0.690% \n",
      "[epoch:1, iter:175] Loss: 6.145 | Acc: 0.686% \n",
      "[epoch:1, iter:176] Loss: 6.145 | Acc: 0.682% \n",
      "[epoch:1, iter:177] Loss: 6.145 | Acc: 0.678% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:1, iter:178] Loss: 6.145 | Acc: 0.674% \n",
      "[epoch:1, iter:179] Loss: 6.144 | Acc: 0.670% \n",
      "[epoch:1, iter:180] Loss: 6.145 | Acc: 0.667% \n",
      "[epoch:1, iter:181] Loss: 6.144 | Acc: 0.663% \n",
      "[epoch:1, iter:182] Loss: 6.144 | Acc: 0.659% \n",
      "[epoch:1, iter:183] Loss: 6.144 | Acc: 0.656% \n",
      "[epoch:1, iter:184] Loss: 6.144 | Acc: 0.652% \n",
      "[epoch:1, iter:185] Loss: 6.144 | Acc: 0.649% \n",
      "[epoch:1, iter:186] Loss: 6.144 | Acc: 0.645% \n",
      "[epoch:1, iter:187] Loss: 6.143 | Acc: 0.642% \n",
      "[epoch:1, iter:188] Loss: 6.143 | Acc: 0.638% \n",
      "[epoch:1, iter:189] Loss: 6.143 | Acc: 0.635% \n",
      "[epoch:1, iter:190] Loss: 6.144 | Acc: 0.632% \n",
      "[epoch:1, iter:191] Loss: 6.144 | Acc: 0.628% \n",
      "[epoch:1, iter:192] Loss: 6.144 | Acc: 0.625% \n",
      "[epoch:1, iter:193] Loss: 6.144 | Acc: 0.622% \n",
      "[epoch:1, iter:194] Loss: 6.143 | Acc: 0.619% \n",
      "[epoch:1, iter:195] Loss: 6.143 | Acc: 0.615% \n",
      "[epoch:1, iter:196] Loss: 6.143 | Acc: 0.612% \n",
      "[epoch:1, iter:197] Loss: 6.143 | Acc: 0.609% \n",
      "[epoch:1, iter:198] Loss: 6.143 | Acc: 0.606% \n",
      "[epoch:1, iter:199] Loss: 6.143 | Acc: 0.603% \n",
      "[epoch:1, iter:200] Loss: 6.143 | Acc: 0.600% \n",
      "[epoch:1, iter:201] Loss: 6.142 | Acc: 0.647% \n",
      "[epoch:1, iter:202] Loss: 6.142 | Acc: 0.644% \n",
      "[epoch:1, iter:203] Loss: 6.141 | Acc: 0.640% \n",
      "[epoch:1, iter:204] Loss: 6.142 | Acc: 0.637% \n",
      "[epoch:1, iter:205] Loss: 6.141 | Acc: 0.634% \n",
      "[epoch:1, iter:206] Loss: 6.141 | Acc: 0.631% \n",
      "[epoch:1, iter:207] Loss: 6.141 | Acc: 0.628% \n",
      "[epoch:1, iter:208] Loss: 6.141 | Acc: 0.625% \n",
      "[epoch:1, iter:209] Loss: 6.141 | Acc: 0.622% \n",
      "[epoch:1, iter:210] Loss: 6.141 | Acc: 0.619% \n",
      "[epoch:1, iter:211] Loss: 6.141 | Acc: 0.664% \n",
      "[epoch:1, iter:212] Loss: 6.141 | Acc: 0.660% \n",
      "[epoch:1, iter:213] Loss: 6.140 | Acc: 0.657% \n",
      "[epoch:1, iter:214] Loss: 6.140 | Acc: 0.654% \n",
      "[epoch:1, iter:215] Loss: 6.140 | Acc: 0.651% \n",
      "[epoch:1, iter:216] Loss: 6.140 | Acc: 0.648% \n",
      "[epoch:1, iter:217] Loss: 6.140 | Acc: 0.691% \n",
      "[epoch:1, iter:218] Loss: 6.139 | Acc: 0.688% \n",
      "[epoch:1, iter:219] Loss: 6.139 | Acc: 0.685% \n",
      "[epoch:1, iter:220] Loss: 6.139 | Acc: 0.727% \n",
      "[epoch:1, iter:221] Loss: 6.138 | Acc: 0.724% \n",
      "[epoch:1, iter:222] Loss: 6.138 | Acc: 0.721% \n",
      "[epoch:1, iter:223] Loss: 6.138 | Acc: 0.717% \n",
      "[epoch:1, iter:224] Loss: 6.138 | Acc: 0.714% \n",
      "[epoch:1, iter:225] Loss: 6.138 | Acc: 0.756% \n",
      "[epoch:1, iter:226] Loss: 6.137 | Acc: 0.752% \n",
      "[epoch:1, iter:227] Loss: 6.137 | Acc: 0.749% \n",
      "[epoch:1, iter:228] Loss: 6.136 | Acc: 0.746% \n",
      "[epoch:1, iter:229] Loss: 6.136 | Acc: 0.742% \n",
      "[epoch:1, iter:230] Loss: 6.135 | Acc: 0.739% \n",
      "[epoch:1, iter:231] Loss: 6.135 | Acc: 0.736% \n",
      "[epoch:1, iter:232] Loss: 6.135 | Acc: 0.733% \n",
      "[epoch:1, iter:233] Loss: 6.135 | Acc: 0.730% \n",
      "[epoch:1, iter:234] Loss: 6.135 | Acc: 0.726% \n",
      "[epoch:1, iter:235] Loss: 6.135 | Acc: 0.723% \n",
      "[epoch:1, iter:236] Loss: 6.135 | Acc: 0.720% \n",
      "[epoch:1, iter:237] Loss: 6.135 | Acc: 0.717% \n",
      "[epoch:1, iter:238] Loss: 6.135 | Acc: 0.714% \n",
      "[epoch:1, iter:239] Loss: 6.135 | Acc: 0.711% \n",
      "[epoch:1, iter:240] Loss: 6.135 | Acc: 0.708% \n",
      "[epoch:1, iter:241] Loss: 6.135 | Acc: 0.705% \n",
      "[epoch:1, iter:242] Loss: 6.135 | Acc: 0.702% \n",
      "[epoch:1, iter:243] Loss: 6.135 | Acc: 0.700% \n",
      "[epoch:1, iter:244] Loss: 6.134 | Acc: 0.697% \n",
      "[epoch:1, iter:245] Loss: 6.134 | Acc: 0.694% \n",
      "[epoch:1, iter:246] Loss: 6.134 | Acc: 0.732% \n",
      "[epoch:1, iter:247] Loss: 6.133 | Acc: 0.729% \n",
      "[epoch:1, iter:248] Loss: 6.133 | Acc: 0.726% \n",
      "[epoch:1, iter:249] Loss: 6.133 | Acc: 0.723% \n",
      "[epoch:1, iter:250] Loss: 6.133 | Acc: 0.720% \n",
      "[epoch:1, iter:251] Loss: 6.132 | Acc: 0.717% \n",
      "[epoch:1, iter:252] Loss: 6.132 | Acc: 0.794% \n",
      "[epoch:1, iter:253] Loss: 6.131 | Acc: 0.830% \n",
      "[epoch:1, iter:254] Loss: 6.131 | Acc: 0.827% \n",
      "[epoch:1, iter:255] Loss: 6.131 | Acc: 0.824% \n",
      "[epoch:1, iter:256] Loss: 6.130 | Acc: 0.820% \n",
      "[epoch:1, iter:257] Loss: 6.130 | Acc: 0.817% \n",
      "[epoch:1, iter:258] Loss: 6.130 | Acc: 0.814% \n",
      "[epoch:1, iter:259] Loss: 6.130 | Acc: 0.811% \n",
      "[epoch:1, iter:260] Loss: 6.129 | Acc: 0.808% \n",
      "[epoch:1, iter:261] Loss: 6.129 | Acc: 0.807% \n",
      "\n",
      "Epoch: 2\n",
      "[epoch:2, iter:262] Loss: 5.898 | Acc: 10.000% \n",
      "[epoch:2, iter:263] Loss: 5.905 | Acc: 5.000% \n",
      "[epoch:2, iter:264] Loss: 5.876 | Acc: 6.667% \n",
      "[epoch:2, iter:265] Loss: 5.895 | Acc: 5.000% \n",
      "[epoch:2, iter:266] Loss: 5.911 | Acc: 4.000% \n",
      "[epoch:2, iter:267] Loss: 5.916 | Acc: 3.333% \n",
      "[epoch:2, iter:268] Loss: 5.913 | Acc: 4.286% \n",
      "[epoch:2, iter:269] Loss: 5.920 | Acc: 5.000% \n",
      "[epoch:2, iter:270] Loss: 5.914 | Acc: 4.444% \n",
      "[epoch:2, iter:271] Loss: 5.922 | Acc: 4.000% \n",
      "[epoch:2, iter:272] Loss: 5.927 | Acc: 3.636% \n",
      "[epoch:2, iter:273] Loss: 5.911 | Acc: 4.167% \n",
      "[epoch:2, iter:274] Loss: 5.891 | Acc: 5.385% \n",
      "[epoch:2, iter:275] Loss: 5.882 | Acc: 6.429% \n",
      "[epoch:2, iter:276] Loss: 5.877 | Acc: 6.000% \n",
      "[epoch:2, iter:277] Loss: 5.878 | Acc: 5.625% \n",
      "[epoch:2, iter:278] Loss: 5.889 | Acc: 5.294% \n",
      "[epoch:2, iter:279] Loss: 5.877 | Acc: 5.556% \n",
      "[epoch:2, iter:280] Loss: 5.860 | Acc: 5.789% \n",
      "[epoch:2, iter:281] Loss: 5.866 | Acc: 5.500% \n",
      "[epoch:2, iter:282] Loss: 5.872 | Acc: 5.238% \n",
      "[epoch:2, iter:283] Loss: 5.868 | Acc: 5.000% \n",
      "[epoch:2, iter:284] Loss: 5.878 | Acc: 4.783% \n",
      "[epoch:2, iter:285] Loss: 5.882 | Acc: 4.583% \n",
      "[epoch:2, iter:286] Loss: 5.884 | Acc: 4.400% \n",
      "[epoch:2, iter:287] Loss: 5.886 | Acc: 4.231% \n",
      "[epoch:2, iter:288] Loss: 5.880 | Acc: 4.074% \n",
      "[epoch:2, iter:289] Loss: 5.887 | Acc: 3.929% \n",
      "[epoch:2, iter:290] Loss: 5.894 | Acc: 3.793% \n",
      "[epoch:2, iter:291] Loss: 5.889 | Acc: 3.667% \n",
      "[epoch:2, iter:292] Loss: 5.887 | Acc: 3.871% \n",
      "[epoch:2, iter:293] Loss: 5.880 | Acc: 4.062% \n",
      "[epoch:2, iter:294] Loss: 5.878 | Acc: 3.939% \n",
      "[epoch:2, iter:295] Loss: 5.879 | Acc: 3.824% \n",
      "[epoch:2, iter:296] Loss: 5.877 | Acc: 4.000% \n",
      "[epoch:2, iter:297] Loss: 5.882 | Acc: 3.889% \n",
      "[epoch:2, iter:298] Loss: 5.875 | Acc: 4.054% \n",
      "[epoch:2, iter:299] Loss: 5.874 | Acc: 3.947% \n",
      "[epoch:2, iter:300] Loss: 5.883 | Acc: 3.846% \n",
      "[epoch:2, iter:301] Loss: 5.884 | Acc: 3.750% \n",
      "[epoch:2, iter:302] Loss: 5.880 | Acc: 3.902% \n",
      "[epoch:2, iter:303] Loss: 5.871 | Acc: 4.048% \n",
      "[epoch:2, iter:304] Loss: 5.869 | Acc: 3.953% \n",
      "[epoch:2, iter:305] Loss: 5.866 | Acc: 4.091% \n",
      "[epoch:2, iter:306] Loss: 5.868 | Acc: 4.000% \n",
      "[epoch:2, iter:307] Loss: 5.868 | Acc: 4.130% \n",
      "[epoch:2, iter:308] Loss: 5.871 | Acc: 4.043% \n",
      "[epoch:2, iter:309] Loss: 5.870 | Acc: 3.958% \n",
      "[epoch:2, iter:310] Loss: 5.860 | Acc: 4.082% \n",
      "[epoch:2, iter:311] Loss: 5.859 | Acc: 4.200% \n",
      "[epoch:2, iter:312] Loss: 5.856 | Acc: 4.118% \n",
      "[epoch:2, iter:313] Loss: 5.848 | Acc: 4.231% \n",
      "[epoch:2, iter:314] Loss: 5.851 | Acc: 4.151% \n",
      "[epoch:2, iter:315] Loss: 5.845 | Acc: 4.259% \n",
      "[epoch:2, iter:316] Loss: 5.844 | Acc: 4.182% \n",
      "[epoch:2, iter:317] Loss: 5.844 | Acc: 4.107% \n",
      "[epoch:2, iter:318] Loss: 5.842 | Acc: 4.211% \n",
      "[epoch:2, iter:319] Loss: 5.845 | Acc: 4.138% \n",
      "[epoch:2, iter:320] Loss: 5.841 | Acc: 4.237% \n",
      "[epoch:2, iter:321] Loss: 5.846 | Acc: 4.167% \n",
      "[epoch:2, iter:322] Loss: 5.833 | Acc: 4.426% \n",
      "[epoch:2, iter:323] Loss: 5.832 | Acc: 4.677% \n",
      "[epoch:2, iter:324] Loss: 5.830 | Acc: 4.603% \n",
      "[epoch:2, iter:325] Loss: 5.827 | Acc: 4.531% \n",
      "[epoch:2, iter:326] Loss: 5.824 | Acc: 4.462% \n",
      "[epoch:2, iter:327] Loss: 5.825 | Acc: 4.394% \n",
      "[epoch:2, iter:328] Loss: 5.826 | Acc: 4.328% \n",
      "[epoch:2, iter:329] Loss: 5.824 | Acc: 4.265% \n",
      "[epoch:2, iter:330] Loss: 5.823 | Acc: 4.203% \n",
      "[epoch:2, iter:331] Loss: 5.815 | Acc: 4.143% \n",
      "[epoch:2, iter:332] Loss: 5.810 | Acc: 4.366% \n",
      "[epoch:2, iter:333] Loss: 5.808 | Acc: 4.306% \n",
      "[epoch:2, iter:334] Loss: 5.810 | Acc: 4.247% \n",
      "[epoch:2, iter:335] Loss: 5.807 | Acc: 4.324% \n",
      "[epoch:2, iter:336] Loss: 5.809 | Acc: 4.267% \n",
      "[epoch:2, iter:337] Loss: 5.811 | Acc: 4.211% \n",
      "[epoch:2, iter:338] Loss: 5.808 | Acc: 4.156% \n",
      "[epoch:2, iter:339] Loss: 5.807 | Acc: 4.103% \n",
      "[epoch:2, iter:340] Loss: 5.804 | Acc: 4.304% \n",
      "[epoch:2, iter:341] Loss: 5.798 | Acc: 4.375% \n",
      "[epoch:2, iter:342] Loss: 5.794 | Acc: 4.568% \n",
      "[epoch:2, iter:343] Loss: 5.794 | Acc: 4.512% \n",
      "[epoch:2, iter:344] Loss: 5.793 | Acc: 4.458% \n",
      "[epoch:2, iter:345] Loss: 5.793 | Acc: 4.405% \n",
      "[epoch:2, iter:346] Loss: 5.789 | Acc: 4.353% \n",
      "[epoch:2, iter:347] Loss: 5.785 | Acc: 4.302% \n",
      "[epoch:2, iter:348] Loss: 5.781 | Acc: 4.368% \n",
      "[epoch:2, iter:349] Loss: 5.783 | Acc: 4.318% \n",
      "[epoch:2, iter:350] Loss: 5.781 | Acc: 4.382% \n",
      "[epoch:2, iter:351] Loss: 5.782 | Acc: 4.333% \n",
      "[epoch:2, iter:352] Loss: 5.781 | Acc: 4.286% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:2, iter:353] Loss: 5.780 | Acc: 4.348% \n",
      "[epoch:2, iter:354] Loss: 5.772 | Acc: 4.409% \n",
      "[epoch:2, iter:355] Loss: 5.769 | Acc: 4.362% \n",
      "[epoch:2, iter:356] Loss: 5.765 | Acc: 4.421% \n",
      "[epoch:2, iter:357] Loss: 5.764 | Acc: 4.375% \n",
      "[epoch:2, iter:358] Loss: 5.764 | Acc: 4.330% \n",
      "[epoch:2, iter:359] Loss: 5.765 | Acc: 4.286% \n",
      "[epoch:2, iter:360] Loss: 5.762 | Acc: 4.242% \n",
      "[epoch:2, iter:361] Loss: 5.761 | Acc: 4.200% \n",
      "[epoch:2, iter:362] Loss: 5.760 | Acc: 4.158% \n",
      "[epoch:2, iter:363] Loss: 5.757 | Acc: 4.314% \n",
      "[epoch:2, iter:364] Loss: 5.758 | Acc: 4.369% \n",
      "[epoch:2, iter:365] Loss: 5.756 | Acc: 4.327% \n",
      "[epoch:2, iter:366] Loss: 5.752 | Acc: 4.286% \n",
      "[epoch:2, iter:367] Loss: 5.752 | Acc: 4.245% \n",
      "[epoch:2, iter:368] Loss: 5.752 | Acc: 4.206% \n",
      "[epoch:2, iter:369] Loss: 5.744 | Acc: 4.352% \n",
      "[epoch:2, iter:370] Loss: 5.739 | Acc: 4.404% \n",
      "[epoch:2, iter:371] Loss: 5.737 | Acc: 4.364% \n",
      "[epoch:2, iter:372] Loss: 5.736 | Acc: 4.324% \n",
      "[epoch:2, iter:373] Loss: 5.735 | Acc: 4.286% \n",
      "[epoch:2, iter:374] Loss: 5.733 | Acc: 4.248% \n",
      "[epoch:2, iter:375] Loss: 5.731 | Acc: 4.211% \n",
      "[epoch:2, iter:376] Loss: 5.727 | Acc: 4.261% \n",
      "[epoch:2, iter:377] Loss: 5.727 | Acc: 4.224% \n",
      "[epoch:2, iter:378] Loss: 5.724 | Acc: 4.188% \n",
      "[epoch:2, iter:379] Loss: 5.721 | Acc: 4.153% \n",
      "[epoch:2, iter:380] Loss: 5.719 | Acc: 4.118% \n",
      "[epoch:2, iter:381] Loss: 5.718 | Acc: 4.083% \n",
      "[epoch:2, iter:382] Loss: 5.712 | Acc: 4.132% \n",
      "[epoch:2, iter:383] Loss: 5.711 | Acc: 4.098% \n",
      "[epoch:2, iter:384] Loss: 5.709 | Acc: 4.065% \n",
      "[epoch:2, iter:385] Loss: 5.707 | Acc: 4.032% \n",
      "[epoch:2, iter:386] Loss: 5.707 | Acc: 4.080% \n",
      "[epoch:2, iter:387] Loss: 5.704 | Acc: 4.127% \n",
      "[epoch:2, iter:388] Loss: 5.701 | Acc: 4.094% \n",
      "[epoch:2, iter:389] Loss: 5.699 | Acc: 4.141% \n",
      "[epoch:2, iter:390] Loss: 5.699 | Acc: 4.109% \n",
      "[epoch:2, iter:391] Loss: 5.696 | Acc: 4.154% \n",
      "[epoch:2, iter:392] Loss: 5.695 | Acc: 4.122% \n",
      "[epoch:2, iter:393] Loss: 5.690 | Acc: 4.167% \n",
      "[epoch:2, iter:394] Loss: 5.687 | Acc: 4.286% \n",
      "[epoch:2, iter:395] Loss: 5.687 | Acc: 4.254% \n",
      "[epoch:2, iter:396] Loss: 5.683 | Acc: 4.444% \n",
      "[epoch:2, iter:397] Loss: 5.678 | Acc: 4.412% \n",
      "[epoch:2, iter:398] Loss: 5.677 | Acc: 4.453% \n",
      "[epoch:2, iter:399] Loss: 5.673 | Acc: 4.493% \n",
      "[epoch:2, iter:400] Loss: 5.670 | Acc: 4.460% \n",
      "[epoch:2, iter:401] Loss: 5.670 | Acc: 4.429% \n",
      "[epoch:2, iter:402] Loss: 5.670 | Acc: 4.397% \n",
      "[epoch:2, iter:403] Loss: 5.668 | Acc: 4.366% \n",
      "[epoch:2, iter:404] Loss: 5.663 | Acc: 4.476% \n",
      "[epoch:2, iter:405] Loss: 5.663 | Acc: 4.444% \n",
      "[epoch:2, iter:406] Loss: 5.660 | Acc: 4.414% \n",
      "[epoch:2, iter:407] Loss: 5.658 | Acc: 4.521% \n",
      "[epoch:2, iter:408] Loss: 5.657 | Acc: 4.490% \n",
      "[epoch:2, iter:409] Loss: 5.653 | Acc: 4.527% \n",
      "[epoch:2, iter:410] Loss: 5.651 | Acc: 4.564% \n",
      "[epoch:2, iter:411] Loss: 5.649 | Acc: 4.600% \n",
      "[epoch:2, iter:412] Loss: 5.644 | Acc: 4.636% \n",
      "[epoch:2, iter:413] Loss: 5.641 | Acc: 4.605% \n",
      "[epoch:2, iter:414] Loss: 5.638 | Acc: 4.575% \n",
      "[epoch:2, iter:415] Loss: 5.635 | Acc: 4.545% \n",
      "[epoch:2, iter:416] Loss: 5.633 | Acc: 4.516% \n",
      "[epoch:2, iter:417] Loss: 5.631 | Acc: 4.551% \n",
      "[epoch:2, iter:418] Loss: 5.628 | Acc: 4.586% \n",
      "[epoch:2, iter:419] Loss: 5.627 | Acc: 4.557% \n",
      "[epoch:2, iter:420] Loss: 5.623 | Acc: 4.654% \n",
      "[epoch:2, iter:421] Loss: 5.617 | Acc: 4.812% \n",
      "[epoch:2, iter:422] Loss: 5.619 | Acc: 4.783% \n",
      "[epoch:2, iter:423] Loss: 5.610 | Acc: 4.877% \n",
      "[epoch:2, iter:424] Loss: 5.606 | Acc: 5.031% \n",
      "[epoch:2, iter:425] Loss: 5.600 | Acc: 5.122% \n",
      "[epoch:2, iter:426] Loss: 5.601 | Acc: 5.091% \n",
      "[epoch:2, iter:427] Loss: 5.598 | Acc: 5.241% \n",
      "[epoch:2, iter:428] Loss: 5.598 | Acc: 5.210% \n",
      "[epoch:2, iter:429] Loss: 5.596 | Acc: 5.298% \n",
      "[epoch:2, iter:430] Loss: 5.595 | Acc: 5.266% \n",
      "[epoch:2, iter:431] Loss: 5.592 | Acc: 5.294% \n",
      "[epoch:2, iter:432] Loss: 5.592 | Acc: 5.322% \n",
      "[epoch:2, iter:433] Loss: 5.590 | Acc: 5.291% \n",
      "[epoch:2, iter:434] Loss: 5.588 | Acc: 5.318% \n",
      "[epoch:2, iter:435] Loss: 5.583 | Acc: 5.345% \n",
      "[epoch:2, iter:436] Loss: 5.581 | Acc: 5.371% \n",
      "[epoch:2, iter:437] Loss: 5.580 | Acc: 5.341% \n",
      "[epoch:2, iter:438] Loss: 5.575 | Acc: 5.424% \n",
      "[epoch:2, iter:439] Loss: 5.576 | Acc: 5.449% \n",
      "[epoch:2, iter:440] Loss: 5.574 | Acc: 5.475% \n",
      "[epoch:2, iter:441] Loss: 5.574 | Acc: 5.500% \n",
      "[epoch:2, iter:442] Loss: 5.574 | Acc: 5.470% \n",
      "[epoch:2, iter:443] Loss: 5.571 | Acc: 5.549% \n",
      "[epoch:2, iter:444] Loss: 5.566 | Acc: 5.574% \n",
      "[epoch:2, iter:445] Loss: 5.565 | Acc: 5.543% \n",
      "[epoch:2, iter:446] Loss: 5.565 | Acc: 5.568% \n",
      "[epoch:2, iter:447] Loss: 5.564 | Acc: 5.538% \n",
      "[epoch:2, iter:448] Loss: 5.558 | Acc: 5.615% \n",
      "[epoch:2, iter:449] Loss: 5.554 | Acc: 5.638% \n",
      "[epoch:2, iter:450] Loss: 5.551 | Acc: 5.608% \n",
      "[epoch:2, iter:451] Loss: 5.550 | Acc: 5.579% \n",
      "[epoch:2, iter:452] Loss: 5.549 | Acc: 5.550% \n",
      "[epoch:2, iter:453] Loss: 5.544 | Acc: 5.573% \n",
      "[epoch:2, iter:454] Loss: 5.543 | Acc: 5.544% \n",
      "[epoch:2, iter:455] Loss: 5.540 | Acc: 5.515% \n",
      "[epoch:2, iter:456] Loss: 5.533 | Acc: 5.641% \n",
      "[epoch:2, iter:457] Loss: 5.531 | Acc: 5.663% \n",
      "[epoch:2, iter:458] Loss: 5.531 | Acc: 5.685% \n",
      "[epoch:2, iter:459] Loss: 5.533 | Acc: 5.657% \n",
      "[epoch:2, iter:460] Loss: 5.530 | Acc: 5.678% \n",
      "[epoch:2, iter:461] Loss: 5.530 | Acc: 5.650% \n",
      "[epoch:2, iter:462] Loss: 5.526 | Acc: 5.721% \n",
      "[epoch:2, iter:463] Loss: 5.524 | Acc: 5.743% \n",
      "[epoch:2, iter:464] Loss: 5.520 | Acc: 5.764% \n",
      "[epoch:2, iter:465] Loss: 5.517 | Acc: 5.735% \n",
      "[epoch:2, iter:466] Loss: 5.512 | Acc: 5.805% \n",
      "[epoch:2, iter:467] Loss: 5.510 | Acc: 5.825% \n",
      "[epoch:2, iter:468] Loss: 5.509 | Acc: 5.797% \n",
      "[epoch:2, iter:469] Loss: 5.505 | Acc: 5.865% \n",
      "[epoch:2, iter:470] Loss: 5.506 | Acc: 5.837% \n",
      "[epoch:2, iter:471] Loss: 5.506 | Acc: 5.810% \n",
      "[epoch:2, iter:472] Loss: 5.507 | Acc: 5.782% \n",
      "[epoch:2, iter:473] Loss: 5.506 | Acc: 5.755% \n",
      "[epoch:2, iter:474] Loss: 5.505 | Acc: 5.775% \n",
      "[epoch:2, iter:475] Loss: 5.503 | Acc: 5.794% \n",
      "[epoch:2, iter:476] Loss: 5.500 | Acc: 5.767% \n",
      "[epoch:2, iter:477] Loss: 5.495 | Acc: 5.833% \n",
      "[epoch:2, iter:478] Loss: 5.491 | Acc: 5.945% \n",
      "[epoch:2, iter:479] Loss: 5.487 | Acc: 6.009% \n",
      "[epoch:2, iter:480] Loss: 5.483 | Acc: 6.073% \n",
      "[epoch:2, iter:481] Loss: 5.479 | Acc: 6.045% \n",
      "[epoch:2, iter:482] Loss: 5.478 | Acc: 6.018% \n",
      "[epoch:2, iter:483] Loss: 5.474 | Acc: 6.081% \n",
      "[epoch:2, iter:484] Loss: 5.469 | Acc: 6.143% \n",
      "[epoch:2, iter:485] Loss: 5.467 | Acc: 6.116% \n",
      "[epoch:2, iter:486] Loss: 5.466 | Acc: 6.133% \n",
      "[epoch:2, iter:487] Loss: 5.460 | Acc: 6.239% \n",
      "[epoch:2, iter:488] Loss: 5.453 | Acc: 6.388% \n",
      "[epoch:2, iter:489] Loss: 5.452 | Acc: 6.404% \n",
      "[epoch:2, iter:490] Loss: 5.455 | Acc: 6.376% \n",
      "[epoch:2, iter:491] Loss: 5.453 | Acc: 6.348% \n",
      "[epoch:2, iter:492] Loss: 5.452 | Acc: 6.407% \n",
      "[epoch:2, iter:493] Loss: 5.448 | Acc: 6.422% \n",
      "[epoch:2, iter:494] Loss: 5.445 | Acc: 6.438% \n",
      "[epoch:2, iter:495] Loss: 5.441 | Acc: 6.496% \n",
      "[epoch:2, iter:496] Loss: 5.433 | Acc: 6.596% \n",
      "[epoch:2, iter:497] Loss: 5.430 | Acc: 6.695% \n",
      "[epoch:2, iter:498] Loss: 5.424 | Acc: 6.793% \n",
      "[epoch:2, iter:499] Loss: 5.421 | Acc: 6.807% \n",
      "[epoch:2, iter:500] Loss: 5.416 | Acc: 6.904% \n",
      "[epoch:2, iter:501] Loss: 5.413 | Acc: 6.958% \n",
      "[epoch:2, iter:502] Loss: 5.408 | Acc: 6.971% \n",
      "[epoch:2, iter:503] Loss: 5.404 | Acc: 6.983% \n",
      "[epoch:2, iter:504] Loss: 5.402 | Acc: 6.996% \n",
      "[epoch:2, iter:505] Loss: 5.396 | Acc: 7.008% \n",
      "[epoch:2, iter:506] Loss: 5.394 | Acc: 6.980% \n",
      "[epoch:2, iter:507] Loss: 5.390 | Acc: 7.033% \n",
      "[epoch:2, iter:508] Loss: 5.388 | Acc: 7.004% \n",
      "[epoch:2, iter:509] Loss: 5.387 | Acc: 6.976% \n",
      "[epoch:2, iter:510] Loss: 5.385 | Acc: 6.948% \n",
      "[epoch:2, iter:511] Loss: 5.382 | Acc: 6.960% \n",
      "[epoch:2, iter:512] Loss: 5.379 | Acc: 7.012% \n",
      "[epoch:2, iter:513] Loss: 5.372 | Acc: 7.063% \n",
      "[epoch:2, iter:514] Loss: 5.370 | Acc: 7.075% \n",
      "[epoch:2, iter:515] Loss: 5.365 | Acc: 7.126% \n",
      "[epoch:2, iter:516] Loss: 5.361 | Acc: 7.216% \n",
      "[epoch:2, iter:517] Loss: 5.360 | Acc: 7.188% \n",
      "[epoch:2, iter:518] Loss: 5.359 | Acc: 7.160% \n",
      "[epoch:2, iter:519] Loss: 5.357 | Acc: 7.132% \n",
      "[epoch:2, iter:520] Loss: 5.354 | Acc: 7.181% \n",
      "[epoch:2, iter:521] Loss: 5.352 | Acc: 7.231% \n",
      "[epoch:2, iter:522] Loss: 5.350 | Acc: 7.228% \n",
      "\n",
      "Epoch: 3\n",
      "[epoch:3, iter:523] Loss: 3.191 | Acc: 50.000% \n",
      "[epoch:3, iter:524] Loss: 3.190 | Acc: 55.000% \n",
      "[epoch:3, iter:525] Loss: 3.530 | Acc: 43.333% \n",
      "[epoch:3, iter:526] Loss: 3.558 | Acc: 40.000% \n",
      "[epoch:3, iter:527] Loss: 3.550 | Acc: 42.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:3, iter:528] Loss: 3.673 | Acc: 38.333% \n",
      "[epoch:3, iter:529] Loss: 3.677 | Acc: 37.143% \n",
      "[epoch:3, iter:530] Loss: 3.657 | Acc: 38.750% \n",
      "[epoch:3, iter:531] Loss: 3.730 | Acc: 34.444% \n",
      "[epoch:3, iter:532] Loss: 3.776 | Acc: 32.000% \n",
      "[epoch:3, iter:533] Loss: 3.790 | Acc: 32.727% \n",
      "[epoch:3, iter:534] Loss: 3.755 | Acc: 32.500% \n",
      "[epoch:3, iter:535] Loss: 3.780 | Acc: 31.538% \n",
      "[epoch:3, iter:536] Loss: 3.749 | Acc: 32.143% \n",
      "[epoch:3, iter:537] Loss: 3.766 | Acc: 30.000% \n",
      "[epoch:3, iter:538] Loss: 3.767 | Acc: 30.000% \n",
      "[epoch:3, iter:539] Loss: 3.768 | Acc: 29.412% \n",
      "[epoch:3, iter:540] Loss: 3.786 | Acc: 28.333% \n",
      "[epoch:3, iter:541] Loss: 3.835 | Acc: 27.368% \n",
      "[epoch:3, iter:542] Loss: 3.824 | Acc: 27.000% \n",
      "[epoch:3, iter:543] Loss: 3.820 | Acc: 27.143% \n",
      "[epoch:3, iter:544] Loss: 3.820 | Acc: 27.727% \n",
      "[epoch:3, iter:545] Loss: 3.794 | Acc: 28.696% \n",
      "[epoch:3, iter:546] Loss: 3.802 | Acc: 28.750% \n",
      "[epoch:3, iter:547] Loss: 3.806 | Acc: 27.600% \n",
      "[epoch:3, iter:548] Loss: 3.815 | Acc: 28.077% \n",
      "[epoch:3, iter:549] Loss: 3.819 | Acc: 27.778% \n",
      "[epoch:3, iter:550] Loss: 3.831 | Acc: 27.143% \n",
      "[epoch:3, iter:551] Loss: 3.839 | Acc: 26.897% \n",
      "[epoch:3, iter:552] Loss: 3.808 | Acc: 27.333% \n",
      "[epoch:3, iter:553] Loss: 3.794 | Acc: 27.742% \n",
      "[epoch:3, iter:554] Loss: 3.788 | Acc: 28.125% \n",
      "[epoch:3, iter:555] Loss: 3.790 | Acc: 28.182% \n",
      "[epoch:3, iter:556] Loss: 3.776 | Acc: 28.529% \n",
      "[epoch:3, iter:557] Loss: 3.763 | Acc: 28.571% \n",
      "[epoch:3, iter:558] Loss: 3.780 | Acc: 28.611% \n",
      "[epoch:3, iter:559] Loss: 3.793 | Acc: 27.838% \n",
      "[epoch:3, iter:560] Loss: 3.774 | Acc: 27.632% \n",
      "[epoch:3, iter:561] Loss: 3.779 | Acc: 27.179% \n",
      "[epoch:3, iter:562] Loss: 3.776 | Acc: 27.250% \n",
      "[epoch:3, iter:563] Loss: 3.773 | Acc: 27.073% \n",
      "[epoch:3, iter:564] Loss: 3.769 | Acc: 27.143% \n",
      "[epoch:3, iter:565] Loss: 3.782 | Acc: 26.977% \n",
      "[epoch:3, iter:566] Loss: 3.759 | Acc: 27.727% \n",
      "[epoch:3, iter:567] Loss: 3.758 | Acc: 27.778% \n",
      "[epoch:3, iter:568] Loss: 3.754 | Acc: 28.043% \n",
      "[epoch:3, iter:569] Loss: 3.738 | Acc: 28.511% \n",
      "[epoch:3, iter:570] Loss: 3.740 | Acc: 28.333% \n",
      "[epoch:3, iter:571] Loss: 3.743 | Acc: 28.367% \n",
      "[epoch:3, iter:572] Loss: 3.733 | Acc: 28.200% \n",
      "[epoch:3, iter:573] Loss: 3.722 | Acc: 28.627% \n",
      "[epoch:3, iter:574] Loss: 3.721 | Acc: 28.462% \n",
      "[epoch:3, iter:575] Loss: 3.733 | Acc: 28.302% \n",
      "[epoch:3, iter:576] Loss: 3.736 | Acc: 28.148% \n",
      "[epoch:3, iter:577] Loss: 3.735 | Acc: 28.182% \n",
      "[epoch:3, iter:578] Loss: 3.735 | Acc: 28.036% \n",
      "[epoch:3, iter:579] Loss: 3.719 | Acc: 28.246% \n",
      "[epoch:3, iter:580] Loss: 3.724 | Acc: 28.103% \n",
      "[epoch:3, iter:581] Loss: 3.720 | Acc: 28.136% \n",
      "[epoch:3, iter:582] Loss: 3.718 | Acc: 28.167% \n",
      "[epoch:3, iter:583] Loss: 3.710 | Acc: 28.033% \n",
      "[epoch:3, iter:584] Loss: 3.708 | Acc: 28.226% \n",
      "[epoch:3, iter:585] Loss: 3.711 | Acc: 27.937% \n",
      "[epoch:3, iter:586] Loss: 3.696 | Acc: 28.438% \n",
      "[epoch:3, iter:587] Loss: 3.695 | Acc: 28.308% \n",
      "[epoch:3, iter:588] Loss: 3.699 | Acc: 28.333% \n",
      "[epoch:3, iter:589] Loss: 3.693 | Acc: 28.507% \n",
      "[epoch:3, iter:590] Loss: 3.697 | Acc: 28.382% \n",
      "[epoch:3, iter:591] Loss: 3.697 | Acc: 28.116% \n",
      "[epoch:3, iter:592] Loss: 3.690 | Acc: 28.286% \n",
      "[epoch:3, iter:593] Loss: 3.691 | Acc: 28.451% \n",
      "[epoch:3, iter:594] Loss: 3.687 | Acc: 28.750% \n",
      "[epoch:3, iter:595] Loss: 3.691 | Acc: 28.493% \n",
      "[epoch:3, iter:596] Loss: 3.701 | Acc: 28.243% \n",
      "[epoch:3, iter:597] Loss: 3.697 | Acc: 28.400% \n",
      "[epoch:3, iter:598] Loss: 3.697 | Acc: 28.421% \n",
      "[epoch:3, iter:599] Loss: 3.706 | Acc: 28.182% \n",
      "[epoch:3, iter:600] Loss: 3.705 | Acc: 28.077% \n",
      "[epoch:3, iter:601] Loss: 3.700 | Acc: 28.101% \n",
      "[epoch:3, iter:602] Loss: 3.704 | Acc: 27.875% \n",
      "[epoch:3, iter:603] Loss: 3.707 | Acc: 27.778% \n",
      "[epoch:3, iter:604] Loss: 3.688 | Acc: 28.171% \n",
      "[epoch:3, iter:605] Loss: 3.686 | Acc: 28.193% \n",
      "[epoch:3, iter:606] Loss: 3.675 | Acc: 28.690% \n",
      "[epoch:3, iter:607] Loss: 3.675 | Acc: 28.824% \n",
      "[epoch:3, iter:608] Loss: 3.661 | Acc: 28.953% \n",
      "[epoch:3, iter:609] Loss: 3.663 | Acc: 28.966% \n",
      "[epoch:3, iter:610] Loss: 3.655 | Acc: 29.091% \n",
      "[epoch:3, iter:611] Loss: 3.649 | Acc: 29.101% \n",
      "[epoch:3, iter:612] Loss: 3.651 | Acc: 29.111% \n",
      "[epoch:3, iter:613] Loss: 3.650 | Acc: 29.121% \n",
      "[epoch:3, iter:614] Loss: 3.650 | Acc: 29.239% \n",
      "[epoch:3, iter:615] Loss: 3.647 | Acc: 29.355% \n",
      "[epoch:3, iter:616] Loss: 3.643 | Acc: 29.362% \n",
      "[epoch:3, iter:617] Loss: 3.646 | Acc: 29.368% \n",
      "[epoch:3, iter:618] Loss: 3.640 | Acc: 29.479% \n",
      "[epoch:3, iter:619] Loss: 3.643 | Acc: 29.278% \n",
      "[epoch:3, iter:620] Loss: 3.639 | Acc: 29.184% \n",
      "[epoch:3, iter:621] Loss: 3.636 | Acc: 29.091% \n",
      "[epoch:3, iter:622] Loss: 3.639 | Acc: 29.200% \n",
      "[epoch:3, iter:623] Loss: 3.634 | Acc: 29.307% \n",
      "[epoch:3, iter:624] Loss: 3.628 | Acc: 29.412% \n",
      "[epoch:3, iter:625] Loss: 3.624 | Acc: 29.320% \n",
      "[epoch:3, iter:626] Loss: 3.618 | Acc: 29.423% \n",
      "[epoch:3, iter:627] Loss: 3.621 | Acc: 29.429% \n",
      "[epoch:3, iter:628] Loss: 3.611 | Acc: 29.623% \n",
      "[epoch:3, iter:629] Loss: 3.604 | Acc: 29.813% \n",
      "[epoch:3, iter:630] Loss: 3.598 | Acc: 29.907% \n",
      "[epoch:3, iter:631] Loss: 3.590 | Acc: 30.092% \n",
      "[epoch:3, iter:632] Loss: 3.576 | Acc: 30.545% \n",
      "[epoch:3, iter:633] Loss: 3.568 | Acc: 30.721% \n",
      "[epoch:3, iter:634] Loss: 3.566 | Acc: 30.893% \n",
      "[epoch:3, iter:635] Loss: 3.562 | Acc: 30.796% \n",
      "[epoch:3, iter:636] Loss: 3.557 | Acc: 30.965% \n",
      "[epoch:3, iter:637] Loss: 3.545 | Acc: 31.304% \n",
      "[epoch:3, iter:638] Loss: 3.547 | Acc: 31.207% \n",
      "[epoch:3, iter:639] Loss: 3.540 | Acc: 31.368% \n",
      "[epoch:3, iter:640] Loss: 3.534 | Acc: 31.441% \n",
      "[epoch:3, iter:641] Loss: 3.528 | Acc: 31.429% \n",
      "[epoch:3, iter:642] Loss: 3.525 | Acc: 31.583% \n",
      "[epoch:3, iter:643] Loss: 3.523 | Acc: 31.570% \n",
      "[epoch:3, iter:644] Loss: 3.523 | Acc: 31.475% \n",
      "[epoch:3, iter:645] Loss: 3.512 | Acc: 31.789% \n",
      "[epoch:3, iter:646] Loss: 3.512 | Acc: 31.613% \n",
      "[epoch:3, iter:647] Loss: 3.507 | Acc: 31.680% \n",
      "[epoch:3, iter:648] Loss: 3.501 | Acc: 31.825% \n",
      "[epoch:3, iter:649] Loss: 3.498 | Acc: 31.890% \n",
      "[epoch:3, iter:650] Loss: 3.493 | Acc: 32.031% \n",
      "[epoch:3, iter:651] Loss: 3.492 | Acc: 32.171% \n",
      "[epoch:3, iter:652] Loss: 3.486 | Acc: 32.154% \n",
      "[epoch:3, iter:653] Loss: 3.488 | Acc: 31.985% \n",
      "[epoch:3, iter:654] Loss: 3.477 | Acc: 32.273% \n",
      "[epoch:3, iter:655] Loss: 3.480 | Acc: 32.180% \n",
      "[epoch:3, iter:656] Loss: 3.477 | Acc: 32.164% \n",
      "[epoch:3, iter:657] Loss: 3.477 | Acc: 32.074% \n",
      "[epoch:3, iter:658] Loss: 3.469 | Acc: 32.206% \n",
      "[epoch:3, iter:659] Loss: 3.467 | Acc: 32.117% \n",
      "[epoch:3, iter:660] Loss: 3.461 | Acc: 32.246% \n",
      "[epoch:3, iter:661] Loss: 3.455 | Acc: 32.374% \n",
      "[epoch:3, iter:662] Loss: 3.450 | Acc: 32.571% \n",
      "[epoch:3, iter:663] Loss: 3.445 | Acc: 32.624% \n",
      "[epoch:3, iter:664] Loss: 3.441 | Acc: 32.535% \n",
      "[epoch:3, iter:665] Loss: 3.442 | Acc: 32.378% \n",
      "[epoch:3, iter:666] Loss: 3.441 | Acc: 32.361% \n",
      "[epoch:3, iter:667] Loss: 3.438 | Acc: 32.483% \n",
      "[epoch:3, iter:668] Loss: 3.435 | Acc: 32.466% \n",
      "[epoch:3, iter:669] Loss: 3.431 | Acc: 32.653% \n",
      "[epoch:3, iter:670] Loss: 3.430 | Acc: 32.770% \n",
      "[epoch:3, iter:671] Loss: 3.427 | Acc: 32.685% \n",
      "[epoch:3, iter:672] Loss: 3.421 | Acc: 32.800% \n",
      "[epoch:3, iter:673] Loss: 3.415 | Acc: 33.046% \n",
      "[epoch:3, iter:674] Loss: 3.416 | Acc: 32.961% \n",
      "[epoch:3, iter:675] Loss: 3.412 | Acc: 33.007% \n",
      "[epoch:3, iter:676] Loss: 3.411 | Acc: 33.052% \n",
      "[epoch:3, iter:677] Loss: 3.409 | Acc: 33.032% \n",
      "[epoch:3, iter:678] Loss: 3.406 | Acc: 33.013% \n",
      "[epoch:3, iter:679] Loss: 3.405 | Acc: 32.930% \n",
      "[epoch:3, iter:680] Loss: 3.403 | Acc: 32.911% \n",
      "[epoch:3, iter:681] Loss: 3.401 | Acc: 32.956% \n",
      "[epoch:3, iter:682] Loss: 3.405 | Acc: 32.750% \n",
      "[epoch:3, iter:683] Loss: 3.402 | Acc: 32.795% \n",
      "[epoch:3, iter:684] Loss: 3.399 | Acc: 32.716% \n",
      "[epoch:3, iter:685] Loss: 3.398 | Acc: 32.761% \n",
      "[epoch:3, iter:686] Loss: 3.400 | Acc: 32.622% \n",
      "[epoch:3, iter:687] Loss: 3.402 | Acc: 32.545% \n",
      "[epoch:3, iter:688] Loss: 3.400 | Acc: 32.530% \n",
      "[epoch:3, iter:689] Loss: 3.397 | Acc: 32.635% \n",
      "[epoch:3, iter:690] Loss: 3.391 | Acc: 32.738% \n",
      "[epoch:3, iter:691] Loss: 3.392 | Acc: 32.722% \n",
      "[epoch:3, iter:692] Loss: 3.392 | Acc: 32.588% \n",
      "[epoch:3, iter:693] Loss: 3.393 | Acc: 32.573% \n",
      "[epoch:3, iter:694] Loss: 3.393 | Acc: 32.558% \n",
      "[epoch:3, iter:695] Loss: 3.389 | Acc: 32.543% \n",
      "[epoch:3, iter:696] Loss: 3.389 | Acc: 32.529% \n",
      "[epoch:3, iter:697] Loss: 3.386 | Acc: 32.571% \n",
      "[epoch:3, iter:698] Loss: 3.383 | Acc: 32.670% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:3, iter:699] Loss: 3.380 | Acc: 32.712% \n",
      "[epoch:3, iter:700] Loss: 3.375 | Acc: 32.753% \n",
      "[epoch:3, iter:701] Loss: 3.371 | Acc: 32.793% \n",
      "[epoch:3, iter:702] Loss: 3.369 | Acc: 32.833% \n",
      "[epoch:3, iter:703] Loss: 3.362 | Acc: 32.983% \n",
      "[epoch:3, iter:704] Loss: 3.360 | Acc: 32.967% \n",
      "[epoch:3, iter:705] Loss: 3.359 | Acc: 32.896% \n",
      "[epoch:3, iter:706] Loss: 3.352 | Acc: 33.043% \n",
      "[epoch:3, iter:707] Loss: 3.351 | Acc: 33.189% \n",
      "[epoch:3, iter:708] Loss: 3.350 | Acc: 33.172% \n",
      "[epoch:3, iter:709] Loss: 3.345 | Acc: 33.155% \n",
      "[epoch:3, iter:710] Loss: 3.344 | Acc: 33.245% \n",
      "[epoch:3, iter:711] Loss: 3.345 | Acc: 33.175% \n",
      "[epoch:3, iter:712] Loss: 3.340 | Acc: 33.211% \n",
      "[epoch:3, iter:713] Loss: 3.340 | Acc: 33.298% \n",
      "[epoch:3, iter:714] Loss: 3.337 | Acc: 33.281% \n",
      "[epoch:3, iter:715] Loss: 3.330 | Acc: 33.368% \n",
      "[epoch:3, iter:716] Loss: 3.327 | Acc: 33.402% \n",
      "[epoch:3, iter:717] Loss: 3.324 | Acc: 33.436% \n",
      "[epoch:3, iter:718] Loss: 3.318 | Acc: 33.469% \n",
      "[epoch:3, iter:719] Loss: 3.314 | Acc: 33.604% \n",
      "[epoch:3, iter:720] Loss: 3.314 | Acc: 33.535% \n",
      "[epoch:3, iter:721] Loss: 3.308 | Acc: 33.618% \n",
      "[epoch:3, iter:722] Loss: 3.306 | Acc: 33.650% \n",
      "[epoch:3, iter:723] Loss: 3.301 | Acc: 33.731% \n",
      "[epoch:3, iter:724] Loss: 3.299 | Acc: 33.663% \n",
      "[epoch:3, iter:725] Loss: 3.302 | Acc: 33.547% \n",
      "[epoch:3, iter:726] Loss: 3.299 | Acc: 33.676% \n",
      "[epoch:3, iter:727] Loss: 3.298 | Acc: 33.659% \n",
      "[epoch:3, iter:728] Loss: 3.294 | Acc: 33.641% \n",
      "[epoch:3, iter:729] Loss: 3.291 | Acc: 33.720% \n",
      "[epoch:3, iter:730] Loss: 3.285 | Acc: 33.894% \n",
      "[epoch:3, iter:731] Loss: 3.284 | Acc: 33.876% \n",
      "[epoch:3, iter:732] Loss: 3.283 | Acc: 33.857% \n",
      "[epoch:3, iter:733] Loss: 3.279 | Acc: 33.934% \n",
      "[epoch:3, iter:734] Loss: 3.273 | Acc: 34.009% \n",
      "[epoch:3, iter:735] Loss: 3.271 | Acc: 34.038% \n",
      "[epoch:3, iter:736] Loss: 3.268 | Acc: 34.065% \n",
      "[epoch:3, iter:737] Loss: 3.266 | Acc: 34.140% \n",
      "[epoch:3, iter:738] Loss: 3.265 | Acc: 34.167% \n",
      "[epoch:3, iter:739] Loss: 3.261 | Acc: 34.194% \n",
      "[epoch:3, iter:740] Loss: 3.258 | Acc: 34.312% \n",
      "[epoch:3, iter:741] Loss: 3.251 | Acc: 34.475% \n",
      "[epoch:3, iter:742] Loss: 3.253 | Acc: 34.409% \n",
      "[epoch:3, iter:743] Loss: 3.249 | Acc: 34.480% \n",
      "[epoch:3, iter:744] Loss: 3.246 | Acc: 34.505% \n",
      "[epoch:3, iter:745] Loss: 3.243 | Acc: 34.619% \n",
      "[epoch:3, iter:746] Loss: 3.241 | Acc: 34.732% \n",
      "[epoch:3, iter:747] Loss: 3.239 | Acc: 34.756% \n",
      "[epoch:3, iter:748] Loss: 3.236 | Acc: 34.779% \n",
      "[epoch:3, iter:749] Loss: 3.234 | Acc: 34.802% \n",
      "[epoch:3, iter:750] Loss: 3.234 | Acc: 34.781% \n",
      "[epoch:3, iter:751] Loss: 3.234 | Acc: 34.716% \n",
      "[epoch:3, iter:752] Loss: 3.230 | Acc: 34.826% \n",
      "[epoch:3, iter:753] Loss: 3.226 | Acc: 34.848% \n",
      "[epoch:3, iter:754] Loss: 3.222 | Acc: 34.957% \n",
      "[epoch:3, iter:755] Loss: 3.218 | Acc: 35.021% \n",
      "[epoch:3, iter:756] Loss: 3.215 | Acc: 35.171% \n",
      "[epoch:3, iter:757] Loss: 3.211 | Acc: 35.277% \n",
      "[epoch:3, iter:758] Loss: 3.209 | Acc: 35.339% \n",
      "[epoch:3, iter:759] Loss: 3.204 | Acc: 35.443% \n",
      "[epoch:3, iter:760] Loss: 3.200 | Acc: 35.546% \n",
      "[epoch:3, iter:761] Loss: 3.197 | Acc: 35.523% \n",
      "[epoch:3, iter:762] Loss: 3.192 | Acc: 35.667% \n",
      "[epoch:3, iter:763] Loss: 3.189 | Acc: 35.643% \n",
      "[epoch:3, iter:764] Loss: 3.185 | Acc: 35.702% \n",
      "[epoch:3, iter:765] Loss: 3.183 | Acc: 35.720% \n",
      "[epoch:3, iter:766] Loss: 3.182 | Acc: 35.697% \n",
      "[epoch:3, iter:767] Loss: 3.182 | Acc: 35.755% \n",
      "[epoch:3, iter:768] Loss: 3.175 | Acc: 35.935% \n",
      "[epoch:3, iter:769] Loss: 3.170 | Acc: 36.073% \n",
      "[epoch:3, iter:770] Loss: 3.166 | Acc: 36.129% \n",
      "[epoch:3, iter:771] Loss: 3.162 | Acc: 36.225% \n",
      "[epoch:3, iter:772] Loss: 3.159 | Acc: 36.240% \n",
      "[epoch:3, iter:773] Loss: 3.158 | Acc: 36.255% \n",
      "[epoch:3, iter:774] Loss: 3.152 | Acc: 36.349% \n",
      "[epoch:3, iter:775] Loss: 3.150 | Acc: 36.364% \n",
      "[epoch:3, iter:776] Loss: 3.148 | Acc: 36.378% \n",
      "[epoch:3, iter:777] Loss: 3.146 | Acc: 36.431% \n",
      "[epoch:3, iter:778] Loss: 3.144 | Acc: 36.445% \n",
      "[epoch:3, iter:779] Loss: 3.143 | Acc: 36.381% \n",
      "[epoch:3, iter:780] Loss: 3.141 | Acc: 36.434% \n",
      "[epoch:3, iter:781] Loss: 3.140 | Acc: 36.409% \n",
      "[epoch:3, iter:782] Loss: 3.138 | Acc: 36.346% \n",
      "[epoch:3, iter:783] Loss: 3.141 | Acc: 36.332% \n",
      "\n",
      "Epoch: 4\n",
      "[epoch:4, iter:784] Loss: 1.798 | Acc: 80.000% \n",
      "[epoch:4, iter:785] Loss: 1.851 | Acc: 70.000% \n",
      "[epoch:4, iter:786] Loss: 1.935 | Acc: 63.333% \n",
      "[epoch:4, iter:787] Loss: 1.980 | Acc: 62.500% \n",
      "[epoch:4, iter:788] Loss: 1.936 | Acc: 66.000% \n",
      "[epoch:4, iter:789] Loss: 1.866 | Acc: 66.667% \n",
      "[epoch:4, iter:790] Loss: 1.823 | Acc: 68.571% \n",
      "[epoch:4, iter:791] Loss: 1.903 | Acc: 65.000% \n",
      "[epoch:4, iter:792] Loss: 1.902 | Acc: 64.444% \n",
      "[epoch:4, iter:793] Loss: 1.914 | Acc: 63.000% \n",
      "[epoch:4, iter:794] Loss: 1.897 | Acc: 62.727% \n",
      "[epoch:4, iter:795] Loss: 1.889 | Acc: 63.333% \n",
      "[epoch:4, iter:796] Loss: 1.899 | Acc: 63.846% \n",
      "[epoch:4, iter:797] Loss: 1.934 | Acc: 63.571% \n",
      "[epoch:4, iter:798] Loss: 1.934 | Acc: 63.333% \n",
      "[epoch:4, iter:799] Loss: 1.923 | Acc: 63.750% \n",
      "[epoch:4, iter:800] Loss: 1.913 | Acc: 62.941% \n",
      "[epoch:4, iter:801] Loss: 1.943 | Acc: 62.778% \n",
      "[epoch:4, iter:802] Loss: 1.937 | Acc: 62.105% \n",
      "[epoch:4, iter:803] Loss: 1.926 | Acc: 62.000% \n",
      "[epoch:4, iter:804] Loss: 1.923 | Acc: 62.381% \n",
      "[epoch:4, iter:805] Loss: 1.929 | Acc: 62.273% \n",
      "[epoch:4, iter:806] Loss: 1.930 | Acc: 62.609% \n",
      "[epoch:4, iter:807] Loss: 1.923 | Acc: 62.500% \n",
      "[epoch:4, iter:808] Loss: 1.937 | Acc: 61.200% \n",
      "[epoch:4, iter:809] Loss: 1.922 | Acc: 61.154% \n",
      "[epoch:4, iter:810] Loss: 1.912 | Acc: 61.481% \n",
      "[epoch:4, iter:811] Loss: 1.920 | Acc: 61.071% \n",
      "[epoch:4, iter:812] Loss: 1.903 | Acc: 61.724% \n",
      "[epoch:4, iter:813] Loss: 1.909 | Acc: 61.667% \n",
      "[epoch:4, iter:814] Loss: 1.901 | Acc: 62.258% \n",
      "[epoch:4, iter:815] Loss: 1.909 | Acc: 61.562% \n",
      "[epoch:4, iter:816] Loss: 1.889 | Acc: 61.818% \n",
      "[epoch:4, iter:817] Loss: 1.896 | Acc: 61.471% \n",
      "[epoch:4, iter:818] Loss: 1.899 | Acc: 61.429% \n",
      "[epoch:4, iter:819] Loss: 1.909 | Acc: 61.111% \n",
      "[epoch:4, iter:820] Loss: 1.897 | Acc: 60.811% \n",
      "[epoch:4, iter:821] Loss: 1.896 | Acc: 61.053% \n",
      "[epoch:4, iter:822] Loss: 1.874 | Acc: 61.538% \n",
      "[epoch:4, iter:823] Loss: 1.880 | Acc: 61.000% \n",
      "[epoch:4, iter:824] Loss: 1.889 | Acc: 60.976% \n",
      "[epoch:4, iter:825] Loss: 1.886 | Acc: 61.190% \n",
      "[epoch:4, iter:826] Loss: 1.891 | Acc: 61.395% \n",
      "[epoch:4, iter:827] Loss: 1.903 | Acc: 60.909% \n",
      "[epoch:4, iter:828] Loss: 1.904 | Acc: 60.667% \n",
      "[epoch:4, iter:829] Loss: 1.906 | Acc: 60.652% \n",
      "[epoch:4, iter:830] Loss: 1.895 | Acc: 60.638% \n",
      "[epoch:4, iter:831] Loss: 1.881 | Acc: 61.042% \n",
      "[epoch:4, iter:832] Loss: 1.895 | Acc: 60.612% \n",
      "[epoch:4, iter:833] Loss: 1.894 | Acc: 60.800% \n",
      "[epoch:4, iter:834] Loss: 1.887 | Acc: 60.980% \n",
      "[epoch:4, iter:835] Loss: 1.887 | Acc: 60.962% \n",
      "[epoch:4, iter:836] Loss: 1.887 | Acc: 60.755% \n",
      "[epoch:4, iter:837] Loss: 1.878 | Acc: 60.926% \n",
      "[epoch:4, iter:838] Loss: 1.874 | Acc: 61.091% \n",
      "[epoch:4, iter:839] Loss: 1.881 | Acc: 60.714% \n",
      "[epoch:4, iter:840] Loss: 1.887 | Acc: 60.526% \n",
      "[epoch:4, iter:841] Loss: 1.881 | Acc: 60.517% \n",
      "[epoch:4, iter:842] Loss: 1.889 | Acc: 60.339% \n",
      "[epoch:4, iter:843] Loss: 1.889 | Acc: 60.333% \n",
      "[epoch:4, iter:844] Loss: 1.887 | Acc: 60.328% \n",
      "[epoch:4, iter:845] Loss: 1.889 | Acc: 60.000% \n",
      "[epoch:4, iter:846] Loss: 1.883 | Acc: 60.000% \n",
      "[epoch:4, iter:847] Loss: 1.887 | Acc: 59.844% \n",
      "[epoch:4, iter:848] Loss: 1.895 | Acc: 59.846% \n",
      "[epoch:4, iter:849] Loss: 1.890 | Acc: 59.848% \n",
      "[epoch:4, iter:850] Loss: 1.896 | Acc: 59.552% \n",
      "[epoch:4, iter:851] Loss: 1.891 | Acc: 59.559% \n",
      "[epoch:4, iter:852] Loss: 1.885 | Acc: 59.855% \n",
      "[epoch:4, iter:853] Loss: 1.890 | Acc: 59.571% \n",
      "[epoch:4, iter:854] Loss: 1.883 | Acc: 59.859% \n",
      "[epoch:4, iter:855] Loss: 1.889 | Acc: 59.722% \n",
      "[epoch:4, iter:856] Loss: 1.890 | Acc: 59.726% \n",
      "[epoch:4, iter:857] Loss: 1.889 | Acc: 59.595% \n",
      "[epoch:4, iter:858] Loss: 1.881 | Acc: 59.733% \n",
      "[epoch:4, iter:859] Loss: 1.883 | Acc: 59.474% \n",
      "[epoch:4, iter:860] Loss: 1.878 | Acc: 59.740% \n",
      "[epoch:4, iter:861] Loss: 1.886 | Acc: 59.615% \n",
      "[epoch:4, iter:862] Loss: 1.880 | Acc: 59.620% \n",
      "[epoch:4, iter:863] Loss: 1.880 | Acc: 59.625% \n",
      "[epoch:4, iter:864] Loss: 1.876 | Acc: 59.877% \n",
      "[epoch:4, iter:865] Loss: 1.880 | Acc: 59.878% \n",
      "[epoch:4, iter:866] Loss: 1.874 | Acc: 60.120% \n",
      "[epoch:4, iter:867] Loss: 1.886 | Acc: 60.000% \n",
      "[epoch:4, iter:868] Loss: 1.881 | Acc: 60.118% \n",
      "[epoch:4, iter:869] Loss: 1.881 | Acc: 60.000% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:4, iter:870] Loss: 1.878 | Acc: 60.000% \n",
      "[epoch:4, iter:871] Loss: 1.868 | Acc: 60.341% \n",
      "[epoch:4, iter:872] Loss: 1.862 | Acc: 60.562% \n",
      "[epoch:4, iter:873] Loss: 1.860 | Acc: 60.556% \n",
      "[epoch:4, iter:874] Loss: 1.858 | Acc: 60.549% \n",
      "[epoch:4, iter:875] Loss: 1.852 | Acc: 60.652% \n",
      "[epoch:4, iter:876] Loss: 1.855 | Acc: 60.323% \n",
      "[epoch:4, iter:877] Loss: 1.859 | Acc: 60.319% \n",
      "[epoch:4, iter:878] Loss: 1.867 | Acc: 60.105% \n",
      "[epoch:4, iter:879] Loss: 1.866 | Acc: 60.208% \n",
      "[epoch:4, iter:880] Loss: 1.861 | Acc: 60.206% \n",
      "[epoch:4, iter:881] Loss: 1.858 | Acc: 60.306% \n",
      "[epoch:4, iter:882] Loss: 1.850 | Acc: 60.505% \n",
      "[epoch:4, iter:883] Loss: 1.854 | Acc: 60.500% \n",
      "[epoch:4, iter:884] Loss: 1.859 | Acc: 60.297% \n",
      "[epoch:4, iter:885] Loss: 1.855 | Acc: 60.490% \n",
      "[epoch:4, iter:886] Loss: 1.849 | Acc: 60.583% \n",
      "[epoch:4, iter:887] Loss: 1.847 | Acc: 60.769% \n",
      "[epoch:4, iter:888] Loss: 1.846 | Acc: 60.857% \n",
      "[epoch:4, iter:889] Loss: 1.840 | Acc: 61.038% \n",
      "[epoch:4, iter:890] Loss: 1.834 | Acc: 61.215% \n",
      "[epoch:4, iter:891] Loss: 1.837 | Acc: 61.204% \n",
      "[epoch:4, iter:892] Loss: 1.835 | Acc: 61.284% \n",
      "[epoch:4, iter:893] Loss: 1.832 | Acc: 61.364% \n",
      "[epoch:4, iter:894] Loss: 1.833 | Acc: 61.261% \n",
      "[epoch:4, iter:895] Loss: 1.837 | Acc: 61.071% \n",
      "[epoch:4, iter:896] Loss: 1.833 | Acc: 61.239% \n",
      "[epoch:4, iter:897] Loss: 1.829 | Acc: 61.404% \n",
      "[epoch:4, iter:898] Loss: 1.829 | Acc: 61.565% \n",
      "[epoch:4, iter:899] Loss: 1.830 | Acc: 61.638% \n",
      "[epoch:4, iter:900] Loss: 1.829 | Acc: 61.795% \n",
      "[epoch:4, iter:901] Loss: 1.834 | Acc: 61.610% \n",
      "[epoch:4, iter:902] Loss: 1.837 | Acc: 61.597% \n",
      "[epoch:4, iter:903] Loss: 1.838 | Acc: 61.500% \n",
      "[epoch:4, iter:904] Loss: 1.836 | Acc: 61.570% \n",
      "[epoch:4, iter:905] Loss: 1.835 | Acc: 61.557% \n",
      "[epoch:4, iter:906] Loss: 1.832 | Acc: 61.545% \n",
      "[epoch:4, iter:907] Loss: 1.828 | Acc: 61.694% \n",
      "[epoch:4, iter:908] Loss: 1.823 | Acc: 61.680% \n",
      "[epoch:4, iter:909] Loss: 1.828 | Acc: 61.429% \n",
      "[epoch:4, iter:910] Loss: 1.832 | Acc: 61.260% \n",
      "[epoch:4, iter:911] Loss: 1.826 | Acc: 61.484% \n",
      "[epoch:4, iter:912] Loss: 1.824 | Acc: 61.550% \n",
      "[epoch:4, iter:913] Loss: 1.819 | Acc: 61.769% \n",
      "[epoch:4, iter:914] Loss: 1.813 | Acc: 61.908% \n",
      "[epoch:4, iter:915] Loss: 1.808 | Acc: 62.045% \n",
      "[epoch:4, iter:916] Loss: 1.808 | Acc: 62.030% \n",
      "[epoch:4, iter:917] Loss: 1.806 | Acc: 62.090% \n",
      "[epoch:4, iter:918] Loss: 1.807 | Acc: 62.000% \n",
      "[epoch:4, iter:919] Loss: 1.804 | Acc: 62.206% \n",
      "[epoch:4, iter:920] Loss: 1.803 | Acc: 62.190% \n",
      "[epoch:4, iter:921] Loss: 1.801 | Acc: 62.246% \n",
      "[epoch:4, iter:922] Loss: 1.801 | Acc: 62.302% \n",
      "[epoch:4, iter:923] Loss: 1.801 | Acc: 62.286% \n",
      "[epoch:4, iter:924] Loss: 1.795 | Acc: 62.411% \n",
      "[epoch:4, iter:925] Loss: 1.791 | Acc: 62.535% \n",
      "[epoch:4, iter:926] Loss: 1.790 | Acc: 62.517% \n",
      "[epoch:4, iter:927] Loss: 1.791 | Acc: 62.431% \n",
      "[epoch:4, iter:928] Loss: 1.790 | Acc: 62.483% \n",
      "[epoch:4, iter:929] Loss: 1.792 | Acc: 62.466% \n",
      "[epoch:4, iter:930] Loss: 1.789 | Acc: 62.585% \n",
      "[epoch:4, iter:931] Loss: 1.789 | Acc: 62.568% \n",
      "[epoch:4, iter:932] Loss: 1.795 | Acc: 62.349% \n",
      "[epoch:4, iter:933] Loss: 1.795 | Acc: 62.333% \n",
      "[epoch:4, iter:934] Loss: 1.791 | Acc: 62.450% \n",
      "[epoch:4, iter:935] Loss: 1.791 | Acc: 62.566% \n",
      "[epoch:4, iter:936] Loss: 1.791 | Acc: 62.549% \n",
      "[epoch:4, iter:937] Loss: 1.785 | Acc: 62.727% \n",
      "[epoch:4, iter:938] Loss: 1.787 | Acc: 62.774% \n",
      "[epoch:4, iter:939] Loss: 1.791 | Acc: 62.628% \n",
      "[epoch:4, iter:940] Loss: 1.787 | Acc: 62.611% \n",
      "[epoch:4, iter:941] Loss: 1.784 | Acc: 62.595% \n",
      "[epoch:4, iter:942] Loss: 1.782 | Acc: 62.516% \n",
      "[epoch:4, iter:943] Loss: 1.780 | Acc: 62.500% \n",
      "[epoch:4, iter:944] Loss: 1.778 | Acc: 62.484% \n",
      "[epoch:4, iter:945] Loss: 1.775 | Acc: 62.531% \n",
      "[epoch:4, iter:946] Loss: 1.776 | Acc: 62.454% \n",
      "[epoch:4, iter:947] Loss: 1.772 | Acc: 62.500% \n",
      "[epoch:4, iter:948] Loss: 1.767 | Acc: 62.606% \n",
      "[epoch:4, iter:949] Loss: 1.767 | Acc: 62.590% \n",
      "[epoch:4, iter:950] Loss: 1.766 | Acc: 62.635% \n",
      "[epoch:4, iter:951] Loss: 1.763 | Acc: 62.738% \n",
      "[epoch:4, iter:952] Loss: 1.759 | Acc: 62.840% \n",
      "[epoch:4, iter:953] Loss: 1.760 | Acc: 62.824% \n",
      "[epoch:4, iter:954] Loss: 1.758 | Acc: 62.924% \n",
      "[epoch:4, iter:955] Loss: 1.758 | Acc: 62.965% \n",
      "[epoch:4, iter:956] Loss: 1.755 | Acc: 63.064% \n",
      "[epoch:4, iter:957] Loss: 1.750 | Acc: 63.161% \n",
      "[epoch:4, iter:958] Loss: 1.748 | Acc: 63.257% \n",
      "[epoch:4, iter:959] Loss: 1.748 | Acc: 63.295% \n",
      "[epoch:4, iter:960] Loss: 1.748 | Acc: 63.220% \n",
      "[epoch:4, iter:961] Loss: 1.748 | Acc: 63.090% \n",
      "[epoch:4, iter:962] Loss: 1.745 | Acc: 63.184% \n",
      "[epoch:4, iter:963] Loss: 1.738 | Acc: 63.333% \n",
      "[epoch:4, iter:964] Loss: 1.737 | Acc: 63.370% \n",
      "[epoch:4, iter:965] Loss: 1.732 | Acc: 63.462% \n",
      "[epoch:4, iter:966] Loss: 1.732 | Acc: 63.388% \n",
      "[epoch:4, iter:967] Loss: 1.726 | Acc: 63.533% \n",
      "[epoch:4, iter:968] Loss: 1.724 | Acc: 63.568% \n",
      "[epoch:4, iter:969] Loss: 1.726 | Acc: 63.495% \n",
      "[epoch:4, iter:970] Loss: 1.725 | Acc: 63.583% \n",
      "[epoch:4, iter:971] Loss: 1.723 | Acc: 63.670% \n",
      "[epoch:4, iter:972] Loss: 1.725 | Acc: 63.598% \n",
      "[epoch:4, iter:973] Loss: 1.723 | Acc: 63.737% \n",
      "[epoch:4, iter:974] Loss: 1.724 | Acc: 63.717% \n",
      "[epoch:4, iter:975] Loss: 1.721 | Acc: 63.750% \n",
      "[epoch:4, iter:976] Loss: 1.721 | Acc: 63.782% \n",
      "[epoch:4, iter:977] Loss: 1.721 | Acc: 63.763% \n",
      "[epoch:4, iter:978] Loss: 1.719 | Acc: 63.744% \n",
      "[epoch:4, iter:979] Loss: 1.718 | Acc: 63.724% \n",
      "[epoch:4, iter:980] Loss: 1.716 | Acc: 63.706% \n",
      "[epoch:4, iter:981] Loss: 1.714 | Acc: 63.737% \n",
      "[epoch:4, iter:982] Loss: 1.714 | Acc: 63.618% \n",
      "[epoch:4, iter:983] Loss: 1.715 | Acc: 63.550% \n",
      "[epoch:4, iter:984] Loss: 1.714 | Acc: 63.483% \n",
      "[epoch:4, iter:985] Loss: 1.713 | Acc: 63.416% \n",
      "[epoch:4, iter:986] Loss: 1.712 | Acc: 63.399% \n",
      "[epoch:4, iter:987] Loss: 1.710 | Acc: 63.431% \n",
      "[epoch:4, iter:988] Loss: 1.713 | Acc: 63.366% \n",
      "[epoch:4, iter:989] Loss: 1.712 | Acc: 63.350% \n",
      "[epoch:4, iter:990] Loss: 1.714 | Acc: 63.333% \n",
      "[epoch:4, iter:991] Loss: 1.714 | Acc: 63.317% \n",
      "[epoch:4, iter:992] Loss: 1.712 | Acc: 63.349% \n",
      "[epoch:4, iter:993] Loss: 1.708 | Acc: 63.429% \n",
      "[epoch:4, iter:994] Loss: 1.705 | Acc: 63.412% \n",
      "[epoch:4, iter:995] Loss: 1.706 | Acc: 63.443% \n",
      "[epoch:4, iter:996] Loss: 1.704 | Acc: 63.474% \n",
      "[epoch:4, iter:997] Loss: 1.704 | Acc: 63.458% \n",
      "[epoch:4, iter:998] Loss: 1.704 | Acc: 63.442% \n",
      "[epoch:4, iter:999] Loss: 1.702 | Acc: 63.472% \n",
      "[epoch:4, iter:1000] Loss: 1.701 | Acc: 63.502% \n",
      "[epoch:4, iter:1001] Loss: 1.698 | Acc: 63.578% \n",
      "[epoch:4, iter:1002] Loss: 1.696 | Acc: 63.607% \n",
      "[epoch:4, iter:1003] Loss: 1.691 | Acc: 63.727% \n",
      "[epoch:4, iter:1004] Loss: 1.692 | Acc: 63.665% \n",
      "[epoch:4, iter:1005] Loss: 1.693 | Acc: 63.559% \n",
      "[epoch:4, iter:1006] Loss: 1.691 | Acc: 63.587% \n",
      "[epoch:4, iter:1007] Loss: 1.689 | Acc: 63.571% \n",
      "[epoch:4, iter:1008] Loss: 1.685 | Acc: 63.644% \n",
      "[epoch:4, iter:1009] Loss: 1.685 | Acc: 63.673% \n",
      "[epoch:4, iter:1010] Loss: 1.684 | Acc: 63.656% \n",
      "[epoch:4, iter:1011] Loss: 1.682 | Acc: 63.684% \n",
      "[epoch:4, iter:1012] Loss: 1.686 | Acc: 63.668% \n",
      "[epoch:4, iter:1013] Loss: 1.686 | Acc: 63.609% \n",
      "[epoch:4, iter:1014] Loss: 1.684 | Acc: 63.593% \n",
      "[epoch:4, iter:1015] Loss: 1.684 | Acc: 63.534% \n",
      "[epoch:4, iter:1016] Loss: 1.682 | Acc: 63.605% \n",
      "[epoch:4, iter:1017] Loss: 1.683 | Acc: 63.547% \n",
      "[epoch:4, iter:1018] Loss: 1.683 | Acc: 63.532% \n",
      "[epoch:4, iter:1019] Loss: 1.684 | Acc: 63.559% \n",
      "[epoch:4, iter:1020] Loss: 1.686 | Acc: 63.544% \n",
      "[epoch:4, iter:1021] Loss: 1.683 | Acc: 63.613% \n",
      "[epoch:4, iter:1022] Loss: 1.684 | Acc: 63.640% \n",
      "[epoch:4, iter:1023] Loss: 1.682 | Acc: 63.708% \n",
      "[epoch:4, iter:1024] Loss: 1.682 | Acc: 63.610% \n",
      "[epoch:4, iter:1025] Loss: 1.681 | Acc: 63.678% \n",
      "[epoch:4, iter:1026] Loss: 1.679 | Acc: 63.704% \n",
      "[epoch:4, iter:1027] Loss: 1.676 | Acc: 63.811% \n",
      "[epoch:4, iter:1028] Loss: 1.674 | Acc: 63.837% \n",
      "[epoch:4, iter:1029] Loss: 1.673 | Acc: 63.821% \n",
      "[epoch:4, iter:1030] Loss: 1.670 | Acc: 63.887% \n",
      "[epoch:4, iter:1031] Loss: 1.669 | Acc: 63.911% \n",
      "[epoch:4, iter:1032] Loss: 1.668 | Acc: 63.936% \n",
      "[epoch:4, iter:1033] Loss: 1.667 | Acc: 63.840% \n",
      "[epoch:4, iter:1034] Loss: 1.665 | Acc: 63.865% \n",
      "[epoch:4, iter:1035] Loss: 1.664 | Acc: 63.849% \n",
      "[epoch:4, iter:1036] Loss: 1.663 | Acc: 63.834% \n",
      "[epoch:4, iter:1037] Loss: 1.661 | Acc: 63.898% \n",
      "[epoch:4, iter:1038] Loss: 1.662 | Acc: 63.804% \n",
      "[epoch:4, iter:1039] Loss: 1.661 | Acc: 63.828% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:4, iter:1040] Loss: 1.662 | Acc: 63.813% \n",
      "[epoch:4, iter:1041] Loss: 1.661 | Acc: 63.837% \n",
      "[epoch:4, iter:1042] Loss: 1.662 | Acc: 63.822% \n",
      "[epoch:4, iter:1043] Loss: 1.661 | Acc: 63.769% \n",
      "[epoch:4, iter:1044] Loss: 1.667 | Acc: 63.745% \n",
      "\n",
      "Epoch: 5\n",
      "[epoch:5, iter:1045] Loss: 0.908 | Acc: 80.000% \n",
      "[epoch:5, iter:1046] Loss: 0.941 | Acc: 80.000% \n",
      "[epoch:5, iter:1047] Loss: 1.127 | Acc: 83.333% \n",
      "[epoch:5, iter:1048] Loss: 1.284 | Acc: 82.500% \n",
      "[epoch:5, iter:1049] Loss: 1.239 | Acc: 80.000% \n",
      "[epoch:5, iter:1050] Loss: 1.245 | Acc: 78.333% \n",
      "[epoch:5, iter:1051] Loss: 1.248 | Acc: 74.286% \n",
      "[epoch:5, iter:1052] Loss: 1.247 | Acc: 75.000% \n",
      "[epoch:5, iter:1053] Loss: 1.206 | Acc: 76.667% \n",
      "[epoch:5, iter:1054] Loss: 1.190 | Acc: 77.000% \n",
      "[epoch:5, iter:1055] Loss: 1.158 | Acc: 77.273% \n",
      "[epoch:5, iter:1056] Loss: 1.142 | Acc: 76.667% \n",
      "[epoch:5, iter:1057] Loss: 1.153 | Acc: 76.923% \n",
      "[epoch:5, iter:1058] Loss: 1.153 | Acc: 77.857% \n",
      "[epoch:5, iter:1059] Loss: 1.147 | Acc: 77.333% \n",
      "[epoch:5, iter:1060] Loss: 1.166 | Acc: 77.500% \n",
      "[epoch:5, iter:1061] Loss: 1.151 | Acc: 77.647% \n",
      "[epoch:5, iter:1062] Loss: 1.127 | Acc: 78.889% \n",
      "[epoch:5, iter:1063] Loss: 1.146 | Acc: 78.947% \n",
      "[epoch:5, iter:1064] Loss: 1.139 | Acc: 79.000% \n",
      "[epoch:5, iter:1065] Loss: 1.139 | Acc: 79.524% \n",
      "[epoch:5, iter:1066] Loss: 1.114 | Acc: 80.000% \n",
      "[epoch:5, iter:1067] Loss: 1.092 | Acc: 80.435% \n",
      "[epoch:5, iter:1068] Loss: 1.083 | Acc: 80.417% \n",
      "[epoch:5, iter:1069] Loss: 1.078 | Acc: 80.400% \n",
      "[epoch:5, iter:1070] Loss: 1.099 | Acc: 79.615% \n",
      "[epoch:5, iter:1071] Loss: 1.082 | Acc: 79.630% \n",
      "[epoch:5, iter:1072] Loss: 1.088 | Acc: 78.929% \n",
      "[epoch:5, iter:1073] Loss: 1.100 | Acc: 78.276% \n",
      "[epoch:5, iter:1074] Loss: 1.088 | Acc: 78.667% \n",
      "[epoch:5, iter:1075] Loss: 1.088 | Acc: 78.710% \n",
      "[epoch:5, iter:1076] Loss: 1.094 | Acc: 78.438% \n",
      "[epoch:5, iter:1077] Loss: 1.113 | Acc: 78.182% \n",
      "[epoch:5, iter:1078] Loss: 1.102 | Acc: 78.529% \n",
      "[epoch:5, iter:1079] Loss: 1.092 | Acc: 78.857% \n",
      "[epoch:5, iter:1080] Loss: 1.096 | Acc: 79.167% \n",
      "[epoch:5, iter:1081] Loss: 1.101 | Acc: 79.189% \n",
      "[epoch:5, iter:1082] Loss: 1.096 | Acc: 79.211% \n",
      "[epoch:5, iter:1083] Loss: 1.106 | Acc: 78.718% \n",
      "[epoch:5, iter:1084] Loss: 1.093 | Acc: 79.000% \n",
      "[epoch:5, iter:1085] Loss: 1.091 | Acc: 79.024% \n",
      "[epoch:5, iter:1086] Loss: 1.083 | Acc: 79.286% \n",
      "[epoch:5, iter:1087] Loss: 1.103 | Acc: 78.605% \n",
      "[epoch:5, iter:1088] Loss: 1.111 | Acc: 78.636% \n",
      "[epoch:5, iter:1089] Loss: 1.120 | Acc: 78.444% \n",
      "[epoch:5, iter:1090] Loss: 1.138 | Acc: 77.609% \n",
      "[epoch:5, iter:1091] Loss: 1.135 | Acc: 77.447% \n",
      "[epoch:5, iter:1092] Loss: 1.130 | Acc: 77.708% \n",
      "[epoch:5, iter:1093] Loss: 1.135 | Acc: 77.755% \n",
      "[epoch:5, iter:1094] Loss: 1.142 | Acc: 77.400% \n",
      "[epoch:5, iter:1095] Loss: 1.145 | Acc: 77.059% \n",
      "[epoch:5, iter:1096] Loss: 1.130 | Acc: 77.500% \n",
      "[epoch:5, iter:1097] Loss: 1.123 | Acc: 77.736% \n",
      "[epoch:5, iter:1098] Loss: 1.122 | Acc: 77.407% \n",
      "[epoch:5, iter:1099] Loss: 1.114 | Acc: 77.455% \n",
      "[epoch:5, iter:1100] Loss: 1.107 | Acc: 77.679% \n",
      "[epoch:5, iter:1101] Loss: 1.100 | Acc: 77.895% \n",
      "[epoch:5, iter:1102] Loss: 1.108 | Acc: 77.586% \n",
      "[epoch:5, iter:1103] Loss: 1.107 | Acc: 77.458% \n",
      "[epoch:5, iter:1104] Loss: 1.102 | Acc: 77.667% \n",
      "[epoch:5, iter:1105] Loss: 1.096 | Acc: 77.869% \n",
      "[epoch:5, iter:1106] Loss: 1.089 | Acc: 78.226% \n",
      "[epoch:5, iter:1107] Loss: 1.082 | Acc: 78.413% \n",
      "[epoch:5, iter:1108] Loss: 1.080 | Acc: 78.594% \n",
      "[epoch:5, iter:1109] Loss: 1.075 | Acc: 78.769% \n",
      "[epoch:5, iter:1110] Loss: 1.087 | Acc: 78.333% \n",
      "[epoch:5, iter:1111] Loss: 1.084 | Acc: 78.507% \n",
      "[epoch:5, iter:1112] Loss: 1.087 | Acc: 78.382% \n",
      "[epoch:5, iter:1113] Loss: 1.089 | Acc: 78.406% \n",
      "[epoch:5, iter:1114] Loss: 1.083 | Acc: 78.286% \n",
      "[epoch:5, iter:1115] Loss: 1.074 | Acc: 78.592% \n",
      "[epoch:5, iter:1116] Loss: 1.068 | Acc: 78.889% \n",
      "[epoch:5, iter:1117] Loss: 1.064 | Acc: 79.041% \n",
      "[epoch:5, iter:1118] Loss: 1.069 | Acc: 79.054% \n",
      "[epoch:5, iter:1119] Loss: 1.065 | Acc: 79.200% \n",
      "[epoch:5, iter:1120] Loss: 1.060 | Acc: 79.342% \n",
      "[epoch:5, iter:1121] Loss: 1.062 | Acc: 79.221% \n",
      "[epoch:5, iter:1122] Loss: 1.061 | Acc: 79.359% \n",
      "[epoch:5, iter:1123] Loss: 1.060 | Acc: 79.494% \n",
      "[epoch:5, iter:1124] Loss: 1.056 | Acc: 79.375% \n",
      "[epoch:5, iter:1125] Loss: 1.054 | Acc: 79.259% \n",
      "[epoch:5, iter:1126] Loss: 1.053 | Acc: 79.390% \n",
      "[epoch:5, iter:1127] Loss: 1.049 | Acc: 79.518% \n",
      "[epoch:5, iter:1128] Loss: 1.050 | Acc: 79.524% \n",
      "[epoch:5, iter:1129] Loss: 1.055 | Acc: 79.412% \n",
      "[epoch:5, iter:1130] Loss: 1.052 | Acc: 79.419% \n",
      "[epoch:5, iter:1131] Loss: 1.051 | Acc: 79.425% \n",
      "[epoch:5, iter:1132] Loss: 1.048 | Acc: 79.545% \n",
      "[epoch:5, iter:1133] Loss: 1.051 | Acc: 79.438% \n",
      "[epoch:5, iter:1134] Loss: 1.049 | Acc: 79.444% \n",
      "[epoch:5, iter:1135] Loss: 1.048 | Acc: 79.341% \n",
      "[epoch:5, iter:1136] Loss: 1.048 | Acc: 79.239% \n",
      "[epoch:5, iter:1137] Loss: 1.040 | Acc: 79.462% \n",
      "[epoch:5, iter:1138] Loss: 1.038 | Acc: 79.468% \n",
      "[epoch:5, iter:1139] Loss: 1.033 | Acc: 79.474% \n",
      "[epoch:5, iter:1140] Loss: 1.029 | Acc: 79.583% \n",
      "[epoch:5, iter:1141] Loss: 1.027 | Acc: 79.588% \n",
      "[epoch:5, iter:1142] Loss: 1.028 | Acc: 79.592% \n",
      "[epoch:5, iter:1143] Loss: 1.033 | Acc: 79.192% \n",
      "[epoch:5, iter:1144] Loss: 1.029 | Acc: 79.200% \n",
      "[epoch:5, iter:1145] Loss: 1.023 | Acc: 79.307% \n",
      "[epoch:5, iter:1146] Loss: 1.020 | Acc: 79.216% \n",
      "[epoch:5, iter:1147] Loss: 1.016 | Acc: 79.223% \n",
      "[epoch:5, iter:1148] Loss: 1.011 | Acc: 79.327% \n",
      "[epoch:5, iter:1149] Loss: 1.014 | Acc: 79.238% \n",
      "[epoch:5, iter:1150] Loss: 1.017 | Acc: 79.151% \n",
      "[epoch:5, iter:1151] Loss: 1.013 | Acc: 79.252% \n",
      "[epoch:5, iter:1152] Loss: 1.014 | Acc: 79.074% \n",
      "[epoch:5, iter:1153] Loss: 1.008 | Acc: 79.266% \n",
      "[epoch:5, iter:1154] Loss: 1.005 | Acc: 79.364% \n",
      "[epoch:5, iter:1155] Loss: 1.006 | Acc: 79.279% \n",
      "[epoch:5, iter:1156] Loss: 1.007 | Acc: 79.196% \n",
      "[epoch:5, iter:1157] Loss: 1.009 | Acc: 79.027% \n",
      "[epoch:5, iter:1158] Loss: 1.009 | Acc: 79.123% \n",
      "[epoch:5, iter:1159] Loss: 1.009 | Acc: 79.130% \n",
      "[epoch:5, iter:1160] Loss: 1.009 | Acc: 79.138% \n",
      "[epoch:5, iter:1161] Loss: 1.013 | Acc: 79.145% \n",
      "[epoch:5, iter:1162] Loss: 1.014 | Acc: 79.153% \n",
      "[epoch:5, iter:1163] Loss: 1.013 | Acc: 79.160% \n",
      "[epoch:5, iter:1164] Loss: 1.011 | Acc: 79.333% \n",
      "[epoch:5, iter:1165] Loss: 1.010 | Acc: 79.256% \n",
      "[epoch:5, iter:1166] Loss: 1.010 | Acc: 79.262% \n",
      "[epoch:5, iter:1167] Loss: 1.018 | Acc: 79.024% \n",
      "[epoch:5, iter:1168] Loss: 1.017 | Acc: 79.032% \n",
      "[epoch:5, iter:1169] Loss: 1.016 | Acc: 79.040% \n",
      "[epoch:5, iter:1170] Loss: 1.021 | Acc: 78.730% \n",
      "[epoch:5, iter:1171] Loss: 1.023 | Acc: 78.583% \n",
      "[epoch:5, iter:1172] Loss: 1.018 | Acc: 78.672% \n",
      "[epoch:5, iter:1173] Loss: 1.020 | Acc: 78.605% \n",
      "[epoch:5, iter:1174] Loss: 1.022 | Acc: 78.462% \n",
      "[epoch:5, iter:1175] Loss: 1.023 | Acc: 78.473% \n",
      "[epoch:5, iter:1176] Loss: 1.020 | Acc: 78.485% \n",
      "[epoch:5, iter:1177] Loss: 1.022 | Acc: 78.346% \n",
      "[epoch:5, iter:1178] Loss: 1.025 | Acc: 78.284% \n",
      "[epoch:5, iter:1179] Loss: 1.026 | Acc: 78.148% \n",
      "[epoch:5, iter:1180] Loss: 1.027 | Acc: 78.088% \n",
      "[epoch:5, iter:1181] Loss: 1.029 | Acc: 78.102% \n",
      "[epoch:5, iter:1182] Loss: 1.028 | Acc: 78.188% \n",
      "[epoch:5, iter:1183] Loss: 1.025 | Acc: 78.273% \n",
      "[epoch:5, iter:1184] Loss: 1.023 | Acc: 78.214% \n",
      "[epoch:5, iter:1185] Loss: 1.019 | Acc: 78.369% \n",
      "[epoch:5, iter:1186] Loss: 1.018 | Acc: 78.451% \n",
      "[epoch:5, iter:1187] Loss: 1.017 | Acc: 78.462% \n",
      "[epoch:5, iter:1188] Loss: 1.014 | Acc: 78.542% \n",
      "[epoch:5, iter:1189] Loss: 1.012 | Acc: 78.621% \n",
      "[epoch:5, iter:1190] Loss: 1.011 | Acc: 78.630% \n",
      "[epoch:5, iter:1191] Loss: 1.012 | Acc: 78.571% \n",
      "[epoch:5, iter:1192] Loss: 1.012 | Acc: 78.581% \n",
      "[epoch:5, iter:1193] Loss: 1.008 | Acc: 78.658% \n",
      "[epoch:5, iter:1194] Loss: 1.005 | Acc: 78.733% \n",
      "[epoch:5, iter:1195] Loss: 1.001 | Acc: 78.874% \n",
      "[epoch:5, iter:1196] Loss: 1.004 | Acc: 78.816% \n",
      "[epoch:5, iter:1197] Loss: 1.001 | Acc: 78.889% \n",
      "[epoch:5, iter:1198] Loss: 0.998 | Acc: 79.026% \n",
      "[epoch:5, iter:1199] Loss: 0.996 | Acc: 79.161% \n",
      "[epoch:5, iter:1200] Loss: 0.996 | Acc: 79.103% \n",
      "[epoch:5, iter:1201] Loss: 0.994 | Acc: 79.172% \n",
      "[epoch:5, iter:1202] Loss: 0.994 | Acc: 79.114% \n",
      "[epoch:5, iter:1203] Loss: 0.993 | Acc: 79.119% \n",
      "[epoch:5, iter:1204] Loss: 0.992 | Acc: 79.125% \n",
      "[epoch:5, iter:1205] Loss: 0.989 | Acc: 79.255% \n",
      "[epoch:5, iter:1206] Loss: 0.987 | Acc: 79.259% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:5, iter:1207] Loss: 0.988 | Acc: 79.202% \n",
      "[epoch:5, iter:1208] Loss: 0.990 | Acc: 79.146% \n",
      "[epoch:5, iter:1209] Loss: 0.989 | Acc: 79.152% \n",
      "[epoch:5, iter:1210] Loss: 0.991 | Acc: 79.157% \n",
      "[epoch:5, iter:1211] Loss: 0.990 | Acc: 79.162% \n",
      "[epoch:5, iter:1212] Loss: 0.991 | Acc: 79.048% \n",
      "[epoch:5, iter:1213] Loss: 0.992 | Acc: 78.994% \n",
      "[epoch:5, iter:1214] Loss: 0.991 | Acc: 79.000% \n",
      "[epoch:5, iter:1215] Loss: 0.993 | Acc: 79.064% \n",
      "[epoch:5, iter:1216] Loss: 0.990 | Acc: 79.186% \n",
      "[epoch:5, iter:1217] Loss: 0.989 | Acc: 79.191% \n",
      "[epoch:5, iter:1218] Loss: 0.986 | Acc: 79.310% \n",
      "[epoch:5, iter:1219] Loss: 0.986 | Acc: 79.257% \n",
      "[epoch:5, iter:1220] Loss: 0.986 | Acc: 79.261% \n",
      "[epoch:5, iter:1221] Loss: 0.987 | Acc: 79.209% \n",
      "[epoch:5, iter:1222] Loss: 0.989 | Acc: 79.157% \n",
      "[epoch:5, iter:1223] Loss: 0.988 | Acc: 79.218% \n",
      "[epoch:5, iter:1224] Loss: 0.987 | Acc: 79.222% \n",
      "[epoch:5, iter:1225] Loss: 0.985 | Acc: 79.282% \n",
      "[epoch:5, iter:1226] Loss: 0.985 | Acc: 79.231% \n",
      "[epoch:5, iter:1227] Loss: 0.985 | Acc: 79.290% \n",
      "[epoch:5, iter:1228] Loss: 0.983 | Acc: 79.348% \n",
      "[epoch:5, iter:1229] Loss: 0.979 | Acc: 79.405% \n",
      "[epoch:5, iter:1230] Loss: 0.978 | Acc: 79.409% \n",
      "[epoch:5, iter:1231] Loss: 0.978 | Acc: 79.412% \n",
      "[epoch:5, iter:1232] Loss: 0.976 | Acc: 79.521% \n",
      "[epoch:5, iter:1233] Loss: 0.975 | Acc: 79.577% \n",
      "[epoch:5, iter:1234] Loss: 0.977 | Acc: 79.579% \n",
      "[epoch:5, iter:1235] Loss: 0.977 | Acc: 79.581% \n",
      "[epoch:5, iter:1236] Loss: 0.977 | Acc: 79.635% \n",
      "[epoch:5, iter:1237] Loss: 0.975 | Acc: 79.689% \n",
      "[epoch:5, iter:1238] Loss: 0.974 | Acc: 79.691% \n",
      "[epoch:5, iter:1239] Loss: 0.973 | Acc: 79.692% \n",
      "[epoch:5, iter:1240] Loss: 0.973 | Acc: 79.745% \n",
      "[epoch:5, iter:1241] Loss: 0.973 | Acc: 79.645% \n",
      "[epoch:5, iter:1242] Loss: 0.973 | Acc: 79.697% \n",
      "[epoch:5, iter:1243] Loss: 0.972 | Acc: 79.749% \n",
      "[epoch:5, iter:1244] Loss: 0.971 | Acc: 79.750% \n",
      "[epoch:5, iter:1245] Loss: 0.971 | Acc: 79.701% \n",
      "[epoch:5, iter:1246] Loss: 0.967 | Acc: 79.802% \n",
      "[epoch:5, iter:1247] Loss: 0.967 | Acc: 79.852% \n",
      "[epoch:5, iter:1248] Loss: 0.969 | Acc: 79.804% \n",
      "[epoch:5, iter:1249] Loss: 0.971 | Acc: 79.756% \n",
      "[epoch:5, iter:1250] Loss: 0.969 | Acc: 79.757% \n",
      "[epoch:5, iter:1251] Loss: 0.968 | Acc: 79.807% \n",
      "[epoch:5, iter:1252] Loss: 0.970 | Acc: 79.760% \n",
      "[epoch:5, iter:1253] Loss: 0.967 | Acc: 79.856% \n",
      "[epoch:5, iter:1254] Loss: 0.967 | Acc: 79.810% \n",
      "[epoch:5, iter:1255] Loss: 0.964 | Acc: 79.858% \n",
      "[epoch:5, iter:1256] Loss: 0.961 | Acc: 79.906% \n",
      "[epoch:5, iter:1257] Loss: 0.962 | Acc: 79.906% \n",
      "[epoch:5, iter:1258] Loss: 0.961 | Acc: 79.953% \n",
      "[epoch:5, iter:1259] Loss: 0.963 | Acc: 79.860% \n",
      "[epoch:5, iter:1260] Loss: 0.960 | Acc: 79.954% \n",
      "[epoch:5, iter:1261] Loss: 0.960 | Acc: 79.954% \n",
      "[epoch:5, iter:1262] Loss: 0.958 | Acc: 79.954% \n",
      "[epoch:5, iter:1263] Loss: 0.959 | Acc: 79.909% \n",
      "[epoch:5, iter:1264] Loss: 0.957 | Acc: 80.000% \n",
      "[epoch:5, iter:1265] Loss: 0.956 | Acc: 80.045% \n",
      "[epoch:5, iter:1266] Loss: 0.956 | Acc: 80.045% \n",
      "[epoch:5, iter:1267] Loss: 0.957 | Acc: 80.045% \n",
      "[epoch:5, iter:1268] Loss: 0.959 | Acc: 80.045% \n",
      "[epoch:5, iter:1269] Loss: 0.959 | Acc: 79.956% \n",
      "[epoch:5, iter:1270] Loss: 0.957 | Acc: 80.044% \n",
      "[epoch:5, iter:1271] Loss: 0.955 | Acc: 80.044% \n",
      "[epoch:5, iter:1272] Loss: 0.954 | Acc: 80.088% \n",
      "[epoch:5, iter:1273] Loss: 0.952 | Acc: 80.087% \n",
      "[epoch:5, iter:1274] Loss: 0.950 | Acc: 80.087% \n",
      "[epoch:5, iter:1275] Loss: 0.949 | Acc: 80.130% \n",
      "[epoch:5, iter:1276] Loss: 0.951 | Acc: 80.129% \n",
      "[epoch:5, iter:1277] Loss: 0.949 | Acc: 80.172% \n",
      "[epoch:5, iter:1278] Loss: 0.951 | Acc: 80.128% \n",
      "[epoch:5, iter:1279] Loss: 0.949 | Acc: 80.213% \n",
      "[epoch:5, iter:1280] Loss: 0.947 | Acc: 80.212% \n",
      "[epoch:5, iter:1281] Loss: 0.947 | Acc: 80.211% \n",
      "[epoch:5, iter:1282] Loss: 0.948 | Acc: 80.210% \n",
      "[epoch:5, iter:1283] Loss: 0.947 | Acc: 80.209% \n",
      "[epoch:5, iter:1284] Loss: 0.947 | Acc: 80.208% \n",
      "[epoch:5, iter:1285] Loss: 0.946 | Acc: 80.249% \n",
      "[epoch:5, iter:1286] Loss: 0.944 | Acc: 80.289% \n",
      "[epoch:5, iter:1287] Loss: 0.946 | Acc: 80.247% \n",
      "[epoch:5, iter:1288] Loss: 0.945 | Acc: 80.287% \n",
      "[epoch:5, iter:1289] Loss: 0.948 | Acc: 80.286% \n",
      "[epoch:5, iter:1290] Loss: 0.949 | Acc: 80.285% \n",
      "[epoch:5, iter:1291] Loss: 0.946 | Acc: 80.324% \n",
      "[epoch:5, iter:1292] Loss: 0.947 | Acc: 80.242% \n",
      "[epoch:5, iter:1293] Loss: 0.947 | Acc: 80.241% \n",
      "[epoch:5, iter:1294] Loss: 0.947 | Acc: 80.240% \n",
      "[epoch:5, iter:1295] Loss: 0.946 | Acc: 80.239% \n",
      "[epoch:5, iter:1296] Loss: 0.944 | Acc: 80.278% \n",
      "[epoch:5, iter:1297] Loss: 0.944 | Acc: 80.237% \n",
      "[epoch:5, iter:1298] Loss: 0.946 | Acc: 80.118% \n",
      "[epoch:5, iter:1299] Loss: 0.945 | Acc: 80.118% \n",
      "[epoch:5, iter:1300] Loss: 0.943 | Acc: 80.195% \n",
      "[epoch:5, iter:1301] Loss: 0.941 | Acc: 80.272% \n",
      "[epoch:5, iter:1302] Loss: 0.939 | Acc: 80.349% \n",
      "[epoch:5, iter:1303] Loss: 0.939 | Acc: 80.309% \n",
      "[epoch:5, iter:1304] Loss: 0.940 | Acc: 80.308% \n",
      "[epoch:5, iter:1305] Loss: 0.936 | Acc: 80.315% \n",
      "\n",
      "Epoch: 6\n",
      "[epoch:6, iter:1306] Loss: 0.606 | Acc: 90.000% \n",
      "[epoch:6, iter:1307] Loss: 0.514 | Acc: 90.000% \n",
      "[epoch:6, iter:1308] Loss: 0.597 | Acc: 90.000% \n",
      "[epoch:6, iter:1309] Loss: 0.548 | Acc: 92.500% \n",
      "[epoch:6, iter:1310] Loss: 0.508 | Acc: 94.000% \n",
      "[epoch:6, iter:1311] Loss: 0.544 | Acc: 91.667% \n",
      "[epoch:6, iter:1312] Loss: 0.545 | Acc: 90.000% \n",
      "[epoch:6, iter:1313] Loss: 0.588 | Acc: 90.000% \n",
      "[epoch:6, iter:1314] Loss: 0.612 | Acc: 90.000% \n",
      "[epoch:6, iter:1315] Loss: 0.611 | Acc: 90.000% \n",
      "[epoch:6, iter:1316] Loss: 0.681 | Acc: 89.091% \n",
      "[epoch:6, iter:1317] Loss: 0.659 | Acc: 90.000% \n",
      "[epoch:6, iter:1318] Loss: 0.671 | Acc: 90.000% \n",
      "[epoch:6, iter:1319] Loss: 0.643 | Acc: 90.714% \n",
      "[epoch:6, iter:1320] Loss: 0.616 | Acc: 91.333% \n",
      "[epoch:6, iter:1321] Loss: 0.599 | Acc: 91.250% \n",
      "[epoch:6, iter:1322] Loss: 0.585 | Acc: 91.176% \n",
      "[epoch:6, iter:1323] Loss: 0.584 | Acc: 91.111% \n",
      "[epoch:6, iter:1324] Loss: 0.589 | Acc: 91.053% \n",
      "[epoch:6, iter:1325] Loss: 0.573 | Acc: 91.500% \n",
      "[epoch:6, iter:1326] Loss: 0.601 | Acc: 90.476% \n",
      "[epoch:6, iter:1327] Loss: 0.600 | Acc: 90.455% \n",
      "[epoch:6, iter:1328] Loss: 0.593 | Acc: 90.870% \n",
      "[epoch:6, iter:1329] Loss: 0.607 | Acc: 90.833% \n",
      "[epoch:6, iter:1330] Loss: 0.606 | Acc: 90.800% \n",
      "[epoch:6, iter:1331] Loss: 0.610 | Acc: 90.769% \n",
      "[epoch:6, iter:1332] Loss: 0.602 | Acc: 90.741% \n",
      "[epoch:6, iter:1333] Loss: 0.632 | Acc: 90.357% \n",
      "[epoch:6, iter:1334] Loss: 0.636 | Acc: 90.345% \n",
      "[epoch:6, iter:1335] Loss: 0.632 | Acc: 90.333% \n",
      "[epoch:6, iter:1336] Loss: 0.637 | Acc: 90.000% \n",
      "[epoch:6, iter:1337] Loss: 0.643 | Acc: 89.688% \n",
      "[epoch:6, iter:1338] Loss: 0.632 | Acc: 89.697% \n",
      "[epoch:6, iter:1339] Loss: 0.635 | Acc: 89.412% \n",
      "[epoch:6, iter:1340] Loss: 0.626 | Acc: 89.714% \n",
      "[epoch:6, iter:1341] Loss: 0.620 | Acc: 89.722% \n",
      "[epoch:6, iter:1342] Loss: 0.614 | Acc: 90.000% \n",
      "[epoch:6, iter:1343] Loss: 0.614 | Acc: 89.737% \n",
      "[epoch:6, iter:1344] Loss: 0.620 | Acc: 89.744% \n",
      "[epoch:6, iter:1345] Loss: 0.612 | Acc: 90.000% \n",
      "[epoch:6, iter:1346] Loss: 0.627 | Acc: 89.512% \n",
      "[epoch:6, iter:1347] Loss: 0.626 | Acc: 89.524% \n",
      "[epoch:6, iter:1348] Loss: 0.620 | Acc: 89.767% \n",
      "[epoch:6, iter:1349] Loss: 0.622 | Acc: 89.773% \n",
      "[epoch:6, iter:1350] Loss: 0.623 | Acc: 89.778% \n",
      "[epoch:6, iter:1351] Loss: 0.619 | Acc: 89.783% \n",
      "[epoch:6, iter:1352] Loss: 0.618 | Acc: 89.787% \n",
      "[epoch:6, iter:1353] Loss: 0.617 | Acc: 89.792% \n",
      "[epoch:6, iter:1354] Loss: 0.612 | Acc: 89.796% \n",
      "[epoch:6, iter:1355] Loss: 0.605 | Acc: 90.000% \n",
      "[epoch:6, iter:1356] Loss: 0.605 | Acc: 90.000% \n",
      "[epoch:6, iter:1357] Loss: 0.605 | Acc: 90.000% \n",
      "[epoch:6, iter:1358] Loss: 0.606 | Acc: 90.189% \n",
      "[epoch:6, iter:1359] Loss: 0.601 | Acc: 90.185% \n",
      "[epoch:6, iter:1360] Loss: 0.607 | Acc: 90.000% \n",
      "[epoch:6, iter:1361] Loss: 0.608 | Acc: 90.000% \n",
      "[epoch:6, iter:1362] Loss: 0.612 | Acc: 89.825% \n",
      "[epoch:6, iter:1363] Loss: 0.608 | Acc: 89.828% \n",
      "[epoch:6, iter:1364] Loss: 0.616 | Acc: 89.661% \n",
      "[epoch:6, iter:1365] Loss: 0.612 | Acc: 89.667% \n",
      "[epoch:6, iter:1366] Loss: 0.614 | Acc: 89.672% \n",
      "[epoch:6, iter:1367] Loss: 0.613 | Acc: 89.677% \n",
      "[epoch:6, iter:1368] Loss: 0.619 | Acc: 89.365% \n",
      "[epoch:6, iter:1369] Loss: 0.618 | Acc: 89.531% \n",
      "[epoch:6, iter:1370] Loss: 0.619 | Acc: 89.231% \n",
      "[epoch:6, iter:1371] Loss: 0.613 | Acc: 89.394% \n",
      "[epoch:6, iter:1372] Loss: 0.609 | Acc: 89.552% \n",
      "[epoch:6, iter:1373] Loss: 0.607 | Acc: 89.559% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:6, iter:1374] Loss: 0.604 | Acc: 89.565% \n",
      "[epoch:6, iter:1375] Loss: 0.605 | Acc: 89.571% \n",
      "[epoch:6, iter:1376] Loss: 0.598 | Acc: 89.718% \n",
      "[epoch:6, iter:1377] Loss: 0.598 | Acc: 89.583% \n",
      "[epoch:6, iter:1378] Loss: 0.592 | Acc: 89.726% \n",
      "[epoch:6, iter:1379] Loss: 0.595 | Acc: 89.459% \n",
      "[epoch:6, iter:1380] Loss: 0.599 | Acc: 89.333% \n",
      "[epoch:6, iter:1381] Loss: 0.599 | Acc: 89.211% \n",
      "[epoch:6, iter:1382] Loss: 0.600 | Acc: 89.091% \n",
      "[epoch:6, iter:1383] Loss: 0.597 | Acc: 89.103% \n",
      "[epoch:6, iter:1384] Loss: 0.595 | Acc: 89.114% \n",
      "[epoch:6, iter:1385] Loss: 0.606 | Acc: 88.750% \n",
      "[epoch:6, iter:1386] Loss: 0.606 | Acc: 88.765% \n",
      "[epoch:6, iter:1387] Loss: 0.610 | Acc: 88.537% \n",
      "[epoch:6, iter:1388] Loss: 0.606 | Acc: 88.675% \n",
      "[epoch:6, iter:1389] Loss: 0.604 | Acc: 88.690% \n",
      "[epoch:6, iter:1390] Loss: 0.600 | Acc: 88.824% \n",
      "[epoch:6, iter:1391] Loss: 0.600 | Acc: 88.837% \n",
      "[epoch:6, iter:1392] Loss: 0.598 | Acc: 88.966% \n",
      "[epoch:6, iter:1393] Loss: 0.602 | Acc: 88.977% \n",
      "[epoch:6, iter:1394] Loss: 0.605 | Acc: 88.876% \n",
      "[epoch:6, iter:1395] Loss: 0.606 | Acc: 88.889% \n",
      "[epoch:6, iter:1396] Loss: 0.611 | Acc: 88.791% \n",
      "[epoch:6, iter:1397] Loss: 0.614 | Acc: 88.804% \n",
      "[epoch:6, iter:1398] Loss: 0.617 | Acc: 88.710% \n",
      "[epoch:6, iter:1399] Loss: 0.619 | Acc: 88.723% \n",
      "[epoch:6, iter:1400] Loss: 0.619 | Acc: 88.737% \n",
      "[epoch:6, iter:1401] Loss: 0.620 | Acc: 88.750% \n",
      "[epoch:6, iter:1402] Loss: 0.621 | Acc: 88.557% \n",
      "[epoch:6, iter:1403] Loss: 0.622 | Acc: 88.367% \n",
      "[epoch:6, iter:1404] Loss: 0.624 | Acc: 88.384% \n",
      "[epoch:6, iter:1405] Loss: 0.626 | Acc: 88.300% \n",
      "[epoch:6, iter:1406] Loss: 0.622 | Acc: 88.416% \n",
      "[epoch:6, iter:1407] Loss: 0.621 | Acc: 88.431% \n",
      "[epoch:6, iter:1408] Loss: 0.621 | Acc: 88.447% \n",
      "[epoch:6, iter:1409] Loss: 0.619 | Acc: 88.558% \n",
      "[epoch:6, iter:1410] Loss: 0.619 | Acc: 88.476% \n",
      "[epoch:6, iter:1411] Loss: 0.621 | Acc: 88.396% \n",
      "[epoch:6, iter:1412] Loss: 0.622 | Acc: 88.131% \n",
      "[epoch:6, iter:1413] Loss: 0.621 | Acc: 88.056% \n",
      "[epoch:6, iter:1414] Loss: 0.628 | Acc: 87.890% \n",
      "[epoch:6, iter:1415] Loss: 0.626 | Acc: 87.909% \n",
      "[epoch:6, iter:1416] Loss: 0.623 | Acc: 88.018% \n",
      "[epoch:6, iter:1417] Loss: 0.620 | Acc: 88.125% \n",
      "[epoch:6, iter:1418] Loss: 0.619 | Acc: 88.142% \n",
      "[epoch:6, iter:1419] Loss: 0.619 | Acc: 88.158% \n",
      "[epoch:6, iter:1420] Loss: 0.618 | Acc: 88.261% \n",
      "[epoch:6, iter:1421] Loss: 0.619 | Acc: 88.190% \n",
      "[epoch:6, iter:1422] Loss: 0.619 | Acc: 88.205% \n",
      "[epoch:6, iter:1423] Loss: 0.620 | Acc: 88.136% \n",
      "[epoch:6, iter:1424] Loss: 0.619 | Acc: 88.235% \n",
      "[epoch:6, iter:1425] Loss: 0.620 | Acc: 88.167% \n",
      "[epoch:6, iter:1426] Loss: 0.616 | Acc: 88.264% \n",
      "[epoch:6, iter:1427] Loss: 0.613 | Acc: 88.361% \n",
      "[epoch:6, iter:1428] Loss: 0.616 | Acc: 88.293% \n",
      "[epoch:6, iter:1429] Loss: 0.617 | Acc: 88.306% \n",
      "[epoch:6, iter:1430] Loss: 0.616 | Acc: 88.320% \n",
      "[epoch:6, iter:1431] Loss: 0.613 | Acc: 88.413% \n",
      "[epoch:6, iter:1432] Loss: 0.611 | Acc: 88.425% \n",
      "[epoch:6, iter:1433] Loss: 0.610 | Acc: 88.516% \n",
      "[epoch:6, iter:1434] Loss: 0.608 | Acc: 88.605% \n",
      "[epoch:6, iter:1435] Loss: 0.614 | Acc: 88.385% \n",
      "[epoch:6, iter:1436] Loss: 0.613 | Acc: 88.397% \n",
      "[epoch:6, iter:1437] Loss: 0.611 | Acc: 88.409% \n",
      "[epoch:6, iter:1438] Loss: 0.614 | Acc: 88.271% \n",
      "[epoch:6, iter:1439] Loss: 0.615 | Acc: 88.209% \n",
      "[epoch:6, iter:1440] Loss: 0.616 | Acc: 88.222% \n",
      "[epoch:6, iter:1441] Loss: 0.613 | Acc: 88.309% \n",
      "[epoch:6, iter:1442] Loss: 0.615 | Acc: 88.248% \n",
      "[epoch:6, iter:1443] Loss: 0.613 | Acc: 88.333% \n",
      "[epoch:6, iter:1444] Loss: 0.617 | Acc: 88.129% \n",
      "[epoch:6, iter:1445] Loss: 0.614 | Acc: 88.214% \n",
      "[epoch:6, iter:1446] Loss: 0.612 | Acc: 88.298% \n",
      "[epoch:6, iter:1447] Loss: 0.611 | Acc: 88.310% \n",
      "[epoch:6, iter:1448] Loss: 0.612 | Acc: 88.322% \n",
      "[epoch:6, iter:1449] Loss: 0.613 | Acc: 88.333% \n",
      "[epoch:6, iter:1450] Loss: 0.614 | Acc: 88.276% \n",
      "[epoch:6, iter:1451] Loss: 0.616 | Acc: 88.151% \n",
      "[epoch:6, iter:1452] Loss: 0.618 | Acc: 88.095% \n",
      "[epoch:6, iter:1453] Loss: 0.620 | Acc: 88.041% \n",
      "[epoch:6, iter:1454] Loss: 0.619 | Acc: 88.121% \n",
      "[epoch:6, iter:1455] Loss: 0.620 | Acc: 88.000% \n",
      "[epoch:6, iter:1456] Loss: 0.617 | Acc: 88.079% \n",
      "[epoch:6, iter:1457] Loss: 0.620 | Acc: 87.961% \n",
      "[epoch:6, iter:1458] Loss: 0.621 | Acc: 88.039% \n",
      "[epoch:6, iter:1459] Loss: 0.622 | Acc: 88.052% \n",
      "[epoch:6, iter:1460] Loss: 0.623 | Acc: 88.000% \n",
      "[epoch:6, iter:1461] Loss: 0.620 | Acc: 88.077% \n",
      "[epoch:6, iter:1462] Loss: 0.619 | Acc: 88.089% \n",
      "[epoch:6, iter:1463] Loss: 0.618 | Acc: 88.101% \n",
      "[epoch:6, iter:1464] Loss: 0.616 | Acc: 88.113% \n",
      "[epoch:6, iter:1465] Loss: 0.615 | Acc: 88.125% \n",
      "[epoch:6, iter:1466] Loss: 0.618 | Acc: 87.950% \n",
      "[epoch:6, iter:1467] Loss: 0.618 | Acc: 87.963% \n",
      "[epoch:6, iter:1468] Loss: 0.617 | Acc: 87.975% \n",
      "[epoch:6, iter:1469] Loss: 0.617 | Acc: 87.927% \n",
      "[epoch:6, iter:1470] Loss: 0.619 | Acc: 87.879% \n",
      "[epoch:6, iter:1471] Loss: 0.618 | Acc: 87.892% \n",
      "[epoch:6, iter:1472] Loss: 0.617 | Acc: 87.904% \n",
      "[epoch:6, iter:1473] Loss: 0.616 | Acc: 87.917% \n",
      "[epoch:6, iter:1474] Loss: 0.616 | Acc: 87.929% \n",
      "[epoch:6, iter:1475] Loss: 0.616 | Acc: 87.882% \n",
      "[epoch:6, iter:1476] Loss: 0.616 | Acc: 87.778% \n",
      "[epoch:6, iter:1477] Loss: 0.616 | Acc: 87.791% \n",
      "[epoch:6, iter:1478] Loss: 0.615 | Acc: 87.803% \n",
      "[epoch:6, iter:1479] Loss: 0.618 | Acc: 87.701% \n",
      "[epoch:6, iter:1480] Loss: 0.619 | Acc: 87.657% \n",
      "[epoch:6, iter:1481] Loss: 0.617 | Acc: 87.727% \n",
      "[epoch:6, iter:1482] Loss: 0.619 | Acc: 87.684% \n",
      "[epoch:6, iter:1483] Loss: 0.620 | Acc: 87.640% \n",
      "[epoch:6, iter:1484] Loss: 0.620 | Acc: 87.654% \n",
      "[epoch:6, iter:1485] Loss: 0.620 | Acc: 87.611% \n",
      "[epoch:6, iter:1486] Loss: 0.622 | Acc: 87.624% \n",
      "[epoch:6, iter:1487] Loss: 0.623 | Acc: 87.527% \n",
      "[epoch:6, iter:1488] Loss: 0.622 | Acc: 87.596% \n",
      "[epoch:6, iter:1489] Loss: 0.622 | Acc: 87.609% \n",
      "[epoch:6, iter:1490] Loss: 0.623 | Acc: 87.514% \n",
      "[epoch:6, iter:1491] Loss: 0.623 | Acc: 87.527% \n",
      "[epoch:6, iter:1492] Loss: 0.624 | Acc: 87.540% \n",
      "[epoch:6, iter:1493] Loss: 0.625 | Acc: 87.500% \n",
      "[epoch:6, iter:1494] Loss: 0.624 | Acc: 87.513% \n",
      "[epoch:6, iter:1495] Loss: 0.622 | Acc: 87.579% \n",
      "[epoch:6, iter:1496] Loss: 0.622 | Acc: 87.592% \n",
      "[epoch:6, iter:1497] Loss: 0.623 | Acc: 87.500% \n",
      "[epoch:6, iter:1498] Loss: 0.622 | Acc: 87.513% \n",
      "[epoch:6, iter:1499] Loss: 0.623 | Acc: 87.474% \n",
      "[epoch:6, iter:1500] Loss: 0.624 | Acc: 87.487% \n",
      "[epoch:6, iter:1501] Loss: 0.623 | Acc: 87.500% \n",
      "[epoch:6, iter:1502] Loss: 0.624 | Acc: 87.513% \n",
      "[epoch:6, iter:1503] Loss: 0.624 | Acc: 87.525% \n",
      "[epoch:6, iter:1504] Loss: 0.625 | Acc: 87.487% \n",
      "[epoch:6, iter:1505] Loss: 0.624 | Acc: 87.500% \n",
      "[epoch:6, iter:1506] Loss: 0.623 | Acc: 87.512% \n",
      "[epoch:6, iter:1507] Loss: 0.623 | Acc: 87.475% \n",
      "[epoch:6, iter:1508] Loss: 0.623 | Acc: 87.438% \n",
      "[epoch:6, iter:1509] Loss: 0.624 | Acc: 87.451% \n",
      "[epoch:6, iter:1510] Loss: 0.622 | Acc: 87.512% \n",
      "[epoch:6, iter:1511] Loss: 0.622 | Acc: 87.573% \n",
      "[epoch:6, iter:1512] Loss: 0.621 | Acc: 87.633% \n",
      "[epoch:6, iter:1513] Loss: 0.619 | Acc: 87.644% \n",
      "[epoch:6, iter:1514] Loss: 0.620 | Acc: 87.608% \n",
      "[epoch:6, iter:1515] Loss: 0.621 | Acc: 87.619% \n",
      "[epoch:6, iter:1516] Loss: 0.624 | Acc: 87.536% \n",
      "[epoch:6, iter:1517] Loss: 0.625 | Acc: 87.547% \n",
      "[epoch:6, iter:1518] Loss: 0.624 | Acc: 87.559% \n",
      "[epoch:6, iter:1519] Loss: 0.627 | Acc: 87.430% \n",
      "[epoch:6, iter:1520] Loss: 0.625 | Acc: 87.488% \n",
      "[epoch:6, iter:1521] Loss: 0.627 | Acc: 87.407% \n",
      "[epoch:6, iter:1522] Loss: 0.627 | Acc: 87.419% \n",
      "[epoch:6, iter:1523] Loss: 0.626 | Acc: 87.385% \n",
      "[epoch:6, iter:1524] Loss: 0.625 | Acc: 87.443% \n",
      "[epoch:6, iter:1525] Loss: 0.624 | Acc: 87.455% \n",
      "[epoch:6, iter:1526] Loss: 0.627 | Acc: 87.376% \n",
      "[epoch:6, iter:1527] Loss: 0.625 | Acc: 87.387% \n",
      "[epoch:6, iter:1528] Loss: 0.626 | Acc: 87.354% \n",
      "[epoch:6, iter:1529] Loss: 0.626 | Acc: 87.321% \n",
      "[epoch:6, iter:1530] Loss: 0.626 | Acc: 87.378% \n",
      "[epoch:6, iter:1531] Loss: 0.625 | Acc: 87.389% \n",
      "[epoch:6, iter:1532] Loss: 0.625 | Acc: 87.401% \n",
      "[epoch:6, iter:1533] Loss: 0.628 | Acc: 87.281% \n",
      "[epoch:6, iter:1534] Loss: 0.628 | Acc: 87.293% \n",
      "[epoch:6, iter:1535] Loss: 0.628 | Acc: 87.304% \n",
      "[epoch:6, iter:1536] Loss: 0.627 | Acc: 87.359% \n",
      "[epoch:6, iter:1537] Loss: 0.626 | Acc: 87.371% \n",
      "[epoch:6, iter:1538] Loss: 0.626 | Acc: 87.425% \n",
      "[epoch:6, iter:1539] Loss: 0.625 | Acc: 87.479% \n",
      "[epoch:6, iter:1540] Loss: 0.623 | Acc: 87.532% \n",
      "[epoch:6, iter:1541] Loss: 0.623 | Acc: 87.500% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:6, iter:1542] Loss: 0.622 | Acc: 87.511% \n",
      "[epoch:6, iter:1543] Loss: 0.621 | Acc: 87.563% \n",
      "[epoch:6, iter:1544] Loss: 0.623 | Acc: 87.490% \n",
      "[epoch:6, iter:1545] Loss: 0.621 | Acc: 87.542% \n",
      "[epoch:6, iter:1546] Loss: 0.621 | Acc: 87.510% \n",
      "[epoch:6, iter:1547] Loss: 0.622 | Acc: 87.438% \n",
      "[epoch:6, iter:1548] Loss: 0.621 | Acc: 87.449% \n",
      "[epoch:6, iter:1549] Loss: 0.620 | Acc: 87.459% \n",
      "[epoch:6, iter:1550] Loss: 0.620 | Acc: 87.469% \n",
      "[epoch:6, iter:1551] Loss: 0.619 | Acc: 87.480% \n",
      "[epoch:6, iter:1552] Loss: 0.618 | Acc: 87.530% \n",
      "[epoch:6, iter:1553] Loss: 0.618 | Acc: 87.581% \n",
      "[epoch:6, iter:1554] Loss: 0.617 | Acc: 87.631% \n",
      "[epoch:6, iter:1555] Loss: 0.617 | Acc: 87.600% \n",
      "[epoch:6, iter:1556] Loss: 0.618 | Acc: 87.570% \n",
      "[epoch:6, iter:1557] Loss: 0.619 | Acc: 87.579% \n",
      "[epoch:6, iter:1558] Loss: 0.619 | Acc: 87.589% \n",
      "[epoch:6, iter:1559] Loss: 0.618 | Acc: 87.559% \n",
      "[epoch:6, iter:1560] Loss: 0.619 | Acc: 87.529% \n",
      "[epoch:6, iter:1561] Loss: 0.622 | Acc: 87.500% \n",
      "[epoch:6, iter:1562] Loss: 0.622 | Acc: 87.510% \n",
      "[epoch:6, iter:1563] Loss: 0.624 | Acc: 87.364% \n",
      "[epoch:6, iter:1564] Loss: 0.622 | Acc: 87.375% \n",
      "[epoch:6, iter:1565] Loss: 0.623 | Acc: 87.346% \n",
      "[epoch:6, iter:1566] Loss: 0.621 | Acc: 87.351% \n",
      "\n",
      "Epoch: 7\n",
      "[epoch:7, iter:1567] Loss: 1.014 | Acc: 90.000% \n",
      "[epoch:7, iter:1568] Loss: 0.682 | Acc: 85.000% \n",
      "[epoch:7, iter:1569] Loss: 0.585 | Acc: 90.000% \n",
      "[epoch:7, iter:1570] Loss: 0.478 | Acc: 92.500% \n",
      "[epoch:7, iter:1571] Loss: 0.418 | Acc: 94.000% \n",
      "[epoch:7, iter:1572] Loss: 0.387 | Acc: 95.000% \n",
      "[epoch:7, iter:1573] Loss: 0.358 | Acc: 94.286% \n",
      "[epoch:7, iter:1574] Loss: 0.394 | Acc: 92.500% \n",
      "[epoch:7, iter:1575] Loss: 0.398 | Acc: 91.111% \n",
      "[epoch:7, iter:1576] Loss: 0.406 | Acc: 91.000% \n",
      "[epoch:7, iter:1577] Loss: 0.417 | Acc: 90.909% \n",
      "[epoch:7, iter:1578] Loss: 0.410 | Acc: 91.667% \n",
      "[epoch:7, iter:1579] Loss: 0.413 | Acc: 91.538% \n",
      "[epoch:7, iter:1580] Loss: 0.419 | Acc: 91.429% \n",
      "[epoch:7, iter:1581] Loss: 0.431 | Acc: 91.333% \n",
      "[epoch:7, iter:1582] Loss: 0.424 | Acc: 91.875% \n",
      "[epoch:7, iter:1583] Loss: 0.430 | Acc: 91.765% \n",
      "[epoch:7, iter:1584] Loss: 0.437 | Acc: 91.111% \n",
      "[epoch:7, iter:1585] Loss: 0.453 | Acc: 90.526% \n",
      "[epoch:7, iter:1586] Loss: 0.451 | Acc: 90.500% \n",
      "[epoch:7, iter:1587] Loss: 0.449 | Acc: 90.952% \n",
      "[epoch:7, iter:1588] Loss: 0.441 | Acc: 91.364% \n",
      "[epoch:7, iter:1589] Loss: 0.435 | Acc: 91.739% \n",
      "[epoch:7, iter:1590] Loss: 0.424 | Acc: 92.083% \n",
      "[epoch:7, iter:1591] Loss: 0.413 | Acc: 92.400% \n",
      "[epoch:7, iter:1592] Loss: 0.427 | Acc: 91.923% \n",
      "[epoch:7, iter:1593] Loss: 0.427 | Acc: 91.852% \n",
      "[epoch:7, iter:1594] Loss: 0.423 | Acc: 91.786% \n",
      "[epoch:7, iter:1595] Loss: 0.414 | Acc: 92.069% \n",
      "[epoch:7, iter:1596] Loss: 0.426 | Acc: 91.667% \n",
      "[epoch:7, iter:1597] Loss: 0.430 | Acc: 91.290% \n",
      "[epoch:7, iter:1598] Loss: 0.423 | Acc: 91.562% \n",
      "[epoch:7, iter:1599] Loss: 0.427 | Acc: 91.212% \n",
      "[epoch:7, iter:1600] Loss: 0.421 | Acc: 91.471% \n",
      "[epoch:7, iter:1601] Loss: 0.417 | Acc: 91.429% \n",
      "[epoch:7, iter:1602] Loss: 0.411 | Acc: 91.667% \n",
      "[epoch:7, iter:1603] Loss: 0.416 | Acc: 91.622% \n",
      "[epoch:7, iter:1604] Loss: 0.421 | Acc: 91.579% \n",
      "[epoch:7, iter:1605] Loss: 0.418 | Acc: 91.795% \n",
      "[epoch:7, iter:1606] Loss: 0.409 | Acc: 92.000% \n",
      "[epoch:7, iter:1607] Loss: 0.407 | Acc: 91.951% \n",
      "[epoch:7, iter:1608] Loss: 0.406 | Acc: 91.905% \n",
      "[epoch:7, iter:1609] Loss: 0.411 | Acc: 91.628% \n",
      "[epoch:7, iter:1610] Loss: 0.410 | Acc: 91.591% \n",
      "[epoch:7, iter:1611] Loss: 0.408 | Acc: 91.778% \n",
      "[epoch:7, iter:1612] Loss: 0.406 | Acc: 91.957% \n",
      "[epoch:7, iter:1613] Loss: 0.405 | Acc: 91.915% \n",
      "[epoch:7, iter:1614] Loss: 0.405 | Acc: 91.875% \n",
      "[epoch:7, iter:1615] Loss: 0.409 | Acc: 91.633% \n",
      "[epoch:7, iter:1616] Loss: 0.411 | Acc: 91.400% \n",
      "[epoch:7, iter:1617] Loss: 0.409 | Acc: 91.373% \n",
      "[epoch:7, iter:1618] Loss: 0.413 | Acc: 91.346% \n",
      "[epoch:7, iter:1619] Loss: 0.411 | Acc: 91.509% \n",
      "[epoch:7, iter:1620] Loss: 0.405 | Acc: 91.667% \n",
      "[epoch:7, iter:1621] Loss: 0.407 | Acc: 91.636% \n",
      "[epoch:7, iter:1622] Loss: 0.404 | Acc: 91.786% \n",
      "[epoch:7, iter:1623] Loss: 0.410 | Acc: 91.579% \n",
      "[epoch:7, iter:1624] Loss: 0.416 | Acc: 91.379% \n",
      "[epoch:7, iter:1625] Loss: 0.417 | Acc: 91.356% \n",
      "[epoch:7, iter:1626] Loss: 0.416 | Acc: 91.333% \n",
      "[epoch:7, iter:1627] Loss: 0.417 | Acc: 91.475% \n",
      "[epoch:7, iter:1628] Loss: 0.425 | Acc: 91.290% \n",
      "[epoch:7, iter:1629] Loss: 0.430 | Acc: 91.111% \n",
      "[epoch:7, iter:1630] Loss: 0.431 | Acc: 91.094% \n",
      "[epoch:7, iter:1631] Loss: 0.431 | Acc: 91.077% \n",
      "[epoch:7, iter:1632] Loss: 0.429 | Acc: 91.212% \n",
      "[epoch:7, iter:1633] Loss: 0.434 | Acc: 91.045% \n",
      "[epoch:7, iter:1634] Loss: 0.433 | Acc: 91.176% \n",
      "[epoch:7, iter:1635] Loss: 0.436 | Acc: 91.014% \n",
      "[epoch:7, iter:1636] Loss: 0.434 | Acc: 91.000% \n",
      "[epoch:7, iter:1637] Loss: 0.438 | Acc: 90.986% \n",
      "[epoch:7, iter:1638] Loss: 0.439 | Acc: 90.833% \n",
      "[epoch:7, iter:1639] Loss: 0.437 | Acc: 90.822% \n",
      "[epoch:7, iter:1640] Loss: 0.437 | Acc: 90.946% \n",
      "[epoch:7, iter:1641] Loss: 0.439 | Acc: 90.933% \n",
      "[epoch:7, iter:1642] Loss: 0.442 | Acc: 90.921% \n",
      "[epoch:7, iter:1643] Loss: 0.442 | Acc: 91.039% \n",
      "[epoch:7, iter:1644] Loss: 0.439 | Acc: 91.154% \n",
      "[epoch:7, iter:1645] Loss: 0.440 | Acc: 91.139% \n",
      "[epoch:7, iter:1646] Loss: 0.439 | Acc: 91.125% \n",
      "[epoch:7, iter:1647] Loss: 0.436 | Acc: 91.235% \n",
      "[epoch:7, iter:1648] Loss: 0.434 | Acc: 91.341% \n",
      "[epoch:7, iter:1649] Loss: 0.436 | Acc: 91.325% \n",
      "[epoch:7, iter:1650] Loss: 0.435 | Acc: 91.429% \n",
      "[epoch:7, iter:1651] Loss: 0.434 | Acc: 91.529% \n",
      "[epoch:7, iter:1652] Loss: 0.431 | Acc: 91.628% \n",
      "[epoch:7, iter:1653] Loss: 0.431 | Acc: 91.609% \n",
      "[epoch:7, iter:1654] Loss: 0.429 | Acc: 91.591% \n",
      "[epoch:7, iter:1655] Loss: 0.428 | Acc: 91.685% \n",
      "[epoch:7, iter:1656] Loss: 0.427 | Acc: 91.778% \n",
      "[epoch:7, iter:1657] Loss: 0.430 | Acc: 91.648% \n",
      "[epoch:7, iter:1658] Loss: 0.428 | Acc: 91.739% \n",
      "[epoch:7, iter:1659] Loss: 0.431 | Acc: 91.720% \n",
      "[epoch:7, iter:1660] Loss: 0.431 | Acc: 91.702% \n",
      "[epoch:7, iter:1661] Loss: 0.432 | Acc: 91.684% \n",
      "[epoch:7, iter:1662] Loss: 0.432 | Acc: 91.667% \n",
      "[epoch:7, iter:1663] Loss: 0.429 | Acc: 91.753% \n",
      "[epoch:7, iter:1664] Loss: 0.427 | Acc: 91.837% \n",
      "[epoch:7, iter:1665] Loss: 0.429 | Acc: 91.818% \n",
      "[epoch:7, iter:1666] Loss: 0.428 | Acc: 91.800% \n",
      "[epoch:7, iter:1667] Loss: 0.428 | Acc: 91.782% \n",
      "[epoch:7, iter:1668] Loss: 0.424 | Acc: 91.863% \n",
      "[epoch:7, iter:1669] Loss: 0.424 | Acc: 91.845% \n",
      "[epoch:7, iter:1670] Loss: 0.426 | Acc: 91.635% \n",
      "[epoch:7, iter:1671] Loss: 0.425 | Acc: 91.524% \n",
      "[epoch:7, iter:1672] Loss: 0.431 | Acc: 91.321% \n",
      "[epoch:7, iter:1673] Loss: 0.433 | Acc: 91.215% \n",
      "[epoch:7, iter:1674] Loss: 0.434 | Acc: 91.204% \n",
      "[epoch:7, iter:1675] Loss: 0.432 | Acc: 91.284% \n",
      "[epoch:7, iter:1676] Loss: 0.429 | Acc: 91.364% \n",
      "[epoch:7, iter:1677] Loss: 0.435 | Acc: 91.171% \n",
      "[epoch:7, iter:1678] Loss: 0.433 | Acc: 91.161% \n",
      "[epoch:7, iter:1679] Loss: 0.433 | Acc: 91.150% \n",
      "[epoch:7, iter:1680] Loss: 0.431 | Acc: 91.228% \n",
      "[epoch:7, iter:1681] Loss: 0.430 | Acc: 91.217% \n",
      "[epoch:7, iter:1682] Loss: 0.437 | Acc: 91.034% \n",
      "[epoch:7, iter:1683] Loss: 0.436 | Acc: 91.026% \n",
      "[epoch:7, iter:1684] Loss: 0.438 | Acc: 91.017% \n",
      "[epoch:7, iter:1685] Loss: 0.438 | Acc: 91.008% \n",
      "[epoch:7, iter:1686] Loss: 0.440 | Acc: 90.917% \n",
      "[epoch:7, iter:1687] Loss: 0.439 | Acc: 90.909% \n",
      "[epoch:7, iter:1688] Loss: 0.438 | Acc: 90.902% \n",
      "[epoch:7, iter:1689] Loss: 0.437 | Acc: 90.976% \n",
      "[epoch:7, iter:1690] Loss: 0.434 | Acc: 91.048% \n",
      "[epoch:7, iter:1691] Loss: 0.434 | Acc: 91.040% \n",
      "[epoch:7, iter:1692] Loss: 0.434 | Acc: 91.111% \n",
      "[epoch:7, iter:1693] Loss: 0.433 | Acc: 91.102% \n",
      "[epoch:7, iter:1694] Loss: 0.441 | Acc: 90.938% \n",
      "[epoch:7, iter:1695] Loss: 0.440 | Acc: 91.008% \n",
      "[epoch:7, iter:1696] Loss: 0.439 | Acc: 91.077% \n",
      "[epoch:7, iter:1697] Loss: 0.439 | Acc: 91.069% \n",
      "[epoch:7, iter:1698] Loss: 0.439 | Acc: 91.061% \n",
      "[epoch:7, iter:1699] Loss: 0.441 | Acc: 91.128% \n",
      "[epoch:7, iter:1700] Loss: 0.440 | Acc: 91.194% \n",
      "[epoch:7, iter:1701] Loss: 0.440 | Acc: 91.185% \n",
      "[epoch:7, iter:1702] Loss: 0.438 | Acc: 91.250% \n",
      "[epoch:7, iter:1703] Loss: 0.441 | Acc: 91.168% \n",
      "[epoch:7, iter:1704] Loss: 0.439 | Acc: 91.232% \n",
      "[epoch:7, iter:1705] Loss: 0.438 | Acc: 91.223% \n",
      "[epoch:7, iter:1706] Loss: 0.437 | Acc: 91.214% \n",
      "[epoch:7, iter:1707] Loss: 0.435 | Acc: 91.277% \n",
      "[epoch:7, iter:1708] Loss: 0.434 | Acc: 91.338% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:7, iter:1709] Loss: 0.435 | Acc: 91.329% \n",
      "[epoch:7, iter:1710] Loss: 0.433 | Acc: 91.389% \n",
      "[epoch:7, iter:1711] Loss: 0.432 | Acc: 91.448% \n",
      "[epoch:7, iter:1712] Loss: 0.430 | Acc: 91.507% \n",
      "[epoch:7, iter:1713] Loss: 0.432 | Acc: 91.497% \n",
      "[epoch:7, iter:1714] Loss: 0.430 | Acc: 91.554% \n",
      "[epoch:7, iter:1715] Loss: 0.430 | Acc: 91.544% \n",
      "[epoch:7, iter:1716] Loss: 0.429 | Acc: 91.600% \n",
      "[epoch:7, iter:1717] Loss: 0.430 | Acc: 91.457% \n",
      "[epoch:7, iter:1718] Loss: 0.431 | Acc: 91.447% \n",
      "[epoch:7, iter:1719] Loss: 0.430 | Acc: 91.503% \n",
      "[epoch:7, iter:1720] Loss: 0.431 | Acc: 91.494% \n",
      "[epoch:7, iter:1721] Loss: 0.435 | Acc: 91.419% \n",
      "[epoch:7, iter:1722] Loss: 0.434 | Acc: 91.474% \n",
      "[epoch:7, iter:1723] Loss: 0.432 | Acc: 91.529% \n",
      "[epoch:7, iter:1724] Loss: 0.432 | Acc: 91.519% \n",
      "[epoch:7, iter:1725] Loss: 0.430 | Acc: 91.572% \n",
      "[epoch:7, iter:1726] Loss: 0.429 | Acc: 91.625% \n",
      "[epoch:7, iter:1727] Loss: 0.431 | Acc: 91.491% \n",
      "[epoch:7, iter:1728] Loss: 0.429 | Acc: 91.543% \n",
      "[epoch:7, iter:1729] Loss: 0.430 | Acc: 91.534% \n",
      "[epoch:7, iter:1730] Loss: 0.428 | Acc: 91.585% \n",
      "[epoch:7, iter:1731] Loss: 0.427 | Acc: 91.636% \n",
      "[epoch:7, iter:1732] Loss: 0.426 | Acc: 91.687% \n",
      "[epoch:7, iter:1733] Loss: 0.427 | Acc: 91.677% \n",
      "[epoch:7, iter:1734] Loss: 0.426 | Acc: 91.726% \n",
      "[epoch:7, iter:1735] Loss: 0.426 | Acc: 91.716% \n",
      "[epoch:7, iter:1736] Loss: 0.425 | Acc: 91.765% \n",
      "[epoch:7, iter:1737] Loss: 0.424 | Acc: 91.813% \n",
      "[epoch:7, iter:1738] Loss: 0.425 | Acc: 91.802% \n",
      "[epoch:7, iter:1739] Loss: 0.425 | Acc: 91.792% \n",
      "[epoch:7, iter:1740] Loss: 0.427 | Acc: 91.724% \n",
      "[epoch:7, iter:1741] Loss: 0.425 | Acc: 91.771% \n",
      "[epoch:7, iter:1742] Loss: 0.427 | Acc: 91.705% \n",
      "[epoch:7, iter:1743] Loss: 0.425 | Acc: 91.695% \n",
      "[epoch:7, iter:1744] Loss: 0.424 | Acc: 91.742% \n",
      "[epoch:7, iter:1745] Loss: 0.423 | Acc: 91.788% \n",
      "[epoch:7, iter:1746] Loss: 0.422 | Acc: 91.833% \n",
      "[epoch:7, iter:1747] Loss: 0.422 | Acc: 91.823% \n",
      "[epoch:7, iter:1748] Loss: 0.421 | Acc: 91.813% \n",
      "[epoch:7, iter:1749] Loss: 0.423 | Acc: 91.803% \n",
      "[epoch:7, iter:1750] Loss: 0.422 | Acc: 91.848% \n",
      "[epoch:7, iter:1751] Loss: 0.421 | Acc: 91.892% \n",
      "[epoch:7, iter:1752] Loss: 0.422 | Acc: 91.828% \n",
      "[epoch:7, iter:1753] Loss: 0.421 | Acc: 91.872% \n",
      "[epoch:7, iter:1754] Loss: 0.422 | Acc: 91.915% \n",
      "[epoch:7, iter:1755] Loss: 0.423 | Acc: 91.905% \n",
      "[epoch:7, iter:1756] Loss: 0.423 | Acc: 91.947% \n",
      "[epoch:7, iter:1757] Loss: 0.423 | Acc: 91.990% \n",
      "[epoch:7, iter:1758] Loss: 0.425 | Acc: 91.927% \n",
      "[epoch:7, iter:1759] Loss: 0.424 | Acc: 91.969% \n",
      "[epoch:7, iter:1760] Loss: 0.423 | Acc: 92.010% \n",
      "[epoch:7, iter:1761] Loss: 0.422 | Acc: 92.051% \n",
      "[epoch:7, iter:1762] Loss: 0.421 | Acc: 92.092% \n",
      "[epoch:7, iter:1763] Loss: 0.420 | Acc: 92.132% \n",
      "[epoch:7, iter:1764] Loss: 0.419 | Acc: 92.172% \n",
      "[epoch:7, iter:1765] Loss: 0.418 | Acc: 92.161% \n",
      "[epoch:7, iter:1766] Loss: 0.417 | Acc: 92.200% \n",
      "[epoch:7, iter:1767] Loss: 0.420 | Acc: 92.139% \n",
      "[epoch:7, iter:1768] Loss: 0.418 | Acc: 92.178% \n",
      "[epoch:7, iter:1769] Loss: 0.419 | Acc: 92.118% \n",
      "[epoch:7, iter:1770] Loss: 0.419 | Acc: 92.108% \n",
      "[epoch:7, iter:1771] Loss: 0.417 | Acc: 92.146% \n",
      "[epoch:7, iter:1772] Loss: 0.417 | Acc: 92.184% \n",
      "[epoch:7, iter:1773] Loss: 0.417 | Acc: 92.222% \n",
      "[epoch:7, iter:1774] Loss: 0.415 | Acc: 92.212% \n",
      "[epoch:7, iter:1775] Loss: 0.415 | Acc: 92.249% \n",
      "[epoch:7, iter:1776] Loss: 0.413 | Acc: 92.286% \n",
      "[epoch:7, iter:1777] Loss: 0.412 | Acc: 92.322% \n",
      "[epoch:7, iter:1778] Loss: 0.412 | Acc: 92.311% \n",
      "[epoch:7, iter:1779] Loss: 0.412 | Acc: 92.254% \n",
      "[epoch:7, iter:1780] Loss: 0.412 | Acc: 92.243% \n",
      "[epoch:7, iter:1781] Loss: 0.411 | Acc: 92.279% \n",
      "[epoch:7, iter:1782] Loss: 0.414 | Acc: 92.269% \n",
      "[epoch:7, iter:1783] Loss: 0.413 | Acc: 92.258% \n",
      "[epoch:7, iter:1784] Loss: 0.413 | Acc: 92.248% \n",
      "[epoch:7, iter:1785] Loss: 0.413 | Acc: 92.237% \n",
      "[epoch:7, iter:1786] Loss: 0.412 | Acc: 92.273% \n",
      "[epoch:7, iter:1787] Loss: 0.413 | Acc: 92.262% \n",
      "[epoch:7, iter:1788] Loss: 0.412 | Acc: 92.252% \n",
      "[epoch:7, iter:1789] Loss: 0.412 | Acc: 92.197% \n",
      "[epoch:7, iter:1790] Loss: 0.411 | Acc: 92.232% \n",
      "[epoch:7, iter:1791] Loss: 0.411 | Acc: 92.267% \n",
      "[epoch:7, iter:1792] Loss: 0.411 | Acc: 92.257% \n",
      "[epoch:7, iter:1793] Loss: 0.410 | Acc: 92.291% \n",
      "[epoch:7, iter:1794] Loss: 0.411 | Acc: 92.237% \n",
      "[epoch:7, iter:1795] Loss: 0.410 | Acc: 92.271% \n",
      "[epoch:7, iter:1796] Loss: 0.411 | Acc: 92.261% \n",
      "[epoch:7, iter:1797] Loss: 0.410 | Acc: 92.294% \n",
      "[epoch:7, iter:1798] Loss: 0.409 | Acc: 92.328% \n",
      "[epoch:7, iter:1799] Loss: 0.409 | Acc: 92.361% \n",
      "[epoch:7, iter:1800] Loss: 0.409 | Acc: 92.350% \n",
      "[epoch:7, iter:1801] Loss: 0.409 | Acc: 92.298% \n",
      "[epoch:7, iter:1802] Loss: 0.408 | Acc: 92.288% \n",
      "[epoch:7, iter:1803] Loss: 0.408 | Acc: 92.321% \n",
      "[epoch:7, iter:1804] Loss: 0.409 | Acc: 92.311% \n",
      "[epoch:7, iter:1805] Loss: 0.408 | Acc: 92.343% \n",
      "[epoch:7, iter:1806] Loss: 0.408 | Acc: 92.375% \n",
      "[epoch:7, iter:1807] Loss: 0.407 | Acc: 92.407% \n",
      "[epoch:7, iter:1808] Loss: 0.406 | Acc: 92.438% \n",
      "[epoch:7, iter:1809] Loss: 0.406 | Acc: 92.469% \n",
      "[epoch:7, iter:1810] Loss: 0.407 | Acc: 92.459% \n",
      "[epoch:7, iter:1811] Loss: 0.406 | Acc: 92.490% \n",
      "[epoch:7, iter:1812] Loss: 0.408 | Acc: 92.480% \n",
      "[epoch:7, iter:1813] Loss: 0.407 | Acc: 92.510% \n",
      "[epoch:7, iter:1814] Loss: 0.407 | Acc: 92.500% \n",
      "[epoch:7, iter:1815] Loss: 0.408 | Acc: 92.490% \n",
      "[epoch:7, iter:1816] Loss: 0.407 | Acc: 92.520% \n",
      "[epoch:7, iter:1817] Loss: 0.408 | Acc: 92.470% \n",
      "[epoch:7, iter:1818] Loss: 0.408 | Acc: 92.460% \n",
      "[epoch:7, iter:1819] Loss: 0.407 | Acc: 92.451% \n",
      "[epoch:7, iter:1820] Loss: 0.407 | Acc: 92.480% \n",
      "[epoch:7, iter:1821] Loss: 0.406 | Acc: 92.510% \n",
      "[epoch:7, iter:1822] Loss: 0.407 | Acc: 92.500% \n",
      "[epoch:7, iter:1823] Loss: 0.407 | Acc: 92.451% \n",
      "[epoch:7, iter:1824] Loss: 0.406 | Acc: 92.481% \n",
      "[epoch:7, iter:1825] Loss: 0.405 | Acc: 92.510% \n",
      "[epoch:7, iter:1826] Loss: 0.405 | Acc: 92.500% \n",
      "[epoch:7, iter:1827] Loss: 0.411 | Acc: 92.464% \n",
      "\n",
      "Epoch: 8\n",
      "[epoch:8, iter:1828] Loss: 0.940 | Acc: 70.000% \n",
      "[epoch:8, iter:1829] Loss: 0.575 | Acc: 85.000% \n",
      "[epoch:8, iter:1830] Loss: 0.409 | Acc: 90.000% \n",
      "[epoch:8, iter:1831] Loss: 0.348 | Acc: 92.500% \n",
      "[epoch:8, iter:1832] Loss: 0.344 | Acc: 94.000% \n",
      "[epoch:8, iter:1833] Loss: 0.372 | Acc: 93.333% \n",
      "[epoch:8, iter:1834] Loss: 0.341 | Acc: 94.286% \n",
      "[epoch:8, iter:1835] Loss: 0.327 | Acc: 95.000% \n",
      "[epoch:8, iter:1836] Loss: 0.324 | Acc: 93.333% \n",
      "[epoch:8, iter:1837] Loss: 0.304 | Acc: 94.000% \n",
      "[epoch:8, iter:1838] Loss: 0.320 | Acc: 92.727% \n",
      "[epoch:8, iter:1839] Loss: 0.301 | Acc: 93.333% \n",
      "[epoch:8, iter:1840] Loss: 0.304 | Acc: 93.077% \n",
      "[epoch:8, iter:1841] Loss: 0.308 | Acc: 92.857% \n",
      "[epoch:8, iter:1842] Loss: 0.311 | Acc: 93.333% \n",
      "[epoch:8, iter:1843] Loss: 0.326 | Acc: 93.125% \n",
      "[epoch:8, iter:1844] Loss: 0.326 | Acc: 93.529% \n",
      "[epoch:8, iter:1845] Loss: 0.330 | Acc: 93.333% \n",
      "[epoch:8, iter:1846] Loss: 0.333 | Acc: 93.684% \n",
      "[epoch:8, iter:1847] Loss: 0.334 | Acc: 93.500% \n",
      "[epoch:8, iter:1848] Loss: 0.337 | Acc: 92.857% \n",
      "[epoch:8, iter:1849] Loss: 0.333 | Acc: 93.182% \n",
      "[epoch:8, iter:1850] Loss: 0.331 | Acc: 93.043% \n",
      "[epoch:8, iter:1851] Loss: 0.329 | Acc: 93.333% \n",
      "[epoch:8, iter:1852] Loss: 0.331 | Acc: 93.200% \n",
      "[epoch:8, iter:1853] Loss: 0.338 | Acc: 93.077% \n",
      "[epoch:8, iter:1854] Loss: 0.330 | Acc: 93.333% \n",
      "[epoch:8, iter:1855] Loss: 0.327 | Acc: 93.214% \n",
      "[epoch:8, iter:1856] Loss: 0.323 | Acc: 93.448% \n",
      "[epoch:8, iter:1857] Loss: 0.329 | Acc: 93.000% \n",
      "[epoch:8, iter:1858] Loss: 0.327 | Acc: 92.903% \n",
      "[epoch:8, iter:1859] Loss: 0.324 | Acc: 92.812% \n",
      "[epoch:8, iter:1860] Loss: 0.327 | Acc: 92.727% \n",
      "[epoch:8, iter:1861] Loss: 0.340 | Acc: 92.353% \n",
      "[epoch:8, iter:1862] Loss: 0.337 | Acc: 92.571% \n",
      "[epoch:8, iter:1863] Loss: 0.334 | Acc: 92.778% \n",
      "[epoch:8, iter:1864] Loss: 0.334 | Acc: 92.703% \n",
      "[epoch:8, iter:1865] Loss: 0.333 | Acc: 92.895% \n",
      "[epoch:8, iter:1866] Loss: 0.336 | Acc: 92.821% \n",
      "[epoch:8, iter:1867] Loss: 0.342 | Acc: 92.750% \n",
      "[epoch:8, iter:1868] Loss: 0.344 | Acc: 92.683% \n",
      "[epoch:8, iter:1869] Loss: 0.340 | Acc: 92.857% \n",
      "[epoch:8, iter:1870] Loss: 0.338 | Acc: 93.023% \n",
      "[epoch:8, iter:1871] Loss: 0.333 | Acc: 93.182% \n",
      "[epoch:8, iter:1872] Loss: 0.337 | Acc: 93.111% \n",
      "[epoch:8, iter:1873] Loss: 0.345 | Acc: 93.043% \n",
      "[epoch:8, iter:1874] Loss: 0.343 | Acc: 93.191% \n",
      "[epoch:8, iter:1875] Loss: 0.340 | Acc: 93.333% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:8, iter:1876] Loss: 0.341 | Acc: 93.469% \n",
      "[epoch:8, iter:1877] Loss: 0.344 | Acc: 93.400% \n",
      "[epoch:8, iter:1878] Loss: 0.342 | Acc: 93.333% \n",
      "[epoch:8, iter:1879] Loss: 0.342 | Acc: 93.269% \n",
      "[epoch:8, iter:1880] Loss: 0.338 | Acc: 93.396% \n",
      "[epoch:8, iter:1881] Loss: 0.336 | Acc: 93.333% \n",
      "[epoch:8, iter:1882] Loss: 0.334 | Acc: 93.273% \n",
      "[epoch:8, iter:1883] Loss: 0.337 | Acc: 93.214% \n",
      "[epoch:8, iter:1884] Loss: 0.343 | Acc: 93.333% \n",
      "[epoch:8, iter:1885] Loss: 0.343 | Acc: 93.276% \n",
      "[epoch:8, iter:1886] Loss: 0.343 | Acc: 93.220% \n",
      "[epoch:8, iter:1887] Loss: 0.345 | Acc: 93.000% \n",
      "[epoch:8, iter:1888] Loss: 0.340 | Acc: 93.115% \n",
      "[epoch:8, iter:1889] Loss: 0.340 | Acc: 93.065% \n",
      "[epoch:8, iter:1890] Loss: 0.338 | Acc: 93.175% \n",
      "[epoch:8, iter:1891] Loss: 0.335 | Acc: 93.281% \n",
      "[epoch:8, iter:1892] Loss: 0.336 | Acc: 93.077% \n",
      "[epoch:8, iter:1893] Loss: 0.333 | Acc: 93.182% \n",
      "[epoch:8, iter:1894] Loss: 0.331 | Acc: 93.284% \n",
      "[epoch:8, iter:1895] Loss: 0.331 | Acc: 93.235% \n",
      "[epoch:8, iter:1896] Loss: 0.332 | Acc: 93.188% \n",
      "[epoch:8, iter:1897] Loss: 0.333 | Acc: 93.143% \n",
      "[epoch:8, iter:1898] Loss: 0.331 | Acc: 93.239% \n",
      "[epoch:8, iter:1899] Loss: 0.329 | Acc: 93.333% \n",
      "[epoch:8, iter:1900] Loss: 0.327 | Acc: 93.425% \n",
      "[epoch:8, iter:1901] Loss: 0.323 | Acc: 93.514% \n",
      "[epoch:8, iter:1902] Loss: 0.323 | Acc: 93.600% \n",
      "[epoch:8, iter:1903] Loss: 0.320 | Acc: 93.684% \n",
      "[epoch:8, iter:1904] Loss: 0.318 | Acc: 93.766% \n",
      "[epoch:8, iter:1905] Loss: 0.317 | Acc: 93.846% \n",
      "[epoch:8, iter:1906] Loss: 0.317 | Acc: 93.924% \n",
      "[epoch:8, iter:1907] Loss: 0.316 | Acc: 94.000% \n",
      "[epoch:8, iter:1908] Loss: 0.313 | Acc: 94.074% \n",
      "[epoch:8, iter:1909] Loss: 0.311 | Acc: 94.146% \n",
      "[epoch:8, iter:1910] Loss: 0.313 | Acc: 93.976% \n",
      "[epoch:8, iter:1911] Loss: 0.317 | Acc: 93.929% \n",
      "[epoch:8, iter:1912] Loss: 0.320 | Acc: 93.765% \n",
      "[epoch:8, iter:1913] Loss: 0.317 | Acc: 93.837% \n",
      "[epoch:8, iter:1914] Loss: 0.316 | Acc: 93.908% \n",
      "[epoch:8, iter:1915] Loss: 0.315 | Acc: 93.864% \n",
      "[epoch:8, iter:1916] Loss: 0.313 | Acc: 93.933% \n",
      "[epoch:8, iter:1917] Loss: 0.315 | Acc: 93.889% \n",
      "[epoch:8, iter:1918] Loss: 0.315 | Acc: 93.956% \n",
      "[epoch:8, iter:1919] Loss: 0.314 | Acc: 94.022% \n",
      "[epoch:8, iter:1920] Loss: 0.312 | Acc: 94.086% \n",
      "[epoch:8, iter:1921] Loss: 0.311 | Acc: 94.149% \n",
      "[epoch:8, iter:1922] Loss: 0.311 | Acc: 94.105% \n",
      "[epoch:8, iter:1923] Loss: 0.309 | Acc: 94.167% \n",
      "[epoch:8, iter:1924] Loss: 0.309 | Acc: 94.227% \n",
      "[epoch:8, iter:1925] Loss: 0.312 | Acc: 94.082% \n",
      "[epoch:8, iter:1926] Loss: 0.310 | Acc: 94.040% \n",
      "[epoch:8, iter:1927] Loss: 0.309 | Acc: 94.100% \n",
      "[epoch:8, iter:1928] Loss: 0.310 | Acc: 94.158% \n",
      "[epoch:8, iter:1929] Loss: 0.312 | Acc: 94.216% \n",
      "[epoch:8, iter:1930] Loss: 0.314 | Acc: 94.175% \n",
      "[epoch:8, iter:1931] Loss: 0.313 | Acc: 94.231% \n",
      "[epoch:8, iter:1932] Loss: 0.313 | Acc: 94.190% \n",
      "[epoch:8, iter:1933] Loss: 0.312 | Acc: 94.151% \n",
      "[epoch:8, iter:1934] Loss: 0.312 | Acc: 94.112% \n",
      "[epoch:8, iter:1935] Loss: 0.313 | Acc: 94.074% \n",
      "[epoch:8, iter:1936] Loss: 0.313 | Acc: 94.037% \n",
      "[epoch:8, iter:1937] Loss: 0.311 | Acc: 94.091% \n",
      "[epoch:8, iter:1938] Loss: 0.313 | Acc: 93.964% \n",
      "[epoch:8, iter:1939] Loss: 0.315 | Acc: 93.929% \n",
      "[epoch:8, iter:1940] Loss: 0.314 | Acc: 93.982% \n",
      "[epoch:8, iter:1941] Loss: 0.314 | Acc: 93.947% \n",
      "[epoch:8, iter:1942] Loss: 0.315 | Acc: 94.000% \n",
      "[epoch:8, iter:1943] Loss: 0.316 | Acc: 93.966% \n",
      "[epoch:8, iter:1944] Loss: 0.316 | Acc: 94.017% \n",
      "[epoch:8, iter:1945] Loss: 0.319 | Acc: 93.983% \n",
      "[epoch:8, iter:1946] Loss: 0.318 | Acc: 94.034% \n",
      "[epoch:8, iter:1947] Loss: 0.316 | Acc: 94.083% \n",
      "[epoch:8, iter:1948] Loss: 0.314 | Acc: 94.132% \n",
      "[epoch:8, iter:1949] Loss: 0.313 | Acc: 94.180% \n",
      "[epoch:8, iter:1950] Loss: 0.313 | Acc: 94.146% \n",
      "[epoch:8, iter:1951] Loss: 0.314 | Acc: 94.032% \n",
      "[epoch:8, iter:1952] Loss: 0.312 | Acc: 94.080% \n",
      "[epoch:8, iter:1953] Loss: 0.311 | Acc: 94.048% \n",
      "[epoch:8, iter:1954] Loss: 0.311 | Acc: 94.016% \n",
      "[epoch:8, iter:1955] Loss: 0.309 | Acc: 94.062% \n",
      "[epoch:8, iter:1956] Loss: 0.308 | Acc: 94.109% \n",
      "[epoch:8, iter:1957] Loss: 0.311 | Acc: 93.923% \n",
      "[epoch:8, iter:1958] Loss: 0.312 | Acc: 93.893% \n",
      "[epoch:8, iter:1959] Loss: 0.312 | Acc: 93.864% \n",
      "[epoch:8, iter:1960] Loss: 0.312 | Acc: 93.910% \n",
      "[epoch:8, iter:1961] Loss: 0.311 | Acc: 93.955% \n",
      "[epoch:8, iter:1962] Loss: 0.310 | Acc: 94.000% \n",
      "[epoch:8, iter:1963] Loss: 0.309 | Acc: 93.971% \n",
      "[epoch:8, iter:1964] Loss: 0.309 | Acc: 94.015% \n",
      "[epoch:8, iter:1965] Loss: 0.308 | Acc: 94.058% \n",
      "[epoch:8, iter:1966] Loss: 0.308 | Acc: 94.029% \n",
      "[epoch:8, iter:1967] Loss: 0.309 | Acc: 94.071% \n",
      "[epoch:8, iter:1968] Loss: 0.308 | Acc: 94.113% \n",
      "[epoch:8, iter:1969] Loss: 0.310 | Acc: 94.085% \n",
      "[epoch:8, iter:1970] Loss: 0.310 | Acc: 94.056% \n",
      "[epoch:8, iter:1971] Loss: 0.309 | Acc: 94.097% \n",
      "[epoch:8, iter:1972] Loss: 0.307 | Acc: 94.138% \n",
      "[epoch:8, iter:1973] Loss: 0.306 | Acc: 94.178% \n",
      "[epoch:8, iter:1974] Loss: 0.306 | Acc: 94.150% \n",
      "[epoch:8, iter:1975] Loss: 0.305 | Acc: 94.122% \n",
      "[epoch:8, iter:1976] Loss: 0.304 | Acc: 94.161% \n",
      "[epoch:8, iter:1977] Loss: 0.305 | Acc: 94.067% \n",
      "[epoch:8, iter:1978] Loss: 0.305 | Acc: 94.040% \n",
      "[epoch:8, iter:1979] Loss: 0.305 | Acc: 94.079% \n",
      "[epoch:8, iter:1980] Loss: 0.303 | Acc: 94.118% \n",
      "[epoch:8, iter:1981] Loss: 0.304 | Acc: 94.091% \n",
      "[epoch:8, iter:1982] Loss: 0.303 | Acc: 94.065% \n",
      "[epoch:8, iter:1983] Loss: 0.304 | Acc: 94.038% \n",
      "[epoch:8, iter:1984] Loss: 0.304 | Acc: 94.076% \n",
      "[epoch:8, iter:1985] Loss: 0.305 | Acc: 93.987% \n",
      "[epoch:8, iter:1986] Loss: 0.304 | Acc: 94.025% \n",
      "[epoch:8, iter:1987] Loss: 0.303 | Acc: 94.062% \n",
      "[epoch:8, iter:1988] Loss: 0.302 | Acc: 94.099% \n",
      "[epoch:8, iter:1989] Loss: 0.302 | Acc: 94.136% \n",
      "[epoch:8, iter:1990] Loss: 0.301 | Acc: 94.172% \n",
      "[epoch:8, iter:1991] Loss: 0.301 | Acc: 94.207% \n",
      "[epoch:8, iter:1992] Loss: 0.299 | Acc: 94.242% \n",
      "[epoch:8, iter:1993] Loss: 0.299 | Acc: 94.277% \n",
      "[epoch:8, iter:1994] Loss: 0.299 | Acc: 94.192% \n",
      "[epoch:8, iter:1995] Loss: 0.298 | Acc: 94.226% \n",
      "[epoch:8, iter:1996] Loss: 0.299 | Acc: 94.201% \n",
      "[epoch:8, iter:1997] Loss: 0.299 | Acc: 94.235% \n",
      "[epoch:8, iter:1998] Loss: 0.297 | Acc: 94.269% \n",
      "[epoch:8, iter:1999] Loss: 0.298 | Acc: 94.302% \n",
      "[epoch:8, iter:2000] Loss: 0.299 | Acc: 94.277% \n",
      "[epoch:8, iter:2001] Loss: 0.298 | Acc: 94.310% \n",
      "[epoch:8, iter:2002] Loss: 0.298 | Acc: 94.286% \n",
      "[epoch:8, iter:2003] Loss: 0.298 | Acc: 94.261% \n",
      "[epoch:8, iter:2004] Loss: 0.297 | Acc: 94.294% \n",
      "[epoch:8, iter:2005] Loss: 0.297 | Acc: 94.326% \n",
      "[epoch:8, iter:2006] Loss: 0.295 | Acc: 94.358% \n",
      "[epoch:8, iter:2007] Loss: 0.295 | Acc: 94.389% \n",
      "[epoch:8, iter:2008] Loss: 0.295 | Acc: 94.365% \n",
      "[epoch:8, iter:2009] Loss: 0.299 | Acc: 94.286% \n",
      "[epoch:8, iter:2010] Loss: 0.298 | Acc: 94.317% \n",
      "[epoch:8, iter:2011] Loss: 0.297 | Acc: 94.348% \n",
      "[epoch:8, iter:2012] Loss: 0.297 | Acc: 94.378% \n",
      "[epoch:8, iter:2013] Loss: 0.296 | Acc: 94.409% \n",
      "[epoch:8, iter:2014] Loss: 0.296 | Acc: 94.439% \n",
      "[epoch:8, iter:2015] Loss: 0.295 | Acc: 94.468% \n",
      "[epoch:8, iter:2016] Loss: 0.295 | Acc: 94.497% \n",
      "[epoch:8, iter:2017] Loss: 0.295 | Acc: 94.526% \n",
      "[epoch:8, iter:2018] Loss: 0.295 | Acc: 94.555% \n",
      "[epoch:8, iter:2019] Loss: 0.295 | Acc: 94.583% \n",
      "[epoch:8, iter:2020] Loss: 0.294 | Acc: 94.611% \n",
      "[epoch:8, iter:2021] Loss: 0.294 | Acc: 94.588% \n",
      "[epoch:8, iter:2022] Loss: 0.295 | Acc: 94.564% \n",
      "[epoch:8, iter:2023] Loss: 0.296 | Acc: 94.541% \n",
      "[epoch:8, iter:2024] Loss: 0.295 | Acc: 94.569% \n",
      "[epoch:8, iter:2025] Loss: 0.294 | Acc: 94.596% \n",
      "[epoch:8, iter:2026] Loss: 0.297 | Acc: 94.472% \n",
      "[epoch:8, iter:2027] Loss: 0.296 | Acc: 94.500% \n",
      "[epoch:8, iter:2028] Loss: 0.296 | Acc: 94.527% \n",
      "[epoch:8, iter:2029] Loss: 0.296 | Acc: 94.505% \n",
      "[epoch:8, iter:2030] Loss: 0.297 | Acc: 94.532% \n",
      "[epoch:8, iter:2031] Loss: 0.297 | Acc: 94.461% \n",
      "[epoch:8, iter:2032] Loss: 0.296 | Acc: 94.488% \n",
      "[epoch:8, iter:2033] Loss: 0.297 | Acc: 94.466% \n",
      "[epoch:8, iter:2034] Loss: 0.297 | Acc: 94.444% \n",
      "[epoch:8, iter:2035] Loss: 0.296 | Acc: 94.471% \n",
      "[epoch:8, iter:2036] Loss: 0.295 | Acc: 94.498% \n",
      "[epoch:8, iter:2037] Loss: 0.295 | Acc: 94.524% \n",
      "[epoch:8, iter:2038] Loss: 0.294 | Acc: 94.550% \n",
      "[epoch:8, iter:2039] Loss: 0.294 | Acc: 94.575% \n",
      "[epoch:8, iter:2040] Loss: 0.294 | Acc: 94.601% \n",
      "[epoch:8, iter:2041] Loss: 0.293 | Acc: 94.626% \n",
      "[epoch:8, iter:2042] Loss: 0.293 | Acc: 94.605% \n",
      "[epoch:8, iter:2043] Loss: 0.292 | Acc: 94.630% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:8, iter:2044] Loss: 0.291 | Acc: 94.654% \n",
      "[epoch:8, iter:2045] Loss: 0.291 | Acc: 94.633% \n",
      "[epoch:8, iter:2046] Loss: 0.293 | Acc: 94.521% \n",
      "[epoch:8, iter:2047] Loss: 0.293 | Acc: 94.545% \n",
      "[epoch:8, iter:2048] Loss: 0.293 | Acc: 94.525% \n",
      "[epoch:8, iter:2049] Loss: 0.293 | Acc: 94.550% \n",
      "[epoch:8, iter:2050] Loss: 0.293 | Acc: 94.574% \n",
      "[epoch:8, iter:2051] Loss: 0.293 | Acc: 94.554% \n",
      "[epoch:8, iter:2052] Loss: 0.293 | Acc: 94.578% \n",
      "[epoch:8, iter:2053] Loss: 0.293 | Acc: 94.558% \n",
      "[epoch:8, iter:2054] Loss: 0.292 | Acc: 94.581% \n",
      "[epoch:8, iter:2055] Loss: 0.292 | Acc: 94.605% \n",
      "[epoch:8, iter:2056] Loss: 0.292 | Acc: 94.629% \n",
      "[epoch:8, iter:2057] Loss: 0.293 | Acc: 94.565% \n",
      "[epoch:8, iter:2058] Loss: 0.293 | Acc: 94.589% \n",
      "[epoch:8, iter:2059] Loss: 0.292 | Acc: 94.612% \n",
      "[epoch:8, iter:2060] Loss: 0.292 | Acc: 94.635% \n",
      "[epoch:8, iter:2061] Loss: 0.291 | Acc: 94.658% \n",
      "[epoch:8, iter:2062] Loss: 0.291 | Acc: 94.681% \n",
      "[epoch:8, iter:2063] Loss: 0.292 | Acc: 94.661% \n",
      "[epoch:8, iter:2064] Loss: 0.293 | Acc: 94.641% \n",
      "[epoch:8, iter:2065] Loss: 0.292 | Acc: 94.664% \n",
      "[epoch:8, iter:2066] Loss: 0.292 | Acc: 94.644% \n",
      "[epoch:8, iter:2067] Loss: 0.291 | Acc: 94.667% \n",
      "[epoch:8, iter:2068] Loss: 0.290 | Acc: 94.689% \n",
      "[epoch:8, iter:2069] Loss: 0.290 | Acc: 94.669% \n",
      "[epoch:8, iter:2070] Loss: 0.289 | Acc: 94.691% \n",
      "[epoch:8, iter:2071] Loss: 0.289 | Acc: 94.713% \n",
      "[epoch:8, iter:2072] Loss: 0.289 | Acc: 94.735% \n",
      "[epoch:8, iter:2073] Loss: 0.289 | Acc: 94.756% \n",
      "[epoch:8, iter:2074] Loss: 0.288 | Acc: 94.777% \n",
      "[epoch:8, iter:2075] Loss: 0.288 | Acc: 94.798% \n",
      "[epoch:8, iter:2076] Loss: 0.289 | Acc: 94.739% \n",
      "[epoch:8, iter:2077] Loss: 0.289 | Acc: 94.720% \n",
      "[epoch:8, iter:2078] Loss: 0.291 | Acc: 94.661% \n",
      "[epoch:8, iter:2079] Loss: 0.290 | Acc: 94.683% \n",
      "[epoch:8, iter:2080] Loss: 0.289 | Acc: 94.704% \n",
      "[epoch:8, iter:2081] Loss: 0.289 | Acc: 94.724% \n",
      "[epoch:8, iter:2082] Loss: 0.290 | Acc: 94.667% \n",
      "[epoch:8, iter:2083] Loss: 0.289 | Acc: 94.688% \n",
      "[epoch:8, iter:2084] Loss: 0.289 | Acc: 94.708% \n",
      "[epoch:8, iter:2085] Loss: 0.289 | Acc: 94.690% \n",
      "[epoch:8, iter:2086] Loss: 0.289 | Acc: 94.710% \n",
      "[epoch:8, iter:2087] Loss: 0.289 | Acc: 94.692% \n",
      "[epoch:8, iter:2088] Loss: 0.288 | Acc: 94.694% \n",
      "\n",
      "Epoch: 9\n",
      "[epoch:9, iter:2089] Loss: 0.104 | Acc: 100.000% \n",
      "[epoch:9, iter:2090] Loss: 0.105 | Acc: 100.000% \n",
      "[epoch:9, iter:2091] Loss: 0.129 | Acc: 100.000% \n",
      "[epoch:9, iter:2092] Loss: 0.143 | Acc: 97.500% \n",
      "[epoch:9, iter:2093] Loss: 0.133 | Acc: 98.000% \n",
      "[epoch:9, iter:2094] Loss: 0.143 | Acc: 98.333% \n",
      "[epoch:9, iter:2095] Loss: 0.159 | Acc: 98.571% \n",
      "[epoch:9, iter:2096] Loss: 0.142 | Acc: 98.750% \n",
      "[epoch:9, iter:2097] Loss: 0.138 | Acc: 98.889% \n",
      "[epoch:9, iter:2098] Loss: 0.161 | Acc: 99.000% \n",
      "[epoch:9, iter:2099] Loss: 0.169 | Acc: 99.091% \n",
      "[epoch:9, iter:2100] Loss: 0.175 | Acc: 99.167% \n",
      "[epoch:9, iter:2101] Loss: 0.174 | Acc: 99.231% \n",
      "[epoch:9, iter:2102] Loss: 0.173 | Acc: 99.286% \n",
      "[epoch:9, iter:2103] Loss: 0.169 | Acc: 99.333% \n",
      "[epoch:9, iter:2104] Loss: 0.175 | Acc: 98.750% \n",
      "[epoch:9, iter:2105] Loss: 0.179 | Acc: 98.235% \n",
      "[epoch:9, iter:2106] Loss: 0.178 | Acc: 98.333% \n",
      "[epoch:9, iter:2107] Loss: 0.171 | Acc: 98.421% \n",
      "[epoch:9, iter:2108] Loss: 0.178 | Acc: 98.500% \n",
      "[epoch:9, iter:2109] Loss: 0.175 | Acc: 98.571% \n",
      "[epoch:9, iter:2110] Loss: 0.182 | Acc: 98.182% \n",
      "[epoch:9, iter:2111] Loss: 0.178 | Acc: 98.261% \n",
      "[epoch:9, iter:2112] Loss: 0.172 | Acc: 98.333% \n",
      "[epoch:9, iter:2113] Loss: 0.166 | Acc: 98.400% \n",
      "[epoch:9, iter:2114] Loss: 0.166 | Acc: 98.462% \n",
      "[epoch:9, iter:2115] Loss: 0.162 | Acc: 98.519% \n",
      "[epoch:9, iter:2116] Loss: 0.167 | Acc: 98.214% \n",
      "[epoch:9, iter:2117] Loss: 0.168 | Acc: 97.931% \n",
      "[epoch:9, iter:2118] Loss: 0.165 | Acc: 98.000% \n",
      "[epoch:9, iter:2119] Loss: 0.181 | Acc: 97.419% \n",
      "[epoch:9, iter:2120] Loss: 0.179 | Acc: 97.500% \n",
      "[epoch:9, iter:2121] Loss: 0.182 | Acc: 97.273% \n",
      "[epoch:9, iter:2122] Loss: 0.180 | Acc: 97.353% \n",
      "[epoch:9, iter:2123] Loss: 0.178 | Acc: 97.429% \n",
      "[epoch:9, iter:2124] Loss: 0.174 | Acc: 97.500% \n",
      "[epoch:9, iter:2125] Loss: 0.172 | Acc: 97.568% \n",
      "[epoch:9, iter:2126] Loss: 0.176 | Acc: 97.368% \n",
      "[epoch:9, iter:2127] Loss: 0.179 | Acc: 97.436% \n",
      "[epoch:9, iter:2128] Loss: 0.177 | Acc: 97.500% \n",
      "[epoch:9, iter:2129] Loss: 0.175 | Acc: 97.561% \n",
      "[epoch:9, iter:2130] Loss: 0.175 | Acc: 97.619% \n",
      "[epoch:9, iter:2131] Loss: 0.173 | Acc: 97.674% \n",
      "[epoch:9, iter:2132] Loss: 0.172 | Acc: 97.727% \n",
      "[epoch:9, iter:2133] Loss: 0.172 | Acc: 97.778% \n",
      "[epoch:9, iter:2134] Loss: 0.178 | Acc: 97.609% \n",
      "[epoch:9, iter:2135] Loss: 0.179 | Acc: 97.660% \n",
      "[epoch:9, iter:2136] Loss: 0.179 | Acc: 97.708% \n",
      "[epoch:9, iter:2137] Loss: 0.188 | Acc: 97.551% \n",
      "[epoch:9, iter:2138] Loss: 0.187 | Acc: 97.600% \n",
      "[epoch:9, iter:2139] Loss: 0.185 | Acc: 97.647% \n",
      "[epoch:9, iter:2140] Loss: 0.183 | Acc: 97.692% \n",
      "[epoch:9, iter:2141] Loss: 0.182 | Acc: 97.736% \n",
      "[epoch:9, iter:2142] Loss: 0.188 | Acc: 97.778% \n",
      "[epoch:9, iter:2143] Loss: 0.190 | Acc: 97.636% \n",
      "[epoch:9, iter:2144] Loss: 0.189 | Acc: 97.679% \n",
      "[epoch:9, iter:2145] Loss: 0.188 | Acc: 97.719% \n",
      "[epoch:9, iter:2146] Loss: 0.193 | Acc: 97.586% \n",
      "[epoch:9, iter:2147] Loss: 0.194 | Acc: 97.627% \n",
      "[epoch:9, iter:2148] Loss: 0.197 | Acc: 97.500% \n",
      "[epoch:9, iter:2149] Loss: 0.195 | Acc: 97.541% \n",
      "[epoch:9, iter:2150] Loss: 0.200 | Acc: 97.419% \n",
      "[epoch:9, iter:2151] Loss: 0.202 | Acc: 97.302% \n",
      "[epoch:9, iter:2152] Loss: 0.201 | Acc: 97.344% \n",
      "[epoch:9, iter:2153] Loss: 0.204 | Acc: 97.231% \n",
      "[epoch:9, iter:2154] Loss: 0.203 | Acc: 97.273% \n",
      "[epoch:9, iter:2155] Loss: 0.203 | Acc: 97.164% \n",
      "[epoch:9, iter:2156] Loss: 0.205 | Acc: 97.059% \n",
      "[epoch:9, iter:2157] Loss: 0.210 | Acc: 96.812% \n",
      "[epoch:9, iter:2158] Loss: 0.213 | Acc: 96.714% \n",
      "[epoch:9, iter:2159] Loss: 0.213 | Acc: 96.761% \n",
      "[epoch:9, iter:2160] Loss: 0.212 | Acc: 96.806% \n",
      "[epoch:9, iter:2161] Loss: 0.210 | Acc: 96.849% \n",
      "[epoch:9, iter:2162] Loss: 0.211 | Acc: 96.892% \n",
      "[epoch:9, iter:2163] Loss: 0.211 | Acc: 96.933% \n",
      "[epoch:9, iter:2164] Loss: 0.210 | Acc: 96.974% \n",
      "[epoch:9, iter:2165] Loss: 0.208 | Acc: 97.013% \n",
      "[epoch:9, iter:2166] Loss: 0.208 | Acc: 97.051% \n",
      "[epoch:9, iter:2167] Loss: 0.208 | Acc: 97.089% \n",
      "[epoch:9, iter:2168] Loss: 0.207 | Acc: 97.125% \n",
      "[epoch:9, iter:2169] Loss: 0.205 | Acc: 97.160% \n",
      "[epoch:9, iter:2170] Loss: 0.204 | Acc: 97.195% \n",
      "[epoch:9, iter:2171] Loss: 0.204 | Acc: 97.229% \n",
      "[epoch:9, iter:2172] Loss: 0.203 | Acc: 97.262% \n",
      "[epoch:9, iter:2173] Loss: 0.202 | Acc: 97.294% \n",
      "[epoch:9, iter:2174] Loss: 0.201 | Acc: 97.326% \n",
      "[epoch:9, iter:2175] Loss: 0.200 | Acc: 97.356% \n",
      "[epoch:9, iter:2176] Loss: 0.201 | Acc: 97.273% \n",
      "[epoch:9, iter:2177] Loss: 0.202 | Acc: 97.303% \n",
      "[epoch:9, iter:2178] Loss: 0.200 | Acc: 97.333% \n",
      "[epoch:9, iter:2179] Loss: 0.199 | Acc: 97.363% \n",
      "[epoch:9, iter:2180] Loss: 0.201 | Acc: 97.283% \n",
      "[epoch:9, iter:2181] Loss: 0.203 | Acc: 97.312% \n",
      "[epoch:9, iter:2182] Loss: 0.203 | Acc: 97.234% \n",
      "[epoch:9, iter:2183] Loss: 0.202 | Acc: 97.263% \n",
      "[epoch:9, iter:2184] Loss: 0.201 | Acc: 97.292% \n",
      "[epoch:9, iter:2185] Loss: 0.201 | Acc: 97.320% \n",
      "[epoch:9, iter:2186] Loss: 0.201 | Acc: 97.347% \n",
      "[epoch:9, iter:2187] Loss: 0.200 | Acc: 97.374% \n",
      "[epoch:9, iter:2188] Loss: 0.200 | Acc: 97.400% \n",
      "[epoch:9, iter:2189] Loss: 0.200 | Acc: 97.426% \n",
      "[epoch:9, iter:2190] Loss: 0.199 | Acc: 97.451% \n",
      "[epoch:9, iter:2191] Loss: 0.197 | Acc: 97.476% \n",
      "[epoch:9, iter:2192] Loss: 0.197 | Acc: 97.500% \n",
      "[epoch:9, iter:2193] Loss: 0.196 | Acc: 97.524% \n",
      "[epoch:9, iter:2194] Loss: 0.196 | Acc: 97.547% \n",
      "[epoch:9, iter:2195] Loss: 0.198 | Acc: 97.477% \n",
      "[epoch:9, iter:2196] Loss: 0.197 | Acc: 97.500% \n",
      "[epoch:9, iter:2197] Loss: 0.196 | Acc: 97.523% \n",
      "[epoch:9, iter:2198] Loss: 0.195 | Acc: 97.545% \n",
      "[epoch:9, iter:2199] Loss: 0.200 | Acc: 97.387% \n",
      "[epoch:9, iter:2200] Loss: 0.199 | Acc: 97.411% \n",
      "[epoch:9, iter:2201] Loss: 0.198 | Acc: 97.434% \n",
      "[epoch:9, iter:2202] Loss: 0.199 | Acc: 97.368% \n",
      "[epoch:9, iter:2203] Loss: 0.199 | Acc: 97.391% \n",
      "[epoch:9, iter:2204] Loss: 0.207 | Acc: 97.155% \n",
      "[epoch:9, iter:2205] Loss: 0.206 | Acc: 97.179% \n",
      "[epoch:9, iter:2206] Loss: 0.207 | Acc: 97.203% \n",
      "[epoch:9, iter:2207] Loss: 0.209 | Acc: 97.059% \n",
      "[epoch:9, iter:2208] Loss: 0.208 | Acc: 97.083% \n",
      "[epoch:9, iter:2209] Loss: 0.210 | Acc: 97.025% \n",
      "[epoch:9, iter:2210] Loss: 0.209 | Acc: 97.049% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:9, iter:2211] Loss: 0.209 | Acc: 97.073% \n",
      "[epoch:9, iter:2212] Loss: 0.210 | Acc: 97.016% \n",
      "[epoch:9, iter:2213] Loss: 0.209 | Acc: 97.040% \n",
      "[epoch:9, iter:2214] Loss: 0.208 | Acc: 97.063% \n",
      "[epoch:9, iter:2215] Loss: 0.207 | Acc: 97.087% \n",
      "[epoch:9, iter:2216] Loss: 0.206 | Acc: 97.109% \n",
      "[epoch:9, iter:2217] Loss: 0.208 | Acc: 96.977% \n",
      "[epoch:9, iter:2218] Loss: 0.207 | Acc: 97.000% \n",
      "[epoch:9, iter:2219] Loss: 0.210 | Acc: 96.947% \n",
      "[epoch:9, iter:2220] Loss: 0.209 | Acc: 96.970% \n",
      "[epoch:9, iter:2221] Loss: 0.211 | Acc: 96.917% \n",
      "[epoch:9, iter:2222] Loss: 0.211 | Acc: 96.940% \n",
      "[epoch:9, iter:2223] Loss: 0.211 | Acc: 96.889% \n",
      "[epoch:9, iter:2224] Loss: 0.211 | Acc: 96.912% \n",
      "[epoch:9, iter:2225] Loss: 0.211 | Acc: 96.934% \n",
      "[epoch:9, iter:2226] Loss: 0.211 | Acc: 96.957% \n",
      "[epoch:9, iter:2227] Loss: 0.210 | Acc: 96.978% \n",
      "[epoch:9, iter:2228] Loss: 0.210 | Acc: 96.929% \n",
      "[epoch:9, iter:2229] Loss: 0.212 | Acc: 96.809% \n",
      "[epoch:9, iter:2230] Loss: 0.212 | Acc: 96.831% \n",
      "[epoch:9, iter:2231] Loss: 0.213 | Acc: 96.783% \n",
      "[epoch:9, iter:2232] Loss: 0.215 | Acc: 96.667% \n",
      "[epoch:9, iter:2233] Loss: 0.214 | Acc: 96.690% \n",
      "[epoch:9, iter:2234] Loss: 0.215 | Acc: 96.644% \n",
      "[epoch:9, iter:2235] Loss: 0.214 | Acc: 96.667% \n",
      "[epoch:9, iter:2236] Loss: 0.213 | Acc: 96.689% \n",
      "[epoch:9, iter:2237] Loss: 0.213 | Acc: 96.711% \n",
      "[epoch:9, iter:2238] Loss: 0.212 | Acc: 96.733% \n",
      "[epoch:9, iter:2239] Loss: 0.213 | Acc: 96.689% \n",
      "[epoch:9, iter:2240] Loss: 0.212 | Acc: 96.711% \n",
      "[epoch:9, iter:2241] Loss: 0.213 | Acc: 96.667% \n",
      "[epoch:9, iter:2242] Loss: 0.215 | Acc: 96.623% \n",
      "[epoch:9, iter:2243] Loss: 0.214 | Acc: 96.645% \n",
      "[epoch:9, iter:2244] Loss: 0.214 | Acc: 96.603% \n",
      "[epoch:9, iter:2245] Loss: 0.215 | Acc: 96.561% \n",
      "[epoch:9, iter:2246] Loss: 0.215 | Acc: 96.519% \n",
      "[epoch:9, iter:2247] Loss: 0.217 | Acc: 96.478% \n",
      "[epoch:9, iter:2248] Loss: 0.217 | Acc: 96.438% \n",
      "[epoch:9, iter:2249] Loss: 0.216 | Acc: 96.460% \n",
      "[epoch:9, iter:2250] Loss: 0.218 | Acc: 96.358% \n",
      "[epoch:9, iter:2251] Loss: 0.218 | Acc: 96.380% \n",
      "[epoch:9, iter:2252] Loss: 0.218 | Acc: 96.402% \n",
      "[epoch:9, iter:2253] Loss: 0.217 | Acc: 96.424% \n",
      "[epoch:9, iter:2254] Loss: 0.220 | Acc: 96.325% \n",
      "[epoch:9, iter:2255] Loss: 0.219 | Acc: 96.347% \n",
      "[epoch:9, iter:2256] Loss: 0.220 | Acc: 96.310% \n",
      "[epoch:9, iter:2257] Loss: 0.219 | Acc: 96.331% \n",
      "[epoch:9, iter:2258] Loss: 0.218 | Acc: 96.353% \n",
      "[epoch:9, iter:2259] Loss: 0.218 | Acc: 96.374% \n",
      "[epoch:9, iter:2260] Loss: 0.220 | Acc: 96.279% \n",
      "[epoch:9, iter:2261] Loss: 0.219 | Acc: 96.243% \n",
      "[epoch:9, iter:2262] Loss: 0.219 | Acc: 96.264% \n",
      "[epoch:9, iter:2263] Loss: 0.219 | Acc: 96.286% \n",
      "[epoch:9, iter:2264] Loss: 0.218 | Acc: 96.307% \n",
      "[epoch:9, iter:2265] Loss: 0.220 | Acc: 96.215% \n",
      "[epoch:9, iter:2266] Loss: 0.220 | Acc: 96.180% \n",
      "[epoch:9, iter:2267] Loss: 0.220 | Acc: 96.201% \n",
      "[epoch:9, iter:2268] Loss: 0.220 | Acc: 96.167% \n",
      "[epoch:9, iter:2269] Loss: 0.220 | Acc: 96.188% \n",
      "[epoch:9, iter:2270] Loss: 0.220 | Acc: 96.154% \n",
      "[epoch:9, iter:2271] Loss: 0.220 | Acc: 96.175% \n",
      "[epoch:9, iter:2272] Loss: 0.220 | Acc: 96.196% \n",
      "[epoch:9, iter:2273] Loss: 0.219 | Acc: 96.216% \n",
      "[epoch:9, iter:2274] Loss: 0.218 | Acc: 96.237% \n",
      "[epoch:9, iter:2275] Loss: 0.218 | Acc: 96.257% \n",
      "[epoch:9, iter:2276] Loss: 0.220 | Acc: 96.223% \n",
      "[epoch:9, iter:2277] Loss: 0.220 | Acc: 96.190% \n",
      "[epoch:9, iter:2278] Loss: 0.220 | Acc: 96.211% \n",
      "[epoch:9, iter:2279] Loss: 0.219 | Acc: 96.230% \n",
      "[epoch:9, iter:2280] Loss: 0.219 | Acc: 96.198% \n",
      "[epoch:9, iter:2281] Loss: 0.218 | Acc: 96.218% \n",
      "[epoch:9, iter:2282] Loss: 0.218 | Acc: 96.237% \n",
      "[epoch:9, iter:2283] Loss: 0.219 | Acc: 96.154% \n",
      "[epoch:9, iter:2284] Loss: 0.219 | Acc: 96.122% \n",
      "[epoch:9, iter:2285] Loss: 0.219 | Acc: 96.142% \n",
      "[epoch:9, iter:2286] Loss: 0.218 | Acc: 96.162% \n",
      "[epoch:9, iter:2287] Loss: 0.218 | Acc: 96.181% \n",
      "[epoch:9, iter:2288] Loss: 0.220 | Acc: 96.100% \n",
      "[epoch:9, iter:2289] Loss: 0.222 | Acc: 96.020% \n",
      "[epoch:9, iter:2290] Loss: 0.222 | Acc: 96.040% \n",
      "[epoch:9, iter:2291] Loss: 0.222 | Acc: 96.059% \n",
      "[epoch:9, iter:2292] Loss: 0.222 | Acc: 96.029% \n",
      "[epoch:9, iter:2293] Loss: 0.222 | Acc: 96.049% \n",
      "[epoch:9, iter:2294] Loss: 0.221 | Acc: 96.068% \n",
      "[epoch:9, iter:2295] Loss: 0.220 | Acc: 96.087% \n",
      "[epoch:9, iter:2296] Loss: 0.220 | Acc: 96.058% \n",
      "[epoch:9, iter:2297] Loss: 0.220 | Acc: 96.077% \n",
      "[epoch:9, iter:2298] Loss: 0.219 | Acc: 96.095% \n",
      "[epoch:9, iter:2299] Loss: 0.220 | Acc: 96.019% \n",
      "[epoch:9, iter:2300] Loss: 0.220 | Acc: 95.991% \n",
      "[epoch:9, iter:2301] Loss: 0.221 | Acc: 95.962% \n",
      "[epoch:9, iter:2302] Loss: 0.221 | Acc: 95.981% \n",
      "[epoch:9, iter:2303] Loss: 0.221 | Acc: 96.000% \n",
      "[epoch:9, iter:2304] Loss: 0.221 | Acc: 96.019% \n",
      "[epoch:9, iter:2305] Loss: 0.221 | Acc: 96.037% \n",
      "[epoch:9, iter:2306] Loss: 0.220 | Acc: 96.055% \n",
      "[epoch:9, iter:2307] Loss: 0.220 | Acc: 96.073% \n",
      "[epoch:9, iter:2308] Loss: 0.219 | Acc: 96.091% \n",
      "[epoch:9, iter:2309] Loss: 0.219 | Acc: 96.109% \n",
      "[epoch:9, iter:2310] Loss: 0.218 | Acc: 96.126% \n",
      "[epoch:9, iter:2311] Loss: 0.218 | Acc: 96.143% \n",
      "[epoch:9, iter:2312] Loss: 0.217 | Acc: 96.161% \n",
      "[epoch:9, iter:2313] Loss: 0.218 | Acc: 96.178% \n",
      "[epoch:9, iter:2314] Loss: 0.218 | Acc: 96.195% \n",
      "[epoch:9, iter:2315] Loss: 0.218 | Acc: 96.211% \n",
      "[epoch:9, iter:2316] Loss: 0.217 | Acc: 96.228% \n",
      "[epoch:9, iter:2317] Loss: 0.219 | Acc: 96.157% \n",
      "[epoch:9, iter:2318] Loss: 0.219 | Acc: 96.130% \n",
      "[epoch:9, iter:2319] Loss: 0.219 | Acc: 96.104% \n",
      "[epoch:9, iter:2320] Loss: 0.219 | Acc: 96.078% \n",
      "[epoch:9, iter:2321] Loss: 0.218 | Acc: 96.094% \n",
      "[epoch:9, iter:2322] Loss: 0.218 | Acc: 96.068% \n",
      "[epoch:9, iter:2323] Loss: 0.220 | Acc: 96.043% \n",
      "[epoch:9, iter:2324] Loss: 0.221 | Acc: 96.017% \n",
      "[epoch:9, iter:2325] Loss: 0.220 | Acc: 96.034% \n",
      "[epoch:9, iter:2326] Loss: 0.220 | Acc: 96.008% \n",
      "[epoch:9, iter:2327] Loss: 0.220 | Acc: 96.025% \n",
      "[epoch:9, iter:2328] Loss: 0.220 | Acc: 96.000% \n",
      "[epoch:9, iter:2329] Loss: 0.220 | Acc: 95.975% \n",
      "[epoch:9, iter:2330] Loss: 0.220 | Acc: 95.950% \n",
      "[epoch:9, iter:2331] Loss: 0.219 | Acc: 95.967% \n",
      "[epoch:9, iter:2332] Loss: 0.219 | Acc: 95.984% \n",
      "[epoch:9, iter:2333] Loss: 0.220 | Acc: 95.918% \n",
      "[epoch:9, iter:2334] Loss: 0.221 | Acc: 95.854% \n",
      "[epoch:9, iter:2335] Loss: 0.221 | Acc: 95.870% \n",
      "[epoch:9, iter:2336] Loss: 0.221 | Acc: 95.847% \n",
      "[epoch:9, iter:2337] Loss: 0.220 | Acc: 95.863% \n",
      "[epoch:9, iter:2338] Loss: 0.220 | Acc: 95.880% \n",
      "[epoch:9, iter:2339] Loss: 0.220 | Acc: 95.857% \n",
      "[epoch:9, iter:2340] Loss: 0.221 | Acc: 95.794% \n",
      "[epoch:9, iter:2341] Loss: 0.221 | Acc: 95.810% \n",
      "[epoch:9, iter:2342] Loss: 0.221 | Acc: 95.827% \n",
      "[epoch:9, iter:2343] Loss: 0.221 | Acc: 95.843% \n",
      "[epoch:9, iter:2344] Loss: 0.221 | Acc: 95.859% \n",
      "[epoch:9, iter:2345] Loss: 0.220 | Acc: 95.875% \n",
      "[epoch:9, iter:2346] Loss: 0.220 | Acc: 95.853% \n",
      "[epoch:9, iter:2347] Loss: 0.221 | Acc: 95.830% \n",
      "[epoch:9, iter:2348] Loss: 0.220 | Acc: 95.808% \n",
      "[epoch:9, iter:2349] Loss: 0.219 | Acc: 95.809% \n",
      "\n",
      "Epoch: 10\n",
      "[epoch:10, iter:2350] Loss: 0.209 | Acc: 90.000% \n",
      "[epoch:10, iter:2351] Loss: 0.139 | Acc: 95.000% \n",
      "[epoch:10, iter:2352] Loss: 0.185 | Acc: 96.667% \n",
      "[epoch:10, iter:2353] Loss: 0.161 | Acc: 97.500% \n",
      "[epoch:10, iter:2354] Loss: 0.214 | Acc: 96.000% \n",
      "[epoch:10, iter:2355] Loss: 0.193 | Acc: 96.667% \n",
      "[epoch:10, iter:2356] Loss: 0.171 | Acc: 97.143% \n",
      "[epoch:10, iter:2357] Loss: 0.190 | Acc: 97.500% \n",
      "[epoch:10, iter:2358] Loss: 0.204 | Acc: 96.667% \n",
      "[epoch:10, iter:2359] Loss: 0.234 | Acc: 96.000% \n",
      "[epoch:10, iter:2360] Loss: 0.224 | Acc: 96.364% \n",
      "[epoch:10, iter:2361] Loss: 0.225 | Acc: 95.833% \n",
      "[epoch:10, iter:2362] Loss: 0.218 | Acc: 96.154% \n",
      "[epoch:10, iter:2363] Loss: 0.212 | Acc: 96.429% \n",
      "[epoch:10, iter:2364] Loss: 0.212 | Acc: 96.667% \n",
      "[epoch:10, iter:2365] Loss: 0.202 | Acc: 96.875% \n",
      "[epoch:10, iter:2366] Loss: 0.203 | Acc: 97.059% \n",
      "[epoch:10, iter:2367] Loss: 0.198 | Acc: 97.222% \n",
      "[epoch:10, iter:2368] Loss: 0.194 | Acc: 97.368% \n",
      "[epoch:10, iter:2369] Loss: 0.189 | Acc: 97.500% \n",
      "[epoch:10, iter:2370] Loss: 0.189 | Acc: 97.619% \n",
      "[epoch:10, iter:2371] Loss: 0.188 | Acc: 97.727% \n",
      "[epoch:10, iter:2372] Loss: 0.188 | Acc: 97.391% \n",
      "[epoch:10, iter:2373] Loss: 0.188 | Acc: 97.500% \n",
      "[epoch:10, iter:2374] Loss: 0.183 | Acc: 97.600% \n",
      "[epoch:10, iter:2375] Loss: 0.179 | Acc: 97.692% \n",
      "[epoch:10, iter:2376] Loss: 0.180 | Acc: 97.407% \n",
      "[epoch:10, iter:2377] Loss: 0.177 | Acc: 97.500% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:10, iter:2378] Loss: 0.173 | Acc: 97.586% \n",
      "[epoch:10, iter:2379] Loss: 0.168 | Acc: 97.667% \n",
      "[epoch:10, iter:2380] Loss: 0.167 | Acc: 97.742% \n",
      "[epoch:10, iter:2381] Loss: 0.169 | Acc: 97.812% \n",
      "[epoch:10, iter:2382] Loss: 0.168 | Acc: 97.879% \n",
      "[epoch:10, iter:2383] Loss: 0.167 | Acc: 97.941% \n",
      "[epoch:10, iter:2384] Loss: 0.166 | Acc: 98.000% \n",
      "[epoch:10, iter:2385] Loss: 0.168 | Acc: 97.778% \n",
      "[epoch:10, iter:2386] Loss: 0.165 | Acc: 97.838% \n",
      "[epoch:10, iter:2387] Loss: 0.163 | Acc: 97.895% \n",
      "[epoch:10, iter:2388] Loss: 0.163 | Acc: 97.949% \n",
      "[epoch:10, iter:2389] Loss: 0.162 | Acc: 98.000% \n",
      "[epoch:10, iter:2390] Loss: 0.160 | Acc: 98.049% \n",
      "[epoch:10, iter:2391] Loss: 0.160 | Acc: 98.095% \n",
      "[epoch:10, iter:2392] Loss: 0.163 | Acc: 97.907% \n",
      "[epoch:10, iter:2393] Loss: 0.166 | Acc: 97.500% \n",
      "[epoch:10, iter:2394] Loss: 0.163 | Acc: 97.556% \n",
      "[epoch:10, iter:2395] Loss: 0.161 | Acc: 97.609% \n",
      "[epoch:10, iter:2396] Loss: 0.160 | Acc: 97.660% \n",
      "[epoch:10, iter:2397] Loss: 0.165 | Acc: 97.500% \n",
      "[epoch:10, iter:2398] Loss: 0.168 | Acc: 97.347% \n",
      "[epoch:10, iter:2399] Loss: 0.166 | Acc: 97.400% \n",
      "[epoch:10, iter:2400] Loss: 0.166 | Acc: 97.451% \n",
      "[epoch:10, iter:2401] Loss: 0.165 | Acc: 97.500% \n",
      "[epoch:10, iter:2402] Loss: 0.164 | Acc: 97.358% \n",
      "[epoch:10, iter:2403] Loss: 0.163 | Acc: 97.407% \n",
      "[epoch:10, iter:2404] Loss: 0.162 | Acc: 97.455% \n",
      "[epoch:10, iter:2405] Loss: 0.162 | Acc: 97.500% \n",
      "[epoch:10, iter:2406] Loss: 0.161 | Acc: 97.544% \n",
      "[epoch:10, iter:2407] Loss: 0.159 | Acc: 97.586% \n",
      "[epoch:10, iter:2408] Loss: 0.161 | Acc: 97.458% \n",
      "[epoch:10, iter:2409] Loss: 0.160 | Acc: 97.500% \n",
      "[epoch:10, iter:2410] Loss: 0.159 | Acc: 97.541% \n",
      "[epoch:10, iter:2411] Loss: 0.158 | Acc: 97.581% \n",
      "[epoch:10, iter:2412] Loss: 0.166 | Acc: 97.302% \n",
      "[epoch:10, iter:2413] Loss: 0.164 | Acc: 97.344% \n",
      "[epoch:10, iter:2414] Loss: 0.162 | Acc: 97.385% \n",
      "[epoch:10, iter:2415] Loss: 0.162 | Acc: 97.424% \n",
      "[epoch:10, iter:2416] Loss: 0.163 | Acc: 97.463% \n",
      "[epoch:10, iter:2417] Loss: 0.164 | Acc: 97.353% \n",
      "[epoch:10, iter:2418] Loss: 0.165 | Acc: 97.391% \n",
      "[epoch:10, iter:2419] Loss: 0.166 | Acc: 97.286% \n",
      "[epoch:10, iter:2420] Loss: 0.164 | Acc: 97.324% \n",
      "[epoch:10, iter:2421] Loss: 0.163 | Acc: 97.361% \n",
      "[epoch:10, iter:2422] Loss: 0.162 | Acc: 97.397% \n",
      "[epoch:10, iter:2423] Loss: 0.161 | Acc: 97.432% \n",
      "[epoch:10, iter:2424] Loss: 0.159 | Acc: 97.467% \n",
      "[epoch:10, iter:2425] Loss: 0.160 | Acc: 97.500% \n",
      "[epoch:10, iter:2426] Loss: 0.162 | Acc: 97.403% \n",
      "[epoch:10, iter:2427] Loss: 0.162 | Acc: 97.308% \n",
      "[epoch:10, iter:2428] Loss: 0.160 | Acc: 97.342% \n",
      "[epoch:10, iter:2429] Loss: 0.161 | Acc: 97.375% \n",
      "[epoch:10, iter:2430] Loss: 0.162 | Acc: 97.407% \n",
      "[epoch:10, iter:2431] Loss: 0.166 | Acc: 97.195% \n",
      "[epoch:10, iter:2432] Loss: 0.167 | Acc: 97.108% \n",
      "[epoch:10, iter:2433] Loss: 0.166 | Acc: 97.143% \n",
      "[epoch:10, iter:2434] Loss: 0.165 | Acc: 97.176% \n",
      "[epoch:10, iter:2435] Loss: 0.164 | Acc: 97.209% \n",
      "[epoch:10, iter:2436] Loss: 0.163 | Acc: 97.241% \n",
      "[epoch:10, iter:2437] Loss: 0.161 | Acc: 97.273% \n",
      "[epoch:10, iter:2438] Loss: 0.160 | Acc: 97.303% \n",
      "[epoch:10, iter:2439] Loss: 0.161 | Acc: 97.222% \n",
      "[epoch:10, iter:2440] Loss: 0.159 | Acc: 97.253% \n",
      "[epoch:10, iter:2441] Loss: 0.158 | Acc: 97.283% \n",
      "[epoch:10, iter:2442] Loss: 0.158 | Acc: 97.312% \n",
      "[epoch:10, iter:2443] Loss: 0.160 | Acc: 97.234% \n",
      "[epoch:10, iter:2444] Loss: 0.158 | Acc: 97.263% \n",
      "[epoch:10, iter:2445] Loss: 0.162 | Acc: 97.188% \n",
      "[epoch:10, iter:2446] Loss: 0.161 | Acc: 97.216% \n",
      "[epoch:10, iter:2447] Loss: 0.160 | Acc: 97.245% \n",
      "[epoch:10, iter:2448] Loss: 0.158 | Acc: 97.273% \n",
      "[epoch:10, iter:2449] Loss: 0.158 | Acc: 97.300% \n",
      "[epoch:10, iter:2450] Loss: 0.158 | Acc: 97.327% \n",
      "[epoch:10, iter:2451] Loss: 0.157 | Acc: 97.353% \n",
      "[epoch:10, iter:2452] Loss: 0.156 | Acc: 97.379% \n",
      "[epoch:10, iter:2453] Loss: 0.155 | Acc: 97.404% \n",
      "[epoch:10, iter:2454] Loss: 0.154 | Acc: 97.429% \n",
      "[epoch:10, iter:2455] Loss: 0.153 | Acc: 97.453% \n",
      "[epoch:10, iter:2456] Loss: 0.154 | Acc: 97.383% \n",
      "[epoch:10, iter:2457] Loss: 0.154 | Acc: 97.407% \n",
      "[epoch:10, iter:2458] Loss: 0.154 | Acc: 97.431% \n",
      "[epoch:10, iter:2459] Loss: 0.155 | Acc: 97.364% \n",
      "[epoch:10, iter:2460] Loss: 0.154 | Acc: 97.387% \n",
      "[epoch:10, iter:2461] Loss: 0.155 | Acc: 97.411% \n",
      "[epoch:10, iter:2462] Loss: 0.153 | Acc: 97.434% \n",
      "[epoch:10, iter:2463] Loss: 0.152 | Acc: 97.456% \n",
      "[epoch:10, iter:2464] Loss: 0.151 | Acc: 97.478% \n",
      "[epoch:10, iter:2465] Loss: 0.151 | Acc: 97.500% \n",
      "[epoch:10, iter:2466] Loss: 0.150 | Acc: 97.521% \n",
      "[epoch:10, iter:2467] Loss: 0.149 | Acc: 97.542% \n",
      "[epoch:10, iter:2468] Loss: 0.149 | Acc: 97.563% \n",
      "[epoch:10, iter:2469] Loss: 0.149 | Acc: 97.583% \n",
      "[epoch:10, iter:2470] Loss: 0.148 | Acc: 97.603% \n",
      "[epoch:10, iter:2471] Loss: 0.147 | Acc: 97.623% \n",
      "[epoch:10, iter:2472] Loss: 0.147 | Acc: 97.642% \n",
      "[epoch:10, iter:2473] Loss: 0.146 | Acc: 97.661% \n",
      "[epoch:10, iter:2474] Loss: 0.147 | Acc: 97.600% \n",
      "[epoch:10, iter:2475] Loss: 0.147 | Acc: 97.619% \n",
      "[epoch:10, iter:2476] Loss: 0.146 | Acc: 97.638% \n",
      "[epoch:10, iter:2477] Loss: 0.146 | Acc: 97.656% \n",
      "[epoch:10, iter:2478] Loss: 0.149 | Acc: 97.597% \n",
      "[epoch:10, iter:2479] Loss: 0.149 | Acc: 97.615% \n",
      "[epoch:10, iter:2480] Loss: 0.149 | Acc: 97.634% \n",
      "[epoch:10, iter:2481] Loss: 0.150 | Acc: 97.576% \n",
      "[epoch:10, iter:2482] Loss: 0.149 | Acc: 97.594% \n",
      "[epoch:10, iter:2483] Loss: 0.149 | Acc: 97.612% \n",
      "[epoch:10, iter:2484] Loss: 0.150 | Acc: 97.630% \n",
      "[epoch:10, iter:2485] Loss: 0.149 | Acc: 97.647% \n",
      "[epoch:10, iter:2486] Loss: 0.149 | Acc: 97.664% \n",
      "[epoch:10, iter:2487] Loss: 0.151 | Acc: 97.536% \n",
      "[epoch:10, iter:2488] Loss: 0.151 | Acc: 97.554% \n",
      "[epoch:10, iter:2489] Loss: 0.151 | Acc: 97.571% \n",
      "[epoch:10, iter:2490] Loss: 0.151 | Acc: 97.589% \n",
      "[epoch:10, iter:2491] Loss: 0.151 | Acc: 97.606% \n",
      "[epoch:10, iter:2492] Loss: 0.151 | Acc: 97.622% \n",
      "[epoch:10, iter:2493] Loss: 0.151 | Acc: 97.639% \n",
      "[epoch:10, iter:2494] Loss: 0.151 | Acc: 97.655% \n",
      "[epoch:10, iter:2495] Loss: 0.150 | Acc: 97.671% \n",
      "[epoch:10, iter:2496] Loss: 0.150 | Acc: 97.687% \n",
      "[epoch:10, iter:2497] Loss: 0.150 | Acc: 97.703% \n",
      "[epoch:10, iter:2498] Loss: 0.149 | Acc: 97.718% \n",
      "[epoch:10, iter:2499] Loss: 0.150 | Acc: 97.667% \n",
      "[epoch:10, iter:2500] Loss: 0.150 | Acc: 97.682% \n",
      "[epoch:10, iter:2501] Loss: 0.149 | Acc: 97.697% \n",
      "[epoch:10, iter:2502] Loss: 0.149 | Acc: 97.712% \n",
      "[epoch:10, iter:2503] Loss: 0.149 | Acc: 97.727% \n",
      "[epoch:10, iter:2504] Loss: 0.149 | Acc: 97.677% \n",
      "[epoch:10, iter:2505] Loss: 0.149 | Acc: 97.692% \n",
      "[epoch:10, iter:2506] Loss: 0.148 | Acc: 97.707% \n",
      "[epoch:10, iter:2507] Loss: 0.148 | Acc: 97.722% \n",
      "[epoch:10, iter:2508] Loss: 0.148 | Acc: 97.736% \n",
      "[epoch:10, iter:2509] Loss: 0.147 | Acc: 97.750% \n",
      "[epoch:10, iter:2510] Loss: 0.147 | Acc: 97.764% \n",
      "[epoch:10, iter:2511] Loss: 0.148 | Acc: 97.778% \n",
      "[epoch:10, iter:2512] Loss: 0.149 | Acc: 97.791% \n",
      "[epoch:10, iter:2513] Loss: 0.148 | Acc: 97.805% \n",
      "[epoch:10, iter:2514] Loss: 0.148 | Acc: 97.818% \n",
      "[epoch:10, iter:2515] Loss: 0.148 | Acc: 97.831% \n",
      "[epoch:10, iter:2516] Loss: 0.147 | Acc: 97.844% \n",
      "[epoch:10, iter:2517] Loss: 0.147 | Acc: 97.857% \n",
      "[epoch:10, iter:2518] Loss: 0.148 | Acc: 97.811% \n",
      "[epoch:10, iter:2519] Loss: 0.148 | Acc: 97.824% \n",
      "[epoch:10, iter:2520] Loss: 0.148 | Acc: 97.836% \n",
      "[epoch:10, iter:2521] Loss: 0.148 | Acc: 97.849% \n",
      "[epoch:10, iter:2522] Loss: 0.149 | Acc: 97.803% \n",
      "[epoch:10, iter:2523] Loss: 0.149 | Acc: 97.816% \n",
      "[epoch:10, iter:2524] Loss: 0.149 | Acc: 97.829% \n",
      "[epoch:10, iter:2525] Loss: 0.148 | Acc: 97.841% \n",
      "[epoch:10, iter:2526] Loss: 0.148 | Acc: 97.853% \n",
      "[epoch:10, iter:2527] Loss: 0.149 | Acc: 97.809% \n",
      "[epoch:10, iter:2528] Loss: 0.150 | Acc: 97.821% \n",
      "[epoch:10, iter:2529] Loss: 0.149 | Acc: 97.833% \n",
      "[epoch:10, iter:2530] Loss: 0.149 | Acc: 97.845% \n",
      "[epoch:10, iter:2531] Loss: 0.150 | Acc: 97.802% \n",
      "[epoch:10, iter:2532] Loss: 0.149 | Acc: 97.814% \n",
      "[epoch:10, iter:2533] Loss: 0.149 | Acc: 97.826% \n",
      "[epoch:10, iter:2534] Loss: 0.149 | Acc: 97.784% \n",
      "[epoch:10, iter:2535] Loss: 0.149 | Acc: 97.796% \n",
      "[epoch:10, iter:2536] Loss: 0.150 | Acc: 97.807% \n",
      "[epoch:10, iter:2537] Loss: 0.149 | Acc: 97.819% \n",
      "[epoch:10, iter:2538] Loss: 0.149 | Acc: 97.831% \n",
      "[epoch:10, iter:2539] Loss: 0.149 | Acc: 97.842% \n",
      "[epoch:10, iter:2540] Loss: 0.148 | Acc: 97.853% \n",
      "[epoch:10, iter:2541] Loss: 0.148 | Acc: 97.865% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch:10, iter:2542] Loss: 0.148 | Acc: 97.876% \n",
      "[epoch:10, iter:2543] Loss: 0.148 | Acc: 97.887% \n",
      "[epoch:10, iter:2544] Loss: 0.148 | Acc: 97.897% \n",
      "[epoch:10, iter:2545] Loss: 0.147 | Acc: 97.908% \n",
      "[epoch:10, iter:2546] Loss: 0.147 | Acc: 97.919% \n",
      "[epoch:10, iter:2547] Loss: 0.147 | Acc: 97.929% \n",
      "[epoch:10, iter:2548] Loss: 0.147 | Acc: 97.940% \n",
      "[epoch:10, iter:2549] Loss: 0.147 | Acc: 97.950% \n",
      "[epoch:10, iter:2550] Loss: 0.146 | Acc: 97.960% \n",
      "[epoch:10, iter:2551] Loss: 0.146 | Acc: 97.970% \n",
      "[epoch:10, iter:2552] Loss: 0.147 | Acc: 97.931% \n",
      "[epoch:10, iter:2553] Loss: 0.147 | Acc: 97.892% \n",
      "[epoch:10, iter:2554] Loss: 0.147 | Acc: 97.902% \n",
      "[epoch:10, iter:2555] Loss: 0.147 | Acc: 97.864% \n",
      "[epoch:10, iter:2556] Loss: 0.147 | Acc: 97.874% \n",
      "[epoch:10, iter:2557] Loss: 0.147 | Acc: 97.885% \n",
      "[epoch:10, iter:2558] Loss: 0.146 | Acc: 97.895% \n",
      "[epoch:10, iter:2559] Loss: 0.146 | Acc: 97.905% \n",
      "[epoch:10, iter:2560] Loss: 0.146 | Acc: 97.867% \n",
      "[epoch:10, iter:2561] Loss: 0.147 | Acc: 97.830% \n",
      "[epoch:10, iter:2562] Loss: 0.148 | Acc: 97.840% \n",
      "[epoch:10, iter:2563] Loss: 0.148 | Acc: 97.850% \n",
      "[epoch:10, iter:2564] Loss: 0.148 | Acc: 97.860% \n",
      "[epoch:10, iter:2565] Loss: 0.148 | Acc: 97.870% \n",
      "[epoch:10, iter:2566] Loss: 0.148 | Acc: 97.880% \n",
      "[epoch:10, iter:2567] Loss: 0.147 | Acc: 97.890% \n",
      "[epoch:10, iter:2568] Loss: 0.147 | Acc: 97.900% \n",
      "[epoch:10, iter:2569] Loss: 0.146 | Acc: 97.909% \n",
      "[epoch:10, iter:2570] Loss: 0.146 | Acc: 97.919% \n",
      "[epoch:10, iter:2571] Loss: 0.146 | Acc: 97.928% \n",
      "[epoch:10, iter:2572] Loss: 0.146 | Acc: 97.937% \n",
      "[epoch:10, iter:2573] Loss: 0.145 | Acc: 97.946% \n",
      "[epoch:10, iter:2574] Loss: 0.146 | Acc: 97.956% \n",
      "[epoch:10, iter:2575] Loss: 0.145 | Acc: 97.965% \n",
      "[epoch:10, iter:2576] Loss: 0.145 | Acc: 97.974% \n",
      "[epoch:10, iter:2577] Loss: 0.145 | Acc: 97.982% \n",
      "[epoch:10, iter:2578] Loss: 0.145 | Acc: 97.948% \n",
      "[epoch:10, iter:2579] Loss: 0.147 | Acc: 97.870% \n",
      "[epoch:10, iter:2580] Loss: 0.146 | Acc: 97.879% \n",
      "[epoch:10, iter:2581] Loss: 0.146 | Acc: 97.888% \n",
      "[epoch:10, iter:2582] Loss: 0.147 | Acc: 97.854% \n",
      "[epoch:10, iter:2583] Loss: 0.147 | Acc: 97.863% \n",
      "[epoch:10, iter:2584] Loss: 0.150 | Acc: 97.745% \n",
      "[epoch:10, iter:2585] Loss: 0.150 | Acc: 97.754% \n",
      "[epoch:10, iter:2586] Loss: 0.150 | Acc: 97.764% \n",
      "[epoch:10, iter:2587] Loss: 0.149 | Acc: 97.773% \n",
      "[epoch:10, iter:2588] Loss: 0.149 | Acc: 97.782% \n",
      "[epoch:10, iter:2589] Loss: 0.149 | Acc: 97.792% \n",
      "[epoch:10, iter:2590] Loss: 0.149 | Acc: 97.759% \n",
      "[epoch:10, iter:2591] Loss: 0.149 | Acc: 97.727% \n",
      "[epoch:10, iter:2592] Loss: 0.149 | Acc: 97.737% \n",
      "[epoch:10, iter:2593] Loss: 0.149 | Acc: 97.746% \n",
      "[epoch:10, iter:2594] Loss: 0.149 | Acc: 97.755% \n",
      "[epoch:10, iter:2595] Loss: 0.148 | Acc: 97.764% \n",
      "[epoch:10, iter:2596] Loss: 0.149 | Acc: 97.733% \n",
      "[epoch:10, iter:2597] Loss: 0.150 | Acc: 97.702% \n",
      "[epoch:10, iter:2598] Loss: 0.149 | Acc: 97.711% \n",
      "[epoch:10, iter:2599] Loss: 0.149 | Acc: 97.720% \n",
      "[epoch:10, iter:2600] Loss: 0.148 | Acc: 97.729% \n",
      "[epoch:10, iter:2601] Loss: 0.148 | Acc: 97.698% \n",
      "[epoch:10, iter:2602] Loss: 0.148 | Acc: 97.668% \n",
      "[epoch:10, iter:2603] Loss: 0.149 | Acc: 97.638% \n",
      "[epoch:10, iter:2604] Loss: 0.149 | Acc: 97.647% \n",
      "[epoch:10, iter:2605] Loss: 0.148 | Acc: 97.656% \n",
      "[epoch:10, iter:2606] Loss: 0.148 | Acc: 97.665% \n",
      "[epoch:10, iter:2607] Loss: 0.148 | Acc: 97.674% \n",
      "[epoch:10, iter:2608] Loss: 0.150 | Acc: 97.606% \n",
      "[epoch:10, iter:2609] Loss: 0.150 | Acc: 97.615% \n",
      "[epoch:10, iter:2610] Loss: 0.149 | Acc: 97.616% \n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "print(\"Start Training!\")  # 定义遍历数据集的次数\n",
    "for epoch in range(pre_epoch, EPOCH):\n",
    "    print('\\nEpoch: %d' % (epoch + 1))\n",
    "    net.train()\n",
    "    sum_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    \n",
    "    for i, data in enumerate(training_loader, 0):\n",
    "        # 准备数据\n",
    "        length = len(training_loader)\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # forward + backward\n",
    "        #with torch.no_grad():\n",
    "        outputs = net(inputs)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 每训练1个batch打印一次loss和准确率\n",
    "        sum_loss += loss.item()\n",
    "        \n",
    "        # 使用Top5分类\n",
    "        maxk = max((1,1))\n",
    "        label_resize = labels.view(-1, 1)\n",
    "        _, predicted = outputs.topk(maxk, 1, True, True)\n",
    "        total += labels.size(0)\n",
    "        correct += torch.eq(predicted, label_resize).cpu().sum().float().item()\n",
    "            \n",
    "        print('[epoch:%d, iter:%d] Loss: %.03f | Acc: %.3f%% '% (epoch + 1, (i + 1 + epoch * length), sum_loss / (i + 1), 100. * correct / total))\n",
    "    \n",
    "#     #每训练完一个epoch测试一下准确率\n",
    "#     print(\"Waiting Test!\")\n",
    "#     with torch.no_grad():\n",
    "#         correct = 0\n",
    "#         total = 0\n",
    "#         for data in valing_loader:\n",
    "#             net.eval()\n",
    "#             images, labels = data\n",
    "#             images, labels = images.to(device), labels.to(device)\n",
    "#             outputs = net(images)\n",
    "#             # 取得分最高的那个类 (outputs.data的索引号)\n",
    "            \n",
    "#             maxk = max((1,5))\n",
    "#             label_resize = labels.view(-1, 1)\n",
    "#             _, predicted = outputs.topk(maxk, 1, True, True)\n",
    "#             total += labels.size(0)\n",
    "#             correct += torch.eq(predicted, label_resize).cpu().sum().float().item()\n",
    "            \n",
    "#             y_predict.append(predicted)\n",
    "#             y_true.append(labels)\n",
    "#         print('测试分类准确率为：%.3f%%' % (100 * correct / total))\n",
    "#         acc = 100. * correct / total\n",
    "# print(\"Training Finished, TotalEPOCH=%d\" % EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyenv] *",
   "language": "python",
   "name": "conda-env-pyenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
