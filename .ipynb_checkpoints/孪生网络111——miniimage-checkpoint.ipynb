{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# 数据预处理\n",
    "ROOT_PATH = 'D:\\\\数据库\\\\小样本数据库\\\\mini-imagenet\\\\mini-imagenet'\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "img_size=30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成数据集的x，y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "class MiniImageNet(Dataset):\n",
    "\n",
    "    def __init__(self, setname):\n",
    "        csv_path = osp.join(ROOT_PATH, setname + '.csv')\n",
    "        #filename                 label\n",
    "        #n0153282900000005.jpg    n01532829\n",
    "        lines = [x.strip() for x in open(csv_path, 'r').readlines()][1:]\n",
    "\n",
    "        imgs = []  #图片\n",
    "        labels = []  #图片对应的类别索引\n",
    "        lb = -1\n",
    "\n",
    "        self.wnids = []  #记录该数据集都有哪些类，每个元素（类名）的索引对应label\n",
    "        \n",
    "        self.transform = transforms.Compose([  #图片转换\n",
    "            transforms.Resize(img_size),\n",
    "            transforms.CenterCrop(img_size),  #84\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        for l in lines:\n",
    "            name, wnid = l.split(',')\n",
    "            #path = osp.join(ROOT_PATH, 'images', name)  #每张图片的地址\n",
    "            img=self.transform(Image.open(osp.join(ROOT_PATH, 'images', name)).convert('RGB'))\n",
    "            if wnid not in self.wnids:\n",
    "                self.wnids.append(wnid)\n",
    "                lb += 1\n",
    "            imgs.append(img)\n",
    "            labels.append(lb)\n",
    "\n",
    "        self.imgs = imgs\n",
    "        self.labels = labels\n",
    "        self.classes, self.counts = np.unique(self.labels, return_counts=True)\n",
    "        self.classes = torch.LongTensor(self.classes)\n",
    "        print(self.classes)\n",
    "        \n",
    "        #print(len(self.data))  #训练集一共38400个样本，测试集12000，验证集9600\n",
    "        #print(len(self.wnids)) #训练集包含64个类别，测试集20类，验证集16类，每类有600个样本\n",
    "        #print(self.data[0])  #self.data包含每个样本图片的地址  D:\\数据库\\小样本数据库\\mini-imagenet\\mini-imagenet\\images\\n0153282900000005.jpg\n",
    "        #print(self.label[0])  #self.label包含每个样本的类别 [0~63]   \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img0_tuple=torch.randperm(len(self.classes))[0]   #第一个样本随机选择一类\n",
    "        should_get_same_class = random.randint(0,1)  #随机决定是否要获取同类样本\n",
    "        if should_get_same_class:  \n",
    "            img1_tuple = img0_tuple\n",
    "        else:\n",
    "            while True:    \n",
    "                #直到找到非同一类别\n",
    "                img1_tuple = torch.randperm(len(self.classes))[0]   \n",
    "                if img0_tuple !=img1_tuple:\n",
    "                    break\n",
    "            \n",
    "        img0_idx = torch.randperm(int(self.counts[img0_tuple]))[0] #取出图片一\n",
    "        img1_idx = torch.randperm(int(self.counts[img1_tuple]))[0] #取出图片二\n",
    "        \n",
    "        idx0=img0_tuple*600+img0_idx\n",
    "        idx1=img1_tuple*600+img1_idx\n",
    "\n",
    "        return self.imgs[idx0], self.imgs[idx1], should_get_same_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63])\n",
      "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 30, 30])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dataloader(mode,batch_size):\n",
    "    dataset=MiniImageNet(mode)\n",
    "    return torch.utils.data.DataLoader(dataset, shuffle=True,batch_size=batch_size)\n",
    "\n",
    "train_loader=dataloader('train',10)\n",
    "val_loader=dataloader('val',20)\n",
    "#test_loader=dataloader('test',20)\n",
    "next(iter(train_loader))[0].shape  #([32, 1, 28, 28])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造孪生网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SiamsNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiamsNet, self).__init__()\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),   #padding\n",
    "            nn.Conv2d(3, 4, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(4),\n",
    "            \n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(4, 8, kernel_size=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(8),\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(8*30*30, 500),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(500, 500),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(500, 5))\n",
    "\n",
    "    def forward_once(self, x):\n",
    "        output = self.cnn1(x)\n",
    "        output = output.view(output.size()[0], -1)  #拉直\n",
    "        output = self.fc1(output)\n",
    "        return output\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "        return output1, output2\n",
    "    \n",
    "#自定义损失函数\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "        euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)\n",
    "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "\n",
    "        return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SiamsNet().cuda() #定义模型且移至GPU\n",
    "criterion = ContrastiveLoss() #定义损失函数\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0005) #定义优化器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 0 , Current loss: 0.9011\n",
      "\n",
      "Epoch number: 1 , Current loss: 1.1182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counter = []\n",
    "loss_history = [] \n",
    "iteration_number = 0\n",
    "\n",
    "\n",
    "#开始训练\n",
    "for epoch in range(0, 2):\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        img0, img1 , label = data\n",
    "        #img0维度为torch.Size([32, 1, 100, 100])，32是batch，label为torch.Size([32, 1])\n",
    "        img0, img1, label=img0.type(torch.FloatTensor),img1.type(torch.FloatTensor),label.type(torch.FloatTensor),\n",
    "        img0, img1 , label = img0.cuda(), img1.cuda(), label.cuda() #数据移至GPU\n",
    "        optimizer.zero_grad()\n",
    "        output1,output2 = model(img0, img1)\n",
    "        loss_contrastive = criterion(output1, output2, label)\n",
    "        loss_contrastive.backward()\n",
    "        optimizer.step()\n",
    "        if i % 10 == 0 :\n",
    "            iteration_number +=10\n",
    "            counter.append(iteration_number)\n",
    "            loss_history.append(loss_contrastive.item())\n",
    "    print(\"Epoch number: {} , Current loss: {:.4f}\\n\".format(epoch,loss_contrastive.item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 2/3840 [00:00<03:46, 16.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Epoch: 0 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3840/3840 [03:08<00:00, 20.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 1.087644801735878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 2/3840 [00:00<03:15, 19.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Val Loss: 1.086517067551613, (Best: 0)\n",
      "=== Epoch: 1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3840/3840 [03:08<00:00, 20.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 1.093797780275345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 2/3840 [00:00<03:19, 19.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Val Loss: 1.089845336675644, (Best: 0)\n",
      "=== Epoch: 2 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3840/3840 [03:10<00:00, 20.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 1.0854465806484221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 3/3840 [00:00<03:09, 20.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Val Loss: 1.0920331710577011, (Best: 0)\n",
      "=== Epoch: 3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3840/3840 [03:10<00:00, 20.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 1.0774353724718093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                 | 3/3840 [00:00<03:09, 20.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Val Loss: 1.0762821179628372, (Best: 0)\n",
      "=== Epoch: 4 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3840/3840 [03:09<00:00, 20.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train Loss: 1.0715907889604568\n",
      "Avg Val Loss: 1.0817658245563506, (Best: 0)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/user/Desktop/最近/best_protonet/last_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-139ac212253c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;31m#保存最终所有epoch得到的最佳模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_model_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'最后的结果： best_loss=%d, train_loss=%d, val_loss=%d'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anconda\\envs\\pyenv\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m     \"\"\"\n\u001b[1;32m--> 219\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anconda\\envs\\pyenv\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[1;34m(f, mode, body)\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/user/Desktop/最近/best_protonet/last_model.pth'"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import random\n",
    "    \n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "train_loss = [] #记录每个eposide，每个任务更新的结果\n",
    "\n",
    "val_loss = []\n",
    "\n",
    "best_loss = 0\n",
    "best_model_path='C:/Users/user/Desktop/最近/best_siamsnet/best_model_m.pth'\n",
    "last_model_path='C:/Users/user/Desktop/最近/best_siamsnet/last_model_m.pth'\n",
    "\n",
    "#遍历epoch训练\n",
    "for epoch in range(5):\n",
    "    print('=== Epoch: {} ==='.format(epoch))\n",
    "    #取一个batch的训练数据\n",
    "    tr_iter = iter(train_loader)\n",
    "    model.train()\n",
    "    for eposide in tqdm(tr_iter):  #遍历每个eposide，一共遍历iterations次，#len(next(iter(dataloader))) #[75个图片矩阵，75个标签]\n",
    "        \n",
    "        x1, x2, y = eposide   #x.shape=([75, 1, 28, 28])\n",
    "        #print(x1.shape)\n",
    "        x1, x2, y=x1.type(torch.FloatTensor),x2.type(torch.FloatTensor),y.type(torch.FloatTensor),\n",
    "        x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "        optimizer.zero_grad()  #梯度清零\n",
    "        \n",
    "        output1,output2= model(x1,x2)  #前传\n",
    "        loss= criterion(output1,output2, y)  #计算loss\n",
    " \n",
    "        loss.backward()  #反传\n",
    "        optimizer.step()  #参数更新\n",
    "        \n",
    "        train_loss.append(loss.item())   #加入这个batch的计算loss\n",
    "        \n",
    "    avg_loss = np.mean(train_loss[-100:])  #计算本次epoch的所有batch迭代的平均损失\n",
    "    print('Avg Train Loss: {}'.format(avg_loss))\n",
    "    \n",
    "    #每训练一个batch=iterations个任务后，验证一次模型\n",
    "    val_iter = iter(val_loader)\n",
    "    model.eval()\n",
    "    for eposide in val_iter:\n",
    "        x1, x2, y = eposide   #x.shape=([75, 1, 28, 28])\n",
    "        x1, x2, y=x1.type(torch.FloatTensor),x2.type(torch.FloatTensor),y.type(torch.FloatTensor),\n",
    "        x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "        \n",
    "        output1,output2= model(x1,x2)\n",
    "        loss= criterion(output1,output2, y)  #计算loss\n",
    "        \n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "    avg_loss = np.mean(val_loss[-100:])\n",
    "\n",
    "    #如果当前模型的验证效果比先前好，则把当前模型记为最佳模型\n",
    "    postfix = ' (Best)' if avg_loss <= best_loss else ' (Best: {})'.format(best_loss)\n",
    "    print('Avg Val Loss: {},{}'.format(  #输出本次验证的平均损失和准确率\n",
    "            avg_loss, postfix))\n",
    "\n",
    "    #保存某个epoch内所有batch在验证集上得到的最佳模型、准确率\n",
    "    if avg_loss <= best_loss:\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        best_loss = avg_loss\n",
    "        best_state = model.state_dict()\n",
    "\n",
    "#print(len(train_loss))  #iterations\n",
    "#print(len(val_loss)) #iterations\n",
    "\n",
    "#保存最终所有epoch得到的最佳模型\n",
    "torch.save(model.state_dict(), last_model_path)\n",
    "print('最后的结果： best_loss=%d, train_loss=%d, val_loss=%d' % (best_loss, train_loss[-1] ,val_loss[-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = list()\n",
    "for epoch in range(10):\n",
    "    test_iter = iter(test_loader)\n",
    "    for eposide in test_iter:\n",
    "        x1, x2, y = eposide   #x.shape=([75, 1, 28, 28])\n",
    "        x1, x2, y=x1.type(torch.FloatTensor),x2.type(torch.FloatTensor),y.type(torch.FloatTensor),\n",
    "        x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "        \n",
    "        output1,output2= model(x1,x2)\n",
    "        loss= criterion(output1,output2, y)  #计算loss\n",
    "        \n",
    "        test_loss.append(loss.item())\n",
    "        \n",
    "avg_loss = np.mean(test_loss)\n",
    "print('Test loss: {}'.format(avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=None\n",
    "#加载训练最好的模型参数\n",
    "model = SiamsNet().to(device)\n",
    "model.load_state_dict(torch.load(os.path.join('C:\\\\Users\\\\user\\\\Desktop\\\\最近\\\\best_siamsnet','last_model_m.pth')))\n",
    "#model.load_state_dict(best_state)\n",
    "print('Testing with best model..')\n",
    "\n",
    "#测试模型\n",
    "test_loss = list()\n",
    "for epoch in range(10):\n",
    "    test_iter = iter(test_loader)\n",
    "    for eposide in test_iter:\n",
    "        x1, x2, y = eposide   #x.shape=([75, 1, 28, 28])\n",
    "        x1, x2, y=x1.type(torch.FloatTensor),x2.type(torch.FloatTensor),y.type(torch.FloatTensor),\n",
    "        x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "        \n",
    "        output1,output2= model(x1,x2)\n",
    "        loss= criterion(output1,output2, y)  #计算loss\n",
    "        \n",
    "        test_loss.append(loss.item())\n",
    "        \n",
    "avg_loss = np.mean(test_loss)\n",
    "print('Test loss: {}'.format(avg_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyenv] *",
   "language": "python",
   "name": "conda-env-pyenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
